<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Elasticsearch备考指北_2</title>
      <link href="/2021/02/12/elasticsearch-bei-kao-zhi-bei-2/"/>
      <url>/2021/02/12/elasticsearch-bei-kao-zhi-bei-2/</url>
      
        <content type="html"><![CDATA[<h1 id="写在最前"><a href="#写在最前" class="headerlink" title="写在最前"></a>写在最前</h1><p>本文主要是对极客时间阮一鸣老师的<code>&lt;&lt;Elasticsearch核心技术与实战&gt;&gt;</code>这个课的一个个人总结,EE这个证书目前在国内仅仅有70人拿到,还是非常有含金量的,预计考取收益为涨薪20k+从新P6跃迁到老P6,同时在国际上也非常有竞争力,对于肉身翻墙很有帮助.<br>这里是课程链接: <a href="https://time.geekbang.org/course/intro/197?utm_term=zeusD4TUB&amp;utm_source=website&amp;utm_medium=infoq&amp;utm_campaign=197-presell&amp;utm_content=articlelearningpath0703" target="_blank" rel="noopener">https://time.geekbang.org/course/intro/197?utm_term=zeusD4TUB&amp;utm_source=website&amp;utm_medium=infoq&amp;utm_campaign=197-presell&amp;utm_content=articlelearningpath0703</a></p><h2 id="基于Term的查询和全文的查询"><a href="#基于Term的查询和全文的查询" class="headerlink" title="基于Term的查询和全文的查询"></a>基于Term的查询和全文的查询</h2><p>Term 是表达语义的最小单位,es在搜索的时候不会再对term做进一步拆分.<br>Term查询会直接查找倒排索引,然后根据算分公式计算出一个相关段算分.<br>注意索引都是小写的,直接查大写会无法命中索引.<br>对于有特殊符号的key,比如abc-edf,我们需要在mapping里设定使用keyword模式,或者直接转换为filter模式.<br>对于全文本的搜索,是会默认使用分词器的.<br>具体的演示demo:</p><pre><code>DELETE productsPUT products{  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1  }}POST /products/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;productID&quot; : &quot;XHDK-A-1293-#fJ3&quot;,&quot;desc&quot;:&quot;iPhone&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;productID&quot; : &quot;KDKE-B-9947-#kL5&quot;,&quot;desc&quot;:&quot;iPad&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;productID&quot; : &quot;JODL-X-1937-#pV7&quot;,&quot;desc&quot;:&quot;MBP&quot; }GET /productsPOST /products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;desc&quot;: {        //&quot;value&quot;: &quot;iPhone&quot;        &quot;value&quot;:&quot;iphone&quot;      }    }  }}POST /products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;desc.keyword&quot;: {        //&quot;value&quot;: &quot;iPhone&quot;        //&quot;value&quot;:&quot;iphone&quot;      }    }  }}POST /products/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;productID&quot;: {        &quot;value&quot;: &quot;XHDK-A-1293-#fJ3&quot;      }    }  }}POST /products/_search{  //&quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;productID.keyword&quot;: {        &quot;value&quot;: &quot;XHDK-A-1293-#fJ3&quot;      }    }  }}POST /products/_search{  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;productID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot;        }      }    }  }}#设置 position_increment_gapDELETE groupsPUT groups{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;names&quot;:{        &quot;type&quot;: &quot;text&quot;,        &quot;position_increment_gap&quot;: 0      }    }  }}GET groups/_mappingPOST groups/_doc{  &quot;names&quot;: [ &quot;John Water&quot;, &quot;Water Smith&quot;]}POST groups/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;names&quot;: {        &quot;query&quot;: &quot;Water Water&quot;,        &quot;slop&quot;: 100      }    }  }}POST groups/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;names&quot;: &quot;Water Smith&quot;    }  }} </code></pre><h2 id="结构化搜索"><a href="#结构化搜索" class="headerlink" title="结构化搜索"></a>结构化搜索</h2><p>结构化数据: 遵从一定的pattern的数据,这种情况下可以使用term查询来实现.<br>注意term查询的逻辑是包含而不是等于.  </p><pre><code>#结构化搜索，精确匹配DELETE productsPOST /products/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;price&quot; : 10,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2018-01-01&quot;, &quot;productID&quot; : &quot;XHDK-A-1293-#fJ3&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;price&quot; : 20,&quot;avaliable&quot;:true,&quot;date&quot;:&quot;2019-01-01&quot;, &quot;productID&quot; : &quot;KDKE-B-9947-#kL5&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:true, &quot;productID&quot; : &quot;JODL-X-1937-#pV7&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 }}{ &quot;price&quot; : 30,&quot;avaliable&quot;:false, &quot;productID&quot; : &quot;QQPX-R-3956-#aD8&quot; }GET products/_mapping#对布尔值 match 查询，有算分POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;avaliable&quot;: true    }  }}#对布尔值，通过constant score 转成 filtering，没有算分POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;avaliable&quot;: true        }      }    }  }}#数字类型 TermPOST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;price&quot;: 30    }  }}#数字类型 termsPOST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;terms&quot;: {          &quot;price&quot;: [            &quot;20&quot;,            &quot;30&quot;          ]        }      }    }  }}#数字 Range 查询GET products/_search{    &quot;query&quot; : {        &quot;constant_score&quot; : {            &quot;filter&quot; : {                &quot;range&quot; : {                    &quot;price&quot; : {                        &quot;gte&quot; : 20,                        &quot;lte&quot;  : 30                    }                }            }        }    }}# 日期 rangePOST products/_search{    &quot;query&quot; : {        &quot;constant_score&quot; : {            &quot;filter&quot; : {                &quot;range&quot; : {                    &quot;date&quot; : {                      &quot;gte&quot; : &quot;now-1y&quot;                    }                }            }        }    }}#exists查询POST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;exists&quot;: {          &quot;field&quot;: &quot;date&quot;        }      }    }  }}#处理多值字段POST /movies/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 }}{ &quot;title&quot; : &quot;Father of the Bridge Part II&quot;,&quot;year&quot;:1995, &quot;genre&quot;:&quot;Comedy&quot;}{ &quot;index&quot;: { &quot;_id&quot;: 2 }}{ &quot;title&quot; : &quot;Dave&quot;,&quot;year&quot;:1993,&quot;genre&quot;:[&quot;Comedy&quot;,&quot;Romance&quot;] }#处理多值字段，term 查询是包含，而不是等于POST movies/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;genre.keyword&quot;: &quot;Comedy&quot;        }      }    }  }}#字符类型 termsPOST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;terms&quot;: {          &quot;productID.keyword&quot;: [            &quot;QQPX-R-3956-#aD8&quot;,            &quot;JODL-X-1937-#pV7&quot;          ]        }      }    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;price&quot;: 30    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;date&quot;: &quot;2019-01-01&quot;    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;match&quot;: {      &quot;date&quot;: &quot;2019-01-01&quot;    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;productID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot;        }      }    }  }}POST products/_search{  &quot;profile&quot;: &quot;true&quot;,  &quot;explain&quot;: true,  &quot;query&quot;: {    &quot;term&quot;: {      &quot;productID.keyword&quot;: &quot;XHDK-A-1293-#fJ3&quot;    }  }}#对布尔数值POST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;avaliable&quot;: &quot;false&quot;        }      }    }  }}POST products/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;bool&quot;: {          &quot;must_not&quot;: {            &quot;exists&quot;: {              &quot;field&quot;: &quot;date&quot;            }          }        }      }    }  }}</code></pre><h2 id="相关性和相关性算分"><a href="#相关性和相关性算分" class="headerlink" title="相关性和相关性算分"></a>相关性和相关性算分</h2><p>搜索结果中_score就是搜索的相关性算分, 现在使用的排序方法是BM 25.<br>词频Term Frequency: 检索词在一篇文档中出现的频率,等于检索词出现的次数除以文档的总字数.<br>一个简单的方法是,把搜索句子拆分出来的每个term的TF加起来.比如计算abc,就计算TF_a+TF_b+TF_c<br>文档频率DF: 检索词在所有文档中出现的频率<br>逆文档频率: <code>log(全部文档数/检索词出现过的文档总数)</code><br>TF-IDF: TF_A<em>IDC_A+TF_B</em>IDF_B+TF_C*IDF_C.<br>在查询中使用explain</p>]]></content>
      
      
      <categories>
          
          <category> Elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch备考指北_1</title>
      <link href="/2021/02/04/elasticsearch-bei-kao-zhi-bei-1/"/>
      <url>/2021/02/04/elasticsearch-bei-kao-zhi-bei-1/</url>
      
        <content type="html"><![CDATA[<h1 id="写在最前"><a href="#写在最前" class="headerlink" title="写在最前"></a>写在最前</h1><p>本文主要是对极客时间阮一鸣老师的<code>&lt;&lt;Elasticsearch核心技术与实战&gt;&gt;</code>这个课的一个个人总结,EE这个证书目前在国内仅仅有70人拿到,还是非常有含金量的,预计考取收益为涨薪20k+从新P6跃迁到老P6,同时在国际上也非常有竞争力,对于肉身翻墙很有帮助.<br>这里是课程链接: <a href="https://time.geekbang.org/course/intro/197?utm_term=zeusD4TUB&amp;utm_source=website&amp;utm_medium=infoq&amp;utm_campaign=197-presell&amp;utm_content=articlelearningpath0703" target="_blank" rel="noopener">https://time.geekbang.org/course/intro/197?utm_term=zeusD4TUB&amp;utm_source=website&amp;utm_medium=infoq&amp;utm_campaign=197-presell&amp;utm_content=articlelearningpath0703</a></p><h1 id="基本概念和基本使用"><a href="#基本概念和基本使用" class="headerlink" title="基本概念和基本使用"></a>基本概念和基本使用</h1><h2 id="索引-index"><a href="#索引-index" class="headerlink" title="索引(index):"></a>索引(index):</h2><p>等同于数据库中的 表 这一级别,一个索引包含很多个文档.<br>每一个索引都有自己的Mapping定义,包含这个索引的字段名和类型;还有自己的分片(shard),索引的数据实际上在不同的分片上.  </p><h2 id="文档-document"><a href="#文档-document" class="headerlink" title="文档(document):"></a>文档(document):</h2><p>相当于数据库中的 记录 这一级别,一般是JSON格式,字段类型可以指定或者让ES自动推算.</p><p>相关对照关系可以看这个表格:<br><img src="https://s3.ax1x.com/2021/02/05/y3o3qK.png" alt="es和sql对照关系"></p><h2 id="元数据"><a href="#元数据" class="headerlink" title="元数据:"></a>元数据:</h2><p>标注文档的相关信息,往往使用下划线开头,包含以下字段:</p><ul><li>_index: 文档所属索引名</li><li>_type: 类型名</li><li>_id: 文档的唯一ID</li><li>_source: 文档原始JSON数据</li><li>_version: 文档的版本信息</li><li>_score: 相关性打分</li></ul><h2 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API:"></a>REST API:</h2><p>给一些示例吧,对于某个索引这一级别,直接跟索引名即可;但是对于索引的上一级别,需要先加一个_cat/indices/,再进行更加具体的查询. </p><pre><code>#查看索引相关信息GET kibana_sample_data_ecommerce#查看索引的文档总数GET kibana_sample_data_ecommerce/_count#查看前10条文档，了解文档格式POST kibana_sample_data_ecommerce/_search{}#_cat indices API#查看indicesGET /_cat/indices/kibana*?v&amp;s=index#查看状态为绿的索引GET /_cat/indices?v&amp;health=green#按照文档个数排序GET /_cat/indices?v&amp;s=docs.count:desc#查看具体的字段GET /_cat/indices/kibana*?pri&amp;v&amp;h=health,index,pri,rep,docs.count,mt#How much memory is used per index?GET /_cat/indices?v&amp;h=i,tm&amp;s=tm:desc</code></pre><h2 id="高可用："><a href="#高可用：" class="headerlink" title="高可用："></a>高可用：</h2><p>允许有节点停止服务；部分节点丢失，不会丢失数据；</p><h2 id="可扩展性："><a href="#可扩展性：" class="headerlink" title="可扩展性："></a>可扩展性：</h2><p>数据分布在所有节点上</p><h2 id="es的分布式架构："><a href="#es的分布式架构：" class="headerlink" title="es的分布式架构："></a>es的分布式架构：</h2><p>不同的集群通过不同的名字来区分，可以通过配置文件修改，或者在命令行中进行指定</p><pre><code>-E cluster.name = geektime </code></pre><h2 id="节点："><a href="#节点：" class="headerlink" title="节点："></a>节点：</h2><p>节点本质就是一个Java进程，一般建议一个机器上只运行一个es实例.<br>同样也可以使用命令进行指定:</p><pre><code>-E node.name = node1</code></pre><p>每一个节点在启动之后会有一个UID存在data目录下.</p><h2 id="Master节点"><a href="#Master节点" class="headerlink" title="Master节点:"></a>Master节点:</h2><p>每个节点启动后默认就是一个Master eligible节点,可以在参与主流程选举之后成为Master节点.每个节点都保存了集群状态,但是只有master节点可以修改集群的状态.<br>集群状态包含:</p><ul><li>所有的节点信息</li><li>所有的索引和相关的mapping以及setting信息</li><li>分片的路由信息</li></ul><h2 id="Data-Node"><a href="#Data-Node" class="headerlink" title="Data Node:"></a>Data Node:</h2><p>可以保存数据的节点, 负责保存分片数据;</p><h2 id="Coordinating-Node"><a href="#Coordinating-Node" class="headerlink" title="Coordinating Node:"></a>Coordinating Node:</h2><p>负责接收Client的请求,将请求分发给合适的节点;<br>每个节点默认都起到了CN节点的职责;</p><h2 id="主分片"><a href="#主分片" class="headerlink" title="主分片:"></a>主分片:</h2><p>在索引创建时指定,不允许修改;<br>通过主分片可以把数据分布到所有节点上;<br>分片的数量需要提前做好规划,数量过小会导致后续无法进行水平扩展,同时单个分片的数据量过大,导致数据重分配耗时;分片数量过多会影响结果的相关性打分,也会导致资源的浪费.</p><h2 id="副本"><a href="#副本" class="headerlink" title="副本:"></a>副本:</h2><p>副本是主分片的copy,可以动态调整;</p><h2 id="集群健康状况"><a href="#集群健康状况" class="headerlink" title="集群健康状况:"></a>集群健康状况:</h2><p>使用/_cluster/health来查看当前的健康状态<br>或者使用cat api, /-cat/nodes</p><ul><li>green: 主分片和副本都正常分配</li><li>yellow: 主分片正常,副本不正常</li><li>red: 主分片分配失败</li></ul><p>一些关于节点和集群的常用命令:</p><pre><code>get _cat/nodes 查看节点状态get _cat/shards 查看分片状态GET /_cat/nodes?v&amp;h=id,ip,port,v,m 查看各个节点的一些属性 </code></pre><h2 id="CURD"><a href="#CURD" class="headerlink" title="CURD:"></a>CURD:</h2><p>index和create:<br>都是创建,区别在于如果id已经存在,index会删除现有文档,然后创建新文档,<br>版本+1;但是create会直接失败;<br>这两者都是使用put字段,update是使用post字段.<br>index是_doc字段,create是_create字段</p><p>update:<br>文档必须已经存在, 更新只会对相应字段增量修改;<br>必须要指定doc字段;<br>注意只有在真正更新的时候,update才会增加版本号;但是index即使不更新,也会增加版本号.</p><p>get: 索引名/type类型/id, 获取一个指定的文档,会先返回所有的原始信息,_source中会返回所有保存的原始信息</p><pre><code>#create document. 自动生成 _idPOST users/_doc{    &quot;user&quot; : &quot;Mike&quot;,    &quot;post_date&quot; : &quot;2019-04-15T14:12:12&quot;,    &quot;message&quot; : &quot;trying out Kibana&quot;}#create document. 指定Id。如果id已经存在，报错PUT users/_doc/1?op_type=create{    &quot;user&quot; : &quot;Jack&quot;,    &quot;post_date&quot; : &quot;2019-05-15T14:12:12&quot;,    &quot;message&quot; : &quot;trying out Elasticsearch&quot;}#create document. 指定 ID 如果已经存在，就报错PUT users/_doc/1{     &quot;user&quot; : &quot;Jack&quot;,    &quot;post_date&quot; : &quot;2019-05-15T14:12:12&quot;,    &quot;message&quot; : &quot;trying out Elasticsearch&quot;}### Get Document by ID#Get the document by IDGET users/_doc/1###  Index &amp; Update#Update 指定 ID  (先删除，在写入)GET users/_doc/1PUT users/_doc/1{    &quot;user&quot; : &quot;Mike&quot;}#GET users/_doc/1#在原文档上增加字段POST users/_update/1/{    &quot;doc&quot;:{        &quot;post_date&quot; : &quot;2019-05-15T14:12:12&quot;,        &quot;message&quot; : &quot;trying out Elasticsearch-1&quot;    }}</code></pre><h2 id="Bulk-Api"><a href="#Bulk-Api" class="headerlink" title="Bulk Api:"></a>Bulk Api:</h2><p>支持在一次api调用中,对不同的索引进行操作.<br>操作中单条失败不会影响其他操作.<br>返回的结果包含每一条执行结果. </p><pre><code>#执行第1次POST _bulk{ &quot;index&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;1&quot; } }{ &quot;field1&quot; : &quot;value1&quot; }{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test&quot;, &quot;_id&quot; : &quot;2&quot; } }{ &quot;create&quot; : { &quot;_index&quot; : &quot;test2&quot;, &quot;_id&quot; : &quot;3&quot; } }{ &quot;field1&quot; : &quot;value3&quot; }{ &quot;update&quot; : {&quot;_id&quot; : &quot;1&quot;, &quot;_index&quot; : &quot;test&quot;} }{ &quot;doc&quot; : {&quot;field2&quot; : &quot;value2&quot;} }</code></pre><h2 id="mget"><a href="#mget" class="headerlink" title="mget:"></a>mget:</h2><p>批量读取,降低网络开销</p><pre><code>GET /_mget{    &quot;docs&quot; : [        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;1&quot;        },        {            &quot;_index&quot; : &quot;test&quot;,            &quot;_id&quot; : &quot;2&quot;        }    ]}#URI中指定indexGET /test/_mget{    &quot;docs&quot; : [        {            &quot;_id&quot; : &quot;1&quot;        },        {            &quot;_id&quot; : &quot;2&quot;        }    ]}</code></pre><h2 id="msearch"><a href="#msearch" class="headerlink" title="msearch:"></a>msearch:</h2><p>批量查询</p><pre><code>### msearch 操作POST kibana_sample_data_ecommerce/_msearch{{&quot;query&quot; : {&quot;match_all&quot; : {}},&quot;size&quot;:1}{&quot;index&quot; : &quot;kibana_sample_data_flights&quot;}{&quot;query&quot; : {&quot;match_all&quot; : {}},&quot;size&quot;:2}}</code></pre><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis:"></a>Analysis:</h2><p>文本分析,是把全文本转换为一系列单词的过程,也叫分词.<br>主要目的是为了给构造倒排索引做准备.<br>根据不同的Analyzer来进行处理会得到不同的分词结果.  </p><h2 id="Analyzer分类"><a href="#Analyzer分类" class="headerlink" title="Analyzer分类:"></a>Analyzer分类:</h2><ul><li>Standard: 默认分词器,按词或者空格切分,小写处理.</li></ul><pre><code>POST _analyze{  &quot;analyzer&quot;: &quot;standard&quot;,  &quot;text&quot;: &quot;Elasticsearch Server&quot;}</code></pre><ul><li>Simple: 非字母进行切分,小写处理</li><li>whitespace: 空格切分</li><li>stop: 相比于simple多了一个stop filter,会把the,a,is等修饰性词语去掉.</li><li>keyword: 不分词,直接让整个text作为一个token.</li><li>pattern analyzer: 通过正则表达式进行分词,默认是\W+,按照非字母的符号进行分割.</li><li>english: 英文进行分词,去掉ing或者复数等类似的东西.</li><li>icu_analyzer: 一个比较好用的中文分词器.</li></ul><h2 id="查询"><a href="#查询" class="headerlink" title="查询:"></a>查询:</h2><p>使用/_search来进行查询,但是需要指定对应的索引.</p><pre><code>/index1/_search 在index1上查询/_search 在所有索引上查询/index*/_search 在index开头的索引上查询</code></pre><p>如果使用URI查询,使用q来查询指定字段,比如:</p><pre><code>_search?q=customer_first_name:Eddie 查询名叫Eddie的客户</code></pre><p>返回结果字段分析:<br>took: 花费的时间<br>total: 符合条件的总文档数<br>hits: 结果集,默认前十个文档</p><h2 id="相关性衡量指标"><a href="#相关性衡量指标" class="headerlink" title="相关性衡量指标:"></a>相关性衡量指标:</h2><p>precision(查准率): 尽可能返回较少的无关文档,true positive/all positive<br>recall(查全率): 尽可能返回较多的相关文档, tP/TP+FN<br>ranking: 是否能够按照相关度进行排序</p><h2 id="URI-Search"><a href="#URI-Search" class="headerlink" title="URI Search"></a>URI Search</h2><p>通过uri query实现搜索,<br>q指定查询语句,df指定字段,默认是所有字段,sort排序,from和size用于分页,profile用于查看查询是如何被执行的.<br>使用query string syntax语法格式,空格等于or,引号等于and,括号代表分组bool的概念,冒号字段和对应的条件.<br>布尔操作必须是大写.<br>“+”代表must,”-“代表must not.<br>范围查询仅限于数字使用.<br>模糊匹配是使用<code>~1</code>,代表允许出现一位的误差,比如us-&gt;use;<br>但是如果是<code>引号~1</code>,代表允许单词中插入一个单词,比如log of-&gt;log and of</p><pre><code>#基本查询GET /movies/_search?q=2012&amp;df=title&amp;sort=year:desc&amp;from=0&amp;size=10&amp;timeout=1s#带profileGET /movies/_search?q=2012&amp;df=title{    &quot;profile&quot;:&quot;true&quot;}#泛查询，正对_all,所有字段GET /movies/_search?q=2012{    &quot;profile&quot;:&quot;true&quot;}#指定字段GET /movies/_search?q=title:2012&amp;sort=year:desc&amp;from=0&amp;size=10&amp;timeout=1s{    &quot;profile&quot;:&quot;true&quot;}# 查找美丽心灵, Mind为泛查询GET /movies/_search?q=title:Beautiful Mind{    &quot;profile&quot;:&quot;true&quot;}# 泛查询GET /movies/_search?q=title:2012{    &quot;profile&quot;:&quot;true&quot;}#使用引号，Phrase查询GET /movies/_search?q=title:&quot;Beautiful Mind&quot;{    &quot;profile&quot;:&quot;true&quot;}#分组，Bool查询GET /movies/_search?q=title:(Beautiful Mind){    &quot;profile&quot;:&quot;true&quot;}#布尔操作符# 查找美丽心灵GET /movies/_search?q=title:(Beautiful AND Mind){    &quot;profile&quot;:&quot;true&quot;}# 查找美丽心灵GET /movies/_search?q=title:(Beautiful NOT Mind){    &quot;profile&quot;:&quot;true&quot;}# 查找美丽心灵GET /movies/_search?q=title:(Beautiful %2BMind){    &quot;profile&quot;:&quot;true&quot;}#范围查询 ,区间写法GET /movies/_search?q=title:beautiful AND year:[2002 TO 2018%7D{    &quot;profile&quot;:&quot;true&quot;}#通配符查询GET /movies/_search?q=title:b*{    &quot;profile&quot;:&quot;true&quot;}//模糊匹配&amp;近似度匹配GET /movies/_search?q=title:beautifl~1{    &quot;profile&quot;:&quot;true&quot;}GET /movies/_search?q=title:&quot;Lord Rings&quot;~2{    &quot;profile&quot;:&quot;true&quot;}</code></pre><h2 id="Query-DSL"><a href="#Query-DSL" class="headerlink" title="Query DSL"></a>Query DSL</h2><p>通过http的request body发送给Elasticsearch.<br>语句类似uri查询,但是使用json格式,更加清晰.<br>脚本字段: 使用painless字段去算出来一个我们需要的新字段出来.<br>query的match字段对应的是具体的查询条件.<br>如果需要更加详细的查询条件,可以在具体的字段查询中再使用query字段.<br>看下列demo:</p><pre><code>#ignore_unavailable=true，可以忽略尝试访问不存在的索引“404_idx”导致的报错#查询movies分页POST /movies,404_idx/_search?ignore_unavailable=true{  &quot;profile&quot;: true,    &quot;query&quot;: {        &quot;match_all&quot;: {}    }}POST /kibana_sample_data_ecommerce/_search{  &quot;from&quot;:10,  &quot;size&quot;:20,  &quot;query&quot;:{    &quot;match_all&quot;: {}  }}#对日期排序POST kibana_sample_data_ecommerce/_search{  &quot;sort&quot;:[{&quot;order_date&quot;:&quot;desc&quot;}],  &quot;query&quot;:{    &quot;match_all&quot;: {}  }}#source filteringPOST kibana_sample_data_ecommerce/_search{  &quot;_source&quot;:[&quot;order_date&quot;],  &quot;query&quot;:{    &quot;match_all&quot;: {}  }}#脚本字段GET kibana_sample_data_ecommerce/_search{  &quot;script_fields&quot;: {    &quot;new_field&quot;: {      &quot;script&quot;: {        &quot;lang&quot;: &quot;painless&quot;,        &quot;source&quot;: &quot;doc[&#39;order_date&#39;].value+&#39;hello&#39;&quot;      }    }  },  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}POST movies/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;title&quot;: &quot;last christmas&quot;    }  }}POST movies/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;title&quot;: {        &quot;query&quot;: &quot;last christmas&quot;,        &quot;operator&quot;: &quot;and&quot;      }    }  }}POST movies/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;title&quot;:{        &quot;query&quot;: &quot;one love&quot;      }    }  }}# slop代表可以差一个词,模糊查询.POST movies/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;title&quot;:{        &quot;query&quot;: &quot;one love&quot;,        &quot;slop&quot;: 1      }    }  }}</code></pre><h2 id="query-string-query"><a href="#query-string-query" class="headerlink" title="query string query"></a>query string query</h2><p>使用query_string字段,指定default_field和query具体的内容.<br>simple query查询可以指定default_operator,比如and,但是字符串中的and会被视为字符串的一部分.<br>一些demo:</p><pre><code>PUT /users/_doc/1{  &quot;name&quot;:&quot;Ruan Yiming&quot;,  &quot;about&quot;:&quot;java, golang, node, swift, elasticsearch&quot;}PUT /users/_doc/2{  &quot;name&quot;:&quot;Li Yiming&quot;,  &quot;about&quot;:&quot;Hadoop&quot;}POST users/_search{  &quot;query&quot;: {    &quot;query_string&quot;: {      &quot;default_field&quot;: &quot;name&quot;,      &quot;query&quot;: &quot;Ruan AND Yiming&quot;    }  }}POST users/_search{  &quot;query&quot;: {    &quot;query_string&quot;: {      &quot;fields&quot;:[&quot;name&quot;,&quot;about&quot;],      &quot;query&quot;: &quot;(Ruan AND Yiming) OR (Java AND Elasticsearch)&quot;    }  }}#Simple Query 默认的operator是 OrPOST users/_search{  &quot;query&quot;: {    &quot;simple_query_string&quot;: {      &quot;query&quot;: &quot;Ruan AND Yiming&quot;,      &quot;fields&quot;: [&quot;name&quot;]    }  }}POST users/_search{  &quot;query&quot;: {    &quot;simple_query_string&quot;: {      &quot;query&quot;: &quot;Ruan Yiming&quot;,      &quot;fields&quot;: [&quot;name&quot;],      &quot;default_operator&quot;: &quot;AND&quot;    }  }}GET /movies/_search{    &quot;profile&quot;: true,    &quot;query&quot;:{        &quot;query_string&quot;:{            &quot;default_field&quot;: &quot;title&quot;,            &quot;query&quot;: &quot;Beafiful AND Mind&quot;        }    }}# 多fieldsGET /movies/_search{    &quot;profile&quot;: true,    &quot;query&quot;:{        &quot;query_string&quot;:{            &quot;fields&quot;:[                &quot;title&quot;,                &quot;year&quot;            ],            &quot;query&quot;: &quot;2012&quot;        }    }}GET /movies/_search{    &quot;profile&quot;:true,    &quot;query&quot;:{        &quot;simple_query_string&quot;:{            &quot;query&quot;:&quot;Beautiful +mind&quot;,            &quot;fields&quot;:[&quot;title&quot;]        }    }}</code></pre><h2 id="Dynamic-Mapping"><a href="#Dynamic-Mapping" class="headerlink" title="Dynamic Mapping"></a>Dynamic Mapping</h2><p>Mapping实际上就是schema,定义字段的名称和数据类型以及倒排索引的相关配置.<br>dynamic的机制就是,在创建索引的时候,会自动的推断出字段的类型,是根据json来匹配的,如果无法匹配就创建成text.<br>注意一旦mapping被生成,就不允许再进行修改了.只能重新reindex对索引进行重建.<br>下面是demo:</p><pre><code>#写入文档，查看 MappingPUT mapping_test/_doc/1{  &quot;firstName&quot;:&quot;Chan&quot;,  &quot;lastName&quot;: &quot;Jackie&quot;,  &quot;loginDate&quot;:&quot;2018-07-24T10:29:48.103Z&quot;}#查看 Mapping文件GET mapping_test/_mapping#Delete indexDELETE mapping_test#dynamic mapping，推断字段的类型PUT mapping_test/_doc/1{    &quot;uid&quot; : &quot;123&quot;,    &quot;isVip&quot; : false,    &quot;isAdmin&quot;: &quot;true&quot;,    &quot;age&quot;:19,    &quot;heigh&quot;:180}#查看 DynamicGET mapping_test/_mapping#默认Mapping支持dynamic，写入的文档中加入新的字段PUT dynamic_mapping_test/_doc/1{  &quot;newField&quot;:&quot;someValue&quot;}#该字段可以被搜索，数据也在_source中出现POST dynamic_mapping_test/_search{  &quot;query&quot;:{    &quot;match&quot;:{      &quot;newField&quot;:&quot;someValue&quot;    }  }}#修改为dynamic falsePUT dynamic_mapping_test/_mapping{  &quot;dynamic&quot;: false}#新增 anotherFieldPUT dynamic_mapping_test/_doc/10{  &quot;anotherField&quot;:&quot;someValue&quot;}#该字段不可以被搜索，因为dynamic已经被设置为falsePOST dynamic_mapping_test/_search{  &quot;query&quot;:{    &quot;match&quot;:{      &quot;anotherField&quot;:&quot;someValue&quot;    }  }}get dynamic_mapping_test/_doc/10#修改为strictPUT dynamic_mapping_test/_mapping{  &quot;dynamic&quot;: &quot;strict&quot;}#写入数据出错，HTTP Code 400PUT dynamic_mapping_test/_doc/12{  &quot;lastField&quot;:&quot;value&quot;}DELETE dynamic_mapping_test</code></pre><p>Mapping也可以显示的定义,格式为:<br>put+索引名+”mapping”关键字.<br>但是更加方便的一个方法是,先构造一个临时的index,写入样本数据,使用mapping api获取该临时index的mapping配置,然后删除这个临时索引即可.<br>如果有对null搜索的需求,我们可以使用null_value这个关键字来把null指定为任意的字符串,搜索这个字符串即可.<br>以下是一些相关demo:</p><pre><code>#设置 index 为 falseDELETE usersPUT users{    &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;firstName&quot; : {          &quot;type&quot; : &quot;text&quot;        },        &quot;lastName&quot; : {          &quot;type&quot; : &quot;text&quot;        },        &quot;mobile&quot; : {          &quot;type&quot; : &quot;text&quot;,          &quot;index&quot;: false        }      }    }}PUT users/_doc/1{  &quot;firstName&quot;:&quot;Ruan&quot;,  &quot;lastName&quot;: &quot;Yiming&quot;,  &quot;mobile&quot;: &quot;12345678&quot;}POST /users/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;mobile&quot;:&quot;12345678&quot;    }  }}#设定Null_valueDELETE usersPUT users{    &quot;mappings&quot; : {      &quot;properties&quot; : {        &quot;firstName&quot; : {          &quot;type&quot; : &quot;text&quot;        },        &quot;lastName&quot; : {          &quot;type&quot; : &quot;text&quot;        },        &quot;mobile&quot; : {          &quot;type&quot; : &quot;keyword&quot;,          &quot;null_value&quot;: &quot;NULL&quot;        }      }    }}PUT users/_doc/1{  &quot;firstName&quot;:&quot;Ruan&quot;,  &quot;lastName&quot;: &quot;Yiming&quot;,  &quot;mobile&quot;: null}PUT users/_doc/2{  &quot;firstName&quot;:&quot;Ruan2&quot;,  &quot;lastName&quot;: &quot;Yiming2&quot;}GET users/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;mobile&quot;:&quot;NULL&quot;    }  }}#设置 Copy toDELETE usersPUT users{  &quot;mappings&quot;: {    &quot;properties&quot;: {      &quot;firstName&quot;:{        &quot;type&quot;: &quot;text&quot;,        &quot;copy_to&quot;: &quot;fullName&quot;      },      &quot;lastName&quot;:{        &quot;type&quot;: &quot;text&quot;,        &quot;copy_to&quot;: &quot;fullName&quot;      }    }  }}PUT users/_doc/1{  &quot;firstName&quot;:&quot;Ruan&quot;,  &quot;lastName&quot;: &quot;Yiming&quot;}GET users/_search?q=fullName:(Ruan Yiming)POST users/_search{  &quot;query&quot;: {    &quot;match&quot;: {       &quot;fullName&quot;:{        &quot;query&quot;: &quot;Ruan Yiming&quot;,        &quot;operator&quot;: &quot;and&quot;      }    }  }}#数组类型PUT users/_doc/1{  &quot;name&quot;:&quot;onebird&quot;,  &quot;interests&quot;:&quot;reading&quot;}PUT users/_doc/1{  &quot;name&quot;:&quot;twobirds&quot;,  &quot;interests&quot;:[&quot;reading&quot;,&quot;music&quot;]}POST users/_search{  &quot;query&quot;: {        &quot;match_all&quot;: {}    }}GET users/_mapping</code></pre><h2 id="配置自定义分词"><a href="#配置自定义分词" class="headerlink" title="配置自定义分词"></a>配置自定义分词</h2><p>精确值: 不需要做特殊的分词处理,比如”apple store”这个词可以整个作为一个索引项.<br>Character Filters: 在Tokenizer之前对文本进行处理,会增加删除或者是替换字段.<br>可以在创建索引的settings里自定义分词器<br>一些demo:</p><pre><code>PUT logs/_doc/1{&quot;level&quot;:&quot;DEBUG&quot;}GET /logs/_mappingPOST _analyze{  &quot;tokenizer&quot;:&quot;keyword&quot;,  &quot;char_filter&quot;:[&quot;html_strip&quot;],  &quot;text&quot;: &quot;&lt;b&gt;hello world&lt;/b&gt;&quot;}POST _analyze{  &quot;tokenizer&quot;:&quot;path_hierarchy&quot;,  &quot;text&quot;:&quot;/user/ymruan/a/b/c/d/e&quot;}#使用char filter进行替换POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;char_filter&quot;: [      {        &quot;type&quot; : &quot;mapping&quot;,        &quot;mappings&quot; : [ &quot;- =&gt; _&quot;]      }    ],  &quot;text&quot;: &quot;123-456, I-test! test-990 650-555-1234&quot;}//char filter 替换表情符号POST _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;char_filter&quot;: [      {        &quot;type&quot; : &quot;mapping&quot;,        &quot;mappings&quot; : [ &quot;:) =&gt; happy&quot;, &quot;:( =&gt; sad&quot;]      }    ],    &quot;text&quot;: [&quot;I am felling :)&quot;, &quot;Feeling :( today&quot;]}// white space and snowballGET _analyze{  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;stop&quot;,&quot;snowball&quot;],  &quot;text&quot;: [&quot;The gilrs in China are playing this game!&quot;]}// whitespace与stopGET _analyze{  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;stop&quot;,&quot;snowball&quot;],  &quot;text&quot;: [&quot;The rain in Spain falls mainly on the plain.&quot;]}//remove 加入lowercase后，The被当成 stopword删除GET _analyze{  &quot;tokenizer&quot;: &quot;whitespace&quot;,  &quot;filter&quot;: [&quot;lowercase&quot;,&quot;stop&quot;,&quot;snowball&quot;],  &quot;text&quot;: [&quot;The gilrs in China are playing this game!&quot;]}//正则表达式GET _analyze{  &quot;tokenizer&quot;: &quot;standard&quot;,  &quot;char_filter&quot;: [      {        &quot;type&quot; : &quot;pattern_replace&quot;,        &quot;pattern&quot; : &quot;http://(.*)&quot;,        &quot;replacement&quot; : &quot;$1&quot;      }    ],    &quot;text&quot; : &quot;http://www.elastic.co&quot;}</code></pre><h2 id="index-template和dynamic-template"><a href="#index-template和dynamic-template" class="headerlink" title="index template和dynamic template"></a>index template和dynamic template</h2><p>帮助你设定mappings和settings,并按照一定的规则自动创建到新建的索引上.<br>对应_template关键字,可以指定index_pattern,order,version,settings等等.<br>template使用的工作方式如下:</p><ul><li>应用默认的模板</li><li>应用order数值低的template的设定</li><li>应用order高的设定,之前的被覆盖</li><li>在创建索引时,如果用户自定义了settings就继续覆盖</li></ul><p>dynamic template是指对于某特定模板设定对应的字段类型,比如is开头的全部为boolean类型</p><pre><code>#数字字符串被映射成text，日期字符串被映射成日期PUT ttemplate/_doc/1{    &quot;someNumber&quot;:&quot;1&quot;,    &quot;someDate&quot;:&quot;2019/01/01&quot;}GET ttemplate/_mapping#Create a default templatePUT _template/template_default{  &quot;index_patterns&quot;: [&quot;*&quot;],  &quot;order&quot; : 0,  &quot;version&quot;: 1,  &quot;settings&quot;: {    &quot;number_of_shards&quot;: 1,    &quot;number_of_replicas&quot;:1  }}PUT /_template/template_test{    &quot;index_patterns&quot; : [&quot;test*&quot;],    &quot;order&quot; : 1,    &quot;settings&quot; : {        &quot;number_of_shards&quot;: 1,        &quot;number_of_replicas&quot; : 2    },    &quot;mappings&quot; : {        &quot;date_detection&quot;: false,        &quot;numeric_detection&quot;: true    }}#查看template信息GET /_template/template_defaultGET /_template/temp*#写入新的数据，index以test开头PUT testtemplate/_doc/1{    &quot;someNumber&quot;:&quot;1&quot;,    &quot;someDate&quot;:&quot;2019/01/01&quot;}GET testtemplate/_mappingget testtemplate/_settingsPUT testmy{    &quot;settings&quot;:{        &quot;number_of_replicas&quot;:5    }}put testmy/_doc/1{  &quot;key&quot;:&quot;value&quot;}get testmy/_settingsDELETE testmyDELETE /_template/template_defaultDELETE /_template/template_test#Dynaminc Mapping 根据类型和字段名DELETE my_indexPUT my_index/_doc/1{  &quot;firstName&quot;:&quot;Ruan&quot;,  &quot;isVIP&quot;:&quot;true&quot;}GET my_index/_mappingDELETE my_indexPUT my_index{  &quot;mappings&quot;: {    &quot;dynamic_templates&quot;: [            {        &quot;strings_as_boolean&quot;: {          &quot;match_mapping_type&quot;:   &quot;string&quot;,          &quot;match&quot;:&quot;is*&quot;,          &quot;mapping&quot;: {            &quot;type&quot;: &quot;boolean&quot;          }        }      },      {        &quot;strings_as_keywords&quot;: {          &quot;match_mapping_type&quot;:   &quot;string&quot;,          &quot;mapping&quot;: {            &quot;type&quot;: &quot;keyword&quot;          }        }      }    ]  }}DELETE my_index#结合路径PUT my_index{  &quot;mappings&quot;: {    &quot;dynamic_templates&quot;: [      {        &quot;full_name&quot;: {          &quot;path_match&quot;:   &quot;name.*&quot;,          &quot;path_unmatch&quot;: &quot;*.middle&quot;,          &quot;mapping&quot;: {            &quot;type&quot;:       &quot;text&quot;,            &quot;copy_to&quot;:    &quot;full_name&quot;          }        }      }    ]  }}PUT my_index/_doc/1{  &quot;name&quot;: {    &quot;first&quot;:  &quot;John&quot;,    &quot;middle&quot;: &quot;Winston&quot;,    &quot;last&quot;:   &quot;Lennon&quot;  }} GET my_index/_search?q=full_name:John</code></pre><h2 id="聚合特性"><a href="#聚合特性" class="headerlink" title="聚合特性"></a>聚合特性</h2><p> es提供对es数据进行统计分析的功能,而且性能非常高.<br> 类似于sql语句中的count和group by语句.  </p><pre><code> #按照目的地进行分桶统计GET kibana_sample_data_flights/_search{    &quot;size&quot;: 0,    &quot;aggs&quot;:{        &quot;flight_dest&quot;:{            &quot;terms&quot;:{                &quot;field&quot;:&quot;DestCountry&quot;            }        }    }}#查看航班目的地的统计信息，增加平均，最高最低价格GET kibana_sample_data_flights/_search{    &quot;size&quot;: 0,    &quot;aggs&quot;:{        &quot;flight_dest&quot;:{            &quot;terms&quot;:{                &quot;field&quot;:&quot;DestCountry&quot;            },            &quot;aggs&quot;:{                &quot;avg_price&quot;:{                    &quot;avg&quot;:{                        &quot;field&quot;:&quot;AvgTicketPrice&quot;                    }                },                &quot;max_price&quot;:{                    &quot;max&quot;:{                        &quot;field&quot;:&quot;AvgTicketPrice&quot;                    }                },                &quot;min_price&quot;:{                    &quot;min&quot;:{                        &quot;field&quot;:&quot;AvgTicketPrice&quot;                    }                }            }        }    }}#价格统计信息+天气信息GET kibana_sample_data_flights/_search{    &quot;size&quot;: 0,    &quot;aggs&quot;:{        &quot;flight_dest&quot;:{            &quot;terms&quot;:{                &quot;field&quot;:&quot;DestCountry&quot;            },            &quot;aggs&quot;:{                &quot;stats_price&quot;:{                    &quot;stats&quot;:{                        &quot;field&quot;:&quot;AvgTicketPrice&quot;                    }                },                &quot;wather&quot;:{                  &quot;terms&quot;: {                    &quot;field&quot;: &quot;DestWeather&quot;,                    &quot;size&quot;: 5                  }                }            }        }    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> Elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_17</title>
      <link href="/2021/02/02/java-kai-fa-chang-jian-cuo-wu-17/"/>
      <url>/2021/02/02/java-kai-fa-chang-jian-cuo-wu-17/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="17-别以为自动挡就不可能出现OOM"><a href="#17-别以为自动挡就不可能出现OOM" class="headerlink" title="17. 别以为自动挡就不可能出现OOM"></a>17. 别以为自动挡就不可能出现OOM</h2><p>自动挡其实就是Java垃圾收集器的一个昵称.但是自动挡并不能完全防止OOM.之前老师在第三讲介绍了两种OOM,一种是使用无界队列导致堆OOM,另一种是因为使用没有最大线程数限制的线程池导致无限创建线程的OOM.类似的案例还有很多,这节课我们专门研究下这个问题.</p><h3 id="案例一-太多份相同的对象导致-OOM"><a href="#案例一-太多份相同的对象导致-OOM" class="headerlink" title="案例一: 太多份相同的对象导致 OOM"></a>案例一: 太多份相同的对象导致 OOM</h3><ul><li>问题描述<br>有一个项目在内存中缓存了全量用户数据，在搜索用户时可以直接从缓存中返回用户信息。现在为了改善用户体验，需要实现输入部分用户名自动在下拉框提示补全用户名的功能（也就是所谓的自动完成功能）。<br>为了实现这个功能,我们需要一个HashMap来存放数据,Key是用户姓名索引,Value是索引下对应的用户列表;比如两个用户aa和ab,那么key就有3个,a,aa,ab;用户输入a的时候就能从a的value中拿到aa和ab.<br>在代码中，在数据库中存入 1 万个测试用户，用户名由 a~j 这 6 个字母随机构成，然后把每一个用户名的前 1 个字母、前 2 个字母以此类推直到完整用户名作为 Key 存入缓存中，缓存的 Value 是一个 UserDTO 的 List，存放的是所有相同的用户名索引，以及对应的用户信息<pre><code>//自动完成的索引，Key是用户输入的部分用户名，Value是对应的用户数据private ConcurrentHashMap&lt;String, List&lt;UserDTO&gt;&gt; autoCompleteIndex = new ConcurrentHashMap&lt;&gt;();</code></pre></li></ul><p>@Autowired<br>private UserRepository userRepository;</p><p>@PostConstruct<br>public void wrong() {<br>    //先保存10000个用户名随机的用户到数据库中<br>    userRepository.saveAll(LongStream.rangeClosed(1, 10000).mapToObj(i -&gt; new UserEntity(i, randomName())).collect(Collectors.toList()));</p><pre><code>//从数据库加载所有用户userRepository.findAll().forEach(userEntity -&gt; {    int len = userEntity.getName().length();    //对于每一个用户，对其用户名的前N位进行索引，N可能是1~6六种长度类型    for (int i = 0; i &lt; len; i++) {        String key = userEntity.getName().substring(0, i + 1);        autoCompleteIndex.computeIfAbsent(key, s -&gt; new ArrayList&lt;&gt;())                .add(new UserDTO(userEntity.getName()));    }});log.info(&quot;autoCompleteIndex size:{} count:{}&quot;, autoCompleteIndex.size(),        autoCompleteIndex.entrySet().stream().map(item -&gt; item.getValue().size()).reduce(0, Integer::sum));</code></pre><p>}<br>对于每一个用户对象 UserDTO，除了有用户名，我们还加入了 10K 左右的数据模拟其用户信息：</p><p>@Data<br>public class UserDTO {<br>    private String name;<br>    @EqualsAndHashCode.Exclude<br>    private String payload;</p><pre><code>public UserDTO(String name) {    this.name = name;    this.payload = IntStream.rangeClosed(1, 10_000)            .mapToObj(__ -&gt; &quot;a&quot;)            .collect(Collectors.joining(&quot;&quot;));}</code></pre><p>}</p><pre><code>运行程序后,从日志可以看到,一共有26838个索引;使用内存分析工具Mat打开堆dump发现,差不多占用了1.2GB的内存.可想而知,如果数据进一步增大,很容易就OOM了.  那么这个案例中,有个快捷的修复方法: 使用name作为HashSet的去重字段,先把UserDTO加入HashSet去重再添加索引.回顾一下,这次OOM最主要的问题就是我们虽然定义了数据总量,却忽略了每一份数据在内存中可能被创建了多次,这也提醒我们要慎用new字段,多多复用对象.  再举一个类似的例子,一个后台程序需要从数据库加载大量信息用于数据导出，这些数据在数据库中占用 100M 内存，但是 1GB 的 JVM 堆却无法完成导出操作, 原因就是100M的数据加载到内存中,变为Java数据结构就占用了200M堆内存,这些数据经过 JDBC、MyBatis 等框架其实是加载了 2 份，然后领域模型、DTO 再进行转换可能又加载了 2 次；最终，占用的内存达到了 200M*4=800M。因此,在进行容量评估时, 不能轻易的认为一份数据在内存中也是一份,需要做好容量的备份工作.## 案例二: 使用WeakHashMap 不等于不会OOM- 问题描述WeakHashMap的特点是, Key在哈希表内部是弱引用的,当没有强引用指向这个key的时候,entry会被GC,即使我们一直在往Map里塞数据,只要Key不再使用, 就不会OOM.  回顾一下Java中引用类型和垃圾回收之间的关系:1. GC不回收有强引用的对象;2. 内存充足时不回收有软引用的对象;3. GC只要扫描到了具有弱引用的对象就会回收.接下来我们声明一个Key是User类型, Value是UserProfile类型的WeakHashMap,作为用户数据缓存, 往其中添加200w个entry,然后用ScheduledThreadPoolExecutor发起一个定时任务,每一秒输出entry个数:</code></pre><p>private Map&lt;User, UserProfile&gt; cache = new WeakHashMap&lt;&gt;();</p><p>@GetMapping(“wrong”)<br>public void wrong() {<br>    String userName = “zhuye”;<br>    //间隔1秒定时输出缓存中的条目数<br>    Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(<br>            () -&gt; log.info(“cache size:{}”, cache.size()), 1, 1, TimeUnit.SECONDS);<br>    LongStream.rangeClosed(1, 2000000).forEach(i -&gt; {<br>        User user = new User(userName + i);<br>        cache.put(user, new UserProfile(user, “location” + i));<br>    });<br>}</p><pre><code>日志显示,这个map中的entry数量始终为200w, 即使手动GC也是如此.  进行堆转储之后可以看到,堆内存中有200w个UserProfile和User  但是我们并没有持有对key的引用呀,问题出在哪了呢?  我们来看一下这两个类的构造方法:</code></pre><p>@Data<br>@AllArgsConstructor<br>@NoArgsConstructor<br>class User {<br>    private String name;<br>}</p><p>@Data<br>@AllArgsConstructor<br>@NoArgsConstructor<br>public class UserProfile {<br>    private User user;<br>    private String location;<br>}</p><pre><code>可以看到, UserProfile这个类持有了User类的强引用, 而Entry又持有了对这个value的强引用, entry又被weakHashMap引用,最后导致key无法被回收.  有两个解决办法,一个是用WeakReference包装一下UserProfile,使其变成弱引用. 一个是在每次创建一个新的UserProfile对象的时候都new一个新的User出来, 从而解除强引用关系.  因此,如果真的有弱引用的需求, 可以使用ConcurrentReferenceHashMap来缓存, 这个Map的key和value同时被软引用或者弱引用包裹,也能解决互相引用的数据不能被释放的问题,同时还能保证线程安全.  ## 案例三: Tomcat参数配置不合理导致OOM- 问题描述之前有一个应用,在业务量大的情况下出现了假死,日志中有大量OOM异常, 通过MAT打开dump文件时, 我们发现有1.7GB的byte数组分配. 进一步查看引用发现,大部分都是Tomcat的工作线程,每个线程占用了10M的数组,这已经是非常大的了.  进一步分析,我们发现是Http11InputBuffer 和 Http11OutputBuffer的两个buffer分别占了10M, 那么为什么一个buffer会占用这么大呢?我们打开第一个inputBuffer的int方法来查看一下:</code></pre><p>void init(SocketWrapperBase&lt;?&gt; socketWrapper) {</p><pre><code>wrapper = socketWrapper;wrapper.setAppReadBufHandler(this);int bufLength = headerBufferSize +        wrapper.getSocketBufferHandler().getReadBuffer().capacity();if (byteBuffer == null || byteBuffer.capacity() &lt; bufLength) {    byteBuffer = ByteBuffer.allocate(bufLength);    byteBuffer.position(0).limit(0);}</code></pre><p>}</p><pre><code>后面一项的socket的读缓冲是固定的,所以问题就是headerBufferSize身上,向上继续定位初始化位置,发现是从配置中载入的MaxHttpHeaderSize.因此我们就知道,一定是同学把配置中的对应变量设的过大了.翻看了一下配置,果然如此,该同学之情是遇到了这个bug,上网随便搜了一下就改了参数,影响了整个系统的运行:</code></pre><p>server.max-http-header-size=10000000</p><p>java.lang.IllegalArgumentException: Request header is too large</p><pre><code>## 总结1. 为生产环境配置JVM参数启用详细的GC日志, 方便观察垃圾收集器的行为;2. 启动HeadDumpOnOutOfMemoryError, 以便在出现OOM时自动Dump,留下第一问题现场.</code></pre>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_15</title>
      <link href="/2021/01/27/java-kai-fa-chang-jian-cuo-wu-15/"/>
      <url>/2021/01/27/java-kai-fa-chang-jian-cuo-wu-15/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="15-序列化：一来一回你还是原来的你吗？"><a href="#15-序列化：一来一回你还是原来的你吗？" class="headerlink" title="15.序列化：一来一回你还是原来的你吗？"></a>15.序列化：一来一回你还是原来的你吗？</h2><h3 id="案例1-序列化和反序列化需要确保算法一致"><a href="#案例1-序列化和反序列化需要确保算法一致" class="headerlink" title="案例1: 序列化和反序列化需要确保算法一致"></a>案例1: 序列化和反序列化需要确保算法一致</h3><ul><li>问题描述<br>有一次要运维同学帮忙拉取所有Redis中的Key,结果他反馈Redis中存的Key都是乱码.<br>这个案例是基于RedisTemplate来做的,因为无需考虑连接池,还可以和Spring Cache等组件进行整合.<br>而一般数据要存入到Redis,需要经过序列化算法生成字符串,虽然Redis也支持Hash等多种数据结构,但是每一个field的value还是字符串.在value本身也是字符串的情况下,我们可以使用StringRedisTemplate.<br>我们先来介绍一下SRT和RT之间的区别,写一段测试代码,在应用初始化完成后向Redis设置两组数据.第一次使用 RedisTemplate 设置 Key 为 redisTemplate、Value 为 User 对象，第二次使用 StringRedisTemplate 设置 Key 为 stringRedisTemplate、Value 为 JSON 序列化后的 User 对象：<pre><code>@Autowiredprivate RedisTemplate redisTemplate;@Autowiredprivate StringRedisTemplate stringRedisTemplate;@Autowiredprivate ObjectMapper objectMapper;</code></pre></li></ul><p>@PostConstruct<br>public void init() throws JsonProcessingException {<br>    redisTemplate.opsForValue().set(“redisTemplate”, new User(“zhuye”, 36));<br>    stringRedisTemplate.opsForValue().set(“stringRedisTemplate”, objectMapper.writeValueAsString(new User(“zhuye”, 36)));<br>}</p><pre><code>然后我们使用redis-cli客户端工具连接到Redis, 你会发现根本没有redisTemplate的key.查询结果如下:![keys查询结果](https://s3.ax1x.com/2021/01/30/yFk10g.png)注意,srt的结果是正常的,但是rt的结果就是不正常的.  我们看下源码就会发现,srt实际上用的是string的序列化方式,但是rt用的是jdk的序列化方式.而srt是无法读取jdk的序列化方式的,反过来也一样.  修复的办法也非常简单,各自读各自的即可:</code></pre><p>//使用RedisTemplate获取Value，无需反序列化就可以拿到实际对象，虽然方便，但是Redis中保存的Key和Value不易读<br>User userFromRedisTemplate = (User) redisTemplate.opsForValue().get(“redisTemplate”);<br>log.info(“redisTemplate get {}”, userFromRedisTemplate);<br>//使用StringRedisTemplate，虽然Key正常，但是Value存取需要手动序列化成字符串<br>User userFromStringRedisTemplate = objectMapper.readValue(stringRedisTemplate.opsForValue().get(“stringRedisTemplate”), User.class);<br>log.info(“stringRedisTemplate get {}”, userFromStringRedisTemplate);</p><pre><code>但是这样依旧有个问题, srt虽然key是普通字符串,但是value的存取需要手动序列化成字符串;rt的key和value虽然容易获取,但是可读性比较差.如何解决呢?- 自定义rt的key和value的序列化方式Key 的序列化使用 RedisSerializer.string()（也就是 StringRedisSerializer 方式）实现字符串序列化，而 Value 的序列化使用 Jackson2JsonRedisSerializer</code></pre><p>@Bean<br>public <t> RedisTemplate&lt;String, T&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) {<br>    RedisTemplate&lt;String, T&gt; redisTemplate = new RedisTemplate&lt;&gt;();<br>    redisTemplate.setConnectionFactory(redisConnectionFactory);<br>    Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);<br>    redisTemplate.setKeySerializer(RedisSerializer.string());<br>    redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);<br>    redisTemplate.setHashKeySerializer(RedisSerializer.string());<br>    redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);<br>    redisTemplate.afterPropertiesSet();<br>    return redisTemplate;<br>}</t></p><pre><code>写代码测试一下存取:</code></pre><p>@Autowired<br>private RedisTemplate&lt;String, User&gt; userRedisTemplate;</p><p>@GetMapping(“right2”)<br>public void right2() {<br>    User user = new User(“zhuye”, 36);<br>    userRedisTemplate.opsForValue().set(user.getName(), user);<br>    Object userFromRedis = userRedisTemplate.opsForValue().get(user.getName());<br>    log.info(“userRedisTemplate get {} {}”, userFromRedis, userFromRedis.getClass());<br>    log.info(“stringRedisTemplate get {}”, stringRedisTemplate.opsForValue().get(user.getName()));<br>}</p><pre><code>日志如下:</code></pre><p>[14:07:41.315] [http-nio-45678-exec-1] [INFO ] [.t.c.s.demo1.RedisTemplateController:55  ] - userRedisTemplate get {name=zhuye, age=36} class java.util.LinkedHashMap<br>[14:07:41.318] [http-nio-45678-exec-1] [INFO ] [.t.c.s.demo1.RedisTemplateController:56  ] - stringRedisTemplate get {“name”:”zhuye”,”age”:36}</p><pre><code>乍一看好像没问题,能够正常访问了.  但是仔细一看,第一行日志显示,获取到的value类型是linkedhashMap,并不是我们设定的User类.这个问题的产生原因就是,反序列化时使用的源数据中缺失了序列化之前的对象的类型信息.修复方法也很简单,自定义 RestTemplate 的代码，把 new 出来的 Jackson2JsonRedisSerializer 设置一个自定义的 ObjectMapper，启用 activateDefaultTyping 方法把类型信息作为属性写入序列化后的数据中（当然了，你也可以调整 JsonTypeInfo.As 枚举以其他形式保存类型信息）：</code></pre><p>…<br>Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);<br>ObjectMapper objectMapper = new ObjectMapper();<br>//把类型信息作为属性写入Value<br>objectMapper.activateDefaultTyping(objectMapper.getPolymorphicTypeValidator(), ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);<br>jackson2JsonRedisSerializer.setObjectMapper(objectMapper);<br>…</p><p>或者直接使用 RedisSerializer.json() 快捷方法，它内部使用的 GenericJackson2JsonRedisSerializer 直接设置了把类型作为属性保存到 Value 中</p><p>redisTemplate.setKeySerializer(RedisSerializer.string());<br>redisTemplate.setValueSerializer(RedisSerializer.json());<br>redisTemplate.setHashKeySerializer(RedisSerializer.string());<br>redisTemplate.setHashValueSerializer(RedisSerializer.json());</p><pre><code>总结:- 默认情况下，RedisTemplate 使用 JdkSerializationRedisSerializer，也就是 JDK 序列化，容易产生 Redis 中保存了乱码的错觉。- 通常考虑到易读性，可以设置 Key 的序列化器为 StringRedisSerializer。但直接使用 RedisSerializer.string()，相当于使用了 UTF_8 编码的 StringRedisSerializer，需要注意字符集问题。- 如果希望 Value 也是使用 JSON 序列化的话，可以把 Value 序列化器设置为 Jackson2JsonRedisSerializer。默认情况下，不会把类型信息保存在 Value 中，即使我们定义 RedisTemplate 的 Value 泛型为实际类型，查询出的 Value 也只能是 LinkedHashMap 类型。如果希望直接获取真实的数据类型，你可以启用 Jackson ObjectMapper 的 activateDefaultTyping 方法，把类型信息一起序列化保存在 Value 中。- 如果希望 Value 以 JSON 保存并带上类型信息，更简单的方式是，直接使用 RedisSerializer.json() 快捷方法来获取序列化器。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_16</title>
      <link href="/2021/01/27/java-kai-fa-chang-jian-cuo-wu-16/"/>
      <url>/2021/01/27/java-kai-fa-chang-jian-cuo-wu-16/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="16-用好Java-8的日期时间类，少踩一些“老三样”的坑"><a href="#16-用好Java-8的日期时间类，少踩一些“老三样”的坑" class="headerlink" title="16. 用好Java 8的日期时间类，少踩一些“老三样”的坑"></a>16. 用好Java 8的日期时间类，少踩一些“老三样”的坑</h2><h3 id="案例一-初始化日期时间"><a href="#案例一-初始化日期时间" class="headerlink" title="案例一: 初始化日期时间"></a>案例一: 初始化日期时间</h3><ul><li>问题描述<br>先介绍一下常见的两种时间保存方式</li></ul><ol><li>使用UTC时间直接保存.UTC时间是原子钟毫秒数,默认时间起点是1970年1月1日.保存的时间没有时区概念,也就是我们常说的时间戳.是一种非常常见也极力推荐的用法.  </li><li>以字面量保存,一定要同时保存时区时间.通常用于给前端进行展示.<br>一个常见的问题就是时区不同导致对于同一个日期字符串,在不同的服务器上解析出不同的utc时间导致结果不一致.我们来看一个例子:<br>首先初始化上海、纽约和东京三个时区。我们可以使用 ZoneId.of 来初始化一个标准的时区，也可以使用 ZoneOffset.ofHours 通过一个 offset，来初始化一个具有指定时间差的自定义时区。对于日期时间表示，LocalDateTime 不带有时区属性，所以命名为本地时区的日期时间；而 ZonedDateTime=LocalDateTime+ZoneId，具有时区属性。因此，LocalDateTime 只能认为是一个时间表示，ZonedDateTime 才是一个有效的时间。在这里我们把 2020-01-02 22:00:00 这个时间表示，使用东京时区来解析得到一个 ZonedDateTime。使用 DateTimeFormatter 格式化时间的时候，可以直接通过 withZone 方法直接设置格式化使用的时区。最后，分别以上海、纽约和东京三个时区来格式化这个时间输出：<pre><code>//一个时间表示String stringDate = &quot;2020-01-02 22:00:00&quot;;//初始化三个时区ZoneId timeZoneSH = ZoneId.of(&quot;Asia/Shanghai&quot;);ZoneId timeZoneNY = ZoneId.of(&quot;America/New_York&quot;);ZoneId timeZoneJST = ZoneOffset.ofHours(9);//格式化器DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);ZonedDateTime date = ZonedDateTime.of(LocalDateTime.parse(stringDate, dateTimeFormatter), timeZoneJST);//使用DateTimeFormatter格式化时间，可以通过withZone方法直接设置格式化使用的时区DateTimeFormatter outputFormat = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss Z&quot;);System.out.println(timeZoneSH.getId() + outputFormat.withZone(timeZoneSH).format(date));System.out.println(timeZoneNY.getId() + outputFormat.withZone(timeZoneNY).format(date));System.out.println(timeZoneJST.getId() + outputFormat.withZone(timeZoneJST).format(date));</code></pre>总结下,对于国际化时间问题, 使用ZonedDateTime保存时间, 然后使用设置了ZonedId的DateTimeFormatter配合ZonedDateTime进行时间格式化得到本地时间表示.</li></ol><h3 id="案例二-错误使用大Y来进行时间格式化"><a href="#案例二-错误使用大Y来进行时间格式化" class="headerlink" title="案例二: 错误使用大Y来进行时间格式化"></a>案例二: 错误使用大Y来进行时间格式化</h3><ul><li>问题描述<br>初始化一个 Calendar，设置日期时间为 2019 年 12 月 29 日，使用大写的 YYYY 来初始化 SimpleDateFormat：<pre><code>Locale.setDefault(Locale.SIMPLIFIED_CHINESE);System.out.println(&quot;defaultLocale:&quot; + Locale.getDefault());Calendar calendar = Calendar.getInstance();calendar.set(2019, Calendar.DECEMBER, 29,0,0,0);SimpleDateFormat YYYY = new SimpleDateFormat(&quot;YYYY-MM-dd&quot;);System.out.println(&quot;格式化: &quot; + YYYY.format(calendar.getTime()));System.out.println(&quot;weekYear:&quot; + calendar.getWeekYear());System.out.println(&quot;firstDayOfWeek:&quot; + calendar.getFirstDayOfWeek());System.out.println(&quot;minimalDaysInFirstWeek:&quot; + calendar.getMinimalDaysInFirstWeek());</code></pre>得到的输出却是2020年:<pre><code>defaultLocale:zh_CN格式化: 2020-12-29weekYear:2020firstDayOfWeek:1minimalDaysInFirstWeek:1</code></pre></li></ul><p>问题就在于,小写的y代表的是公历年,而大写的Y是周年,是按照周日开始的完整7天在哪一年来判断的. 修复的办法就是把大写的Y换成小写y.<br>当然SimpleDateFormat还有两个著名的坑:</p><ol><li>static的SDF会出现线程安全问题.原因是SimpleDateFormat 继承了 DateFormat，DateFormat 有一个字段 Calendar；SimpleDateFormat 的 parse 方法调用 CalendarBuilder 的 establish 方法，来构建 Calendar；establish 方法内部先清空 Calendar 再构建 Calendar，整个操作没有加锁。显然，如果多线程池调用 parse 方法，也就意味着多线程在并发操作一个 Calendar，可能会产生一个线程还没来得及处理 Calendar 就被另一个线程清空了的情况<br>以下是源码:<pre><code>public abstract class DateFormat extends Format { protected Calendar calendar;}public class SimpleDateFormat extends DateFormat { @Override public Date parse(String text, ParsePosition pos) {     CalendarBuilder calb = new CalendarBuilder(); parsedDate = calb.establish(calendar).getTime();     return parsedDate; }}</code></pre></li></ol><p>class CalendarBuilder {<br>  Calendar establish(Calendar cal) {<br>         …<br>        cal.clear();//清空<br>        for (int stamp = MINIMUM_USER_STAMP; stamp &lt; nextStamp; stamp++) {<br>            for (int index = 0; index &lt;= maxFieldIndex; index++) {<br>                if (field[index] == stamp) {<br>                    cal.set(index, field[MAX_FIELD + index]);//构建<br>                    break;<br>                }<br>            }<br>        }<br>        return cal;<br>    }<br>}</p><pre><code>因此我们需要通过ThreadLocal来存放SimpleDateFormat:</code></pre><p>private static ThreadLocal<simpledateformat> threadSafeSimpleDateFormat = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(“yyyy-MM-dd HH:mm:ss”));</simpledateformat></p><pre><code>2. 当需要解析的字符串和格式不匹配的时候,SDF表现的很宽容.解决办法是每次都套用DateTimeFormatter,线程安全而且更加严格,如果解析出错会直接抛出.  ### 案例二: 日期时间的计算- 问题描述对于时间运算,新手比较喜欢用时间戳计算,比如: 希望得到当前时间之后 30 天的时间，会这么写代码：直接把 new Date().getTime 方法得到的时间戳加 30 天对应的毫秒数，也就是 30 天 *1000 毫秒 *3600 秒 *24 小时</code></pre><p>Date today = new Date();<br>Date nextMonth = new Date(today.getTime() + 30 <em> 1000 </em> 60 <em> 60 </em> 24);<br>System.out.println(today);<br>System.out.println(nextMonth);<br>但是日志输出并不对:<br>Sat Feb 01 14:17:41 CST 2020<br>Sun Jan 12 21:14:54 CST 2020</p><pre><code>这个问题是因为int发生了溢出,所以如果一定要用,把30改成30L,成为一个long型就可以了.  更好的一个办法是,使用Calendar,如下:</code></pre><p>Calendar c = Calendar.getInstance();<br>c.setTime(new Date());<br>c.add(Calendar.DAY_OF_MONTH, 30);<br>System.out.println(c.getTime());</p><pre><code>或者是使用LocalDateTime直接进行计算,</code></pre><p>LocalDateTime localDateTime = LocalDateTime.now();<br>System.out.println(localDateTime.plusDays(30));</p><pre><code>同时,LDT这个类对日期进行加减操作非常简单,比如如下就实现了加减操作:</code></pre><p>System.out.println(“//测试操作日期”);<br>System.out.println(LocalDate.now()<br>        .minus(Period.ofDays(1))<br>        .plus(1, ChronoUnit.DAYS)<br>        .minusMonths(1)<br>        .plus(Period.ofMonths(1)));</p><p>或者使用with操作进行快捷调节:<br>System.out.println(“//本月的第一天”);<br>System.out.println(LocalDate.now().with(TemporalAdjusters.firstDayOfMonth()));</p><p>或者使用with+lambda进行快捷操作:<br>System.out.println(LocalDate.now().with(temporal -&gt; temporal.plus(ThreadLocalRandom.current().nextInt(100), ChronoUnit.DAYS)));</p><p>System.out.println(“//今年的程序员日”);<br>System.out.println(LocalDate.now().with(TemporalAdjusters.firstDayOfYear()).plusDays(255));</p><p>System.out.println(“//今天之前的一个周六”);<br>System.out.println(LocalDate.now().with(TemporalAdjusters.previous(DayOfWeek.SATURDAY)));</p><p>System.out.println(“//本月最后一个工作日”);<br>System.out.println(LocalDate.now().with(TemporalAdjusters.lastInMonth(DayOfWeek.FRIDAY)));</p><pre><code>还有一个可能会踩到的坑就是,获取两个日期之间的天数,需要使用ChronoUnit.DAYS.between这个方法,而不是Period方法.  ### 思考题- 日期时间数据始终要保存到数据库中，MySQL 中有两种数据类型 datetime 和 timestamp 可以用来保存日期时间。你能说说它们的区别吗，它们是否包含时区信息呢？答: 区别就在于,datetime是保存年月日这种时间的,但是timestamp是保存utc换算当前时区的时间戳的.  </code></pre>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_14</title>
      <link href="/2021/01/21/java-kai-fa-chang-jian-cuo-wu-14/"/>
      <url>/2021/01/21/java-kai-fa-chang-jian-cuo-wu-14/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="14-文件IO：实现高效正确的文件读写并非易事"><a href="#14-文件IO：实现高效正确的文件读写并非易事" class="headerlink" title="14.文件IO：实现高效正确的文件读写并非易事"></a>14.文件IO：实现高效正确的文件读写并非易事</h2><h3 id="案例1-文件读写需要字符编码一致"><a href="#案例1-文件读写需要字符编码一致" class="headerlink" title="案例1: 文件读写需要字符编码一致"></a>案例1: 文件读写需要字符编码一致</h3><ul><li>问题描述</li></ul><p>一个项目需要读取三方的对账文件定时对账,原先是单机运行,后来为了提升性能使用双节点处理,新增节点在读取文件中中文的时候总是读取乱码.  </p><ul><li>问题分析</li></ul><p>我们先来模拟一下这个场景, 使用 GBK 编码把“你好 hi”写入一个名为 hello.txt 的文本文件，然后直接以字节数组形式读取文件内容，转换为十六进制字符串输出到日志中：</p><pre><code>Files.deleteIfExists(Paths.get(&quot;hello.txt&quot;));Files.write(Paths.get(&quot;hello.txt&quot;), &quot;你好hi&quot;.getBytes(Charset.forName(&quot;GBK&quot;)));log.info(&quot;bytes:{}&quot;, Hex.encodeHexString(Files.readAllBytes(Paths.get(&quot;hello.txt&quot;))).toUpperCase());</code></pre><p>我们打开文件,能看到你好hi,但是文字在计算机中是按照一定的规则将其以二进制形式保存的,这个规则就是字符集.字符集本身是一个kv结构,key是所有支持的字符,value是对应的二进制码.因此我们在文件读写的时候,如果是以字节层面操作,不需要涉及字符的编码问题;如果是在字符层面读写,就必须要明确字符的编码方式.</p><p>当时出现问题的文件读取代码是:</p><pre><code>char[] chars = new char[10];String content = &quot;&quot;;try (FileReader fileReader = new FileReader(&quot;hello.txt&quot;)) {    int count;    while ((count = fileReader.read(chars)) != -1) {        content += new String(chars, 0, count);    }}log.info(&quot;result:{}&quot;, content);</code></pre><p>很明显,是调用了fileReader类以字符的方式进行的文件读取,但是没有指定字符集,所以读出来的你好变成了乱码.在默认情况下,FileReader是以当前机器的默认字符集来读取文件的.如果希望指定字符集的话,需要直接使用InputStreamReader和FileInputStream.<br>修复后的代码如下:</p><pre><code>private static void right1() throws IOException {    char[] chars = new char[10];    String content = &quot;&quot;;    try (FileInputStream fileInputStream = new FileInputStream(&quot;hello.txt&quot;);        InputStreamReader inputStreamReader = new InputStreamReader(fileInputStream, Charset.forName(&quot;GBK&quot;))) {        int count;        while ((count = inputStreamReader.read(chars)) != -1) {            content += new String(chars, 0, count);        }    }    log.info(&quot;result: {}&quot;, content);}</code></pre><h3 id="案例二-使用Files类静态方法进行文件操作注意释放文件句柄"><a href="#案例二-使用Files类静态方法进行文件操作注意释放文件句柄" class="headerlink" title="案例二: 使用Files类静态方法进行文件操作注意释放文件句柄"></a>案例二: 使用Files类静态方法进行文件操作注意释放文件句柄</h3><ul><li>问题描述</li></ul><p>在读取文件的时候,我们有两种读取方法,一种是使用Files的readAllLines方法,这个方法返回的是一个<code>List&lt;String&gt;</code>,本质是一次性把整个文件读取到内存中,所以存在OOM的风险;<br>第二种是Files的lines方法,这个方法返回的是<code>Stream&lt;String&gt;</code>,这个方法使得我们在使用的时候可以一边读取一边使用.<br>看起来第二种方法十分的好用,但是使用中经常会出现一个被忽略的问题,没有及时的释放文件句柄.<br>解决的办法也很简单,所有调用lines等stream流的方法都在try中调用,这是一种try-with-resource的语法,可以自动的关闭文件,释放文件句柄.<br>下面是lines方法的源码,我们来看一看他是怎么实现高效读写的:</p><pre><code>public static Stream&lt;String&gt; lines(Path path, Charset cs) throws IOException {    BufferedReader br = Files.newBufferedReader(path, cs);    try {        return br.lines().onClose(asUncheckedRunnable(br));    } catch (Error|RuntimeException e) {        try {            br.close();        } catch (IOException ex) {            try {                e.addSuppressed(ex);            } catch (Throwable ignore) {}        }        throw e;    }}private static Runnable asUncheckedRunnable(Closeable c) {    return () -&gt; {        try {            c.close();        } catch (IOException e) {            throw new UncheckedIOException(e);        }    };}</code></pre><p>从上面的代码中我们可以看出来,lines方法实际上注册了一个回调函数来关闭缓冲区,这里的缓冲区实际上就是每次把一部分的数据提前加载到内存中,从而大量减少IO次数,提高吞吐量.<br>除了缓存区,还有一种更快的方法,在高版本的UNIX和Linux操作系统上往往已经实现了DMA,也就是直接内存访问, 数据从磁盘经过总线直接发送到目标文件，无需经过内存和 CPU 进行数据中转.<br>在Java中使用FileChannel类的transferTo方法进行流的复制就是DMA操作,如下:</p><pre><code>private static void fileChannelOperation() throws IOException {    FileChannel in = FileChannel.open(Paths.get(&quot;src.txt&quot;), StandardOpenOption.READ);    FileChannel out = FileChannel.open(Paths.get(&quot;dest.txt&quot;), CREATE, WRITE);    in.transferTo(0, in.size(), out);}</code></pre><p>这种方法相比于之前的不加缓存区大概快了3600倍左右.一个小的引申, Kafka的吞吐量大其实就是基于批处理的思想以及零拷贝.<br>批处理: Kafka往往不是消息来了立刻发送,而是攒一波之后一起发送,这样对于吞吐量有极大的提升,但是对于需要实时处理的一些场景就不是非常的有效了.<br>零拷贝: Kafka避免了从内存态到内核态以及网络的拷贝,直接读取文件发送给网络,减少了用户态到核心态的拷贝.  </p><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><ol><li><p>Files.lines 方法进行流式处理，需要使用 try-with-resources 进行资源释放。那么，使用 Files 类中其他返回 Stream 包装对象的方法进行流式处理，比如 newDirectoryStream 方法返回 DirectoryStream，list、walk 和 find 方法返回 Stream，也同样有资源释放问题吗？<br>是需要手动关闭的,Files相关文档提到说: When not using the try-with-resources construct, then directory stream’s close method should be invoked after iteration is completed so as to free any resources held for the open directory.</p></li><li><p>Java 的 File 类和 Files 类提供的文件复制、重命名、删除等操作，是原子性的吗？<br>否.文件操作实际上是调度操作系统的文件系统操作的,所以保持原子性没有什么意义,不如直接依赖于文件系统进行原子性保证.  </p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_13</title>
      <link href="/2021/01/18/java-kai-fa-chang-jian-cuo-wu-13/"/>
      <url>/2021/01/18/java-kai-fa-chang-jian-cuo-wu-13/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><h2 id="13-日志：日志记录真没你想象的那么简单"><a href="#13-日志：日志记录真没你想象的那么简单" class="headerlink" title="13.日志：日志记录真没你想象的那么简单"></a>13.日志：日志记录真没你想象的那么简单</h2><h3 id="案例1-为什么我的日志会重复记录"><a href="#案例1-为什么我的日志会重复记录" class="headerlink" title="案例1: 为什么我的日志会重复记录?"></a>案例1: 为什么我的日志会重复记录?</h3><ul><li>问题描述</li></ul><p>Java的日志框架非常多,包含但不限于: Logback、Log4j、Log4j2、commons-logging、JDK 自带的 java.util.logging 等.而且每个日志框架的配置文件非常复杂.<br>那么为了适配这些所有的日志结构,我们引入了SLF4J(Simple Logging Facade For Java),对于spring来说,spring boot默认引入了logback.<br>那么日志为什么会重复呢?主要有以下几个常见的原因:</p><ol><li><p>logger配置继承关系导致日志重复记录.<br>先定义一个方法实现debug,info,warn,error四种日志的记录</p><pre><code>@Log4j2@RequestMapping(&quot;logging&quot;)@RestControllerpublic class LoggingController { @GetMapping(&quot;log&quot;) public void log() {     log.debug(&quot;debug&quot;);     log.info(&quot;info&quot;);     log.warn(&quot;warn&quot;);     log.error(&quot;error&quot;); }}</code></pre><p>然后使用下面的Logback配置:</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;configuration&gt; &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;     &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;         &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;     &lt;/layout&gt; &lt;/appender&gt; &lt;logger name=&quot;org.geekbang.time.commonmistakes.logging&quot; level=&quot;DEBUG&quot;&gt;     &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;INFO&quot;&gt;     &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt;</code></pre><p>第 3 到 7 行，首先将 CONSOLE Appender 定义为 ConsoleAppender，也就是把日志输出到控制台（System.out/System.err）；然后通过 PatternLayout 定义了日志的输出格式。关于格式化字符串的各种使用方式，你可以进一步查阅官方文档。第 8 到 10 行实现了一个 Logger 配置，将应用包的日志级别设置为 DEBUG、日志输出同样使用 CONSOLE Appender; 第 11 和 12 行设置了全局的日志级别为 INFO，日志输出使用 CONSOLE Appender。<br>这段配置看起来没问题,但是使用之后出现了重复记录的问题,原因就是我们自己定义的logger实际上是继承自root的,而我们把console重复挂载了两次.<br>如果一定要单独自定义一个logger,我们可以把logger的additivity属性改为false,这样就不会继承了.</p></li><li><p>错误配置LevelFilter导致重复.<br>一般互联网公司都会使用ELK三件套来统一收集日志,使用Kibana展示日志结果,使用Logstash收集数据,使用es当做数据索引.<br>我们先看一个logback的配置:</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;configuration&gt;&lt;property name=&quot;logDir&quot; value=&quot;./logs&quot; /&gt;&lt;property name=&quot;app.name&quot; value=&quot;common-mistakes&quot; /&gt;&lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;   &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;      &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;   &lt;/layout&gt;&lt;/appender&gt;&lt;appender name=&quot;INFO_FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt;   &lt;File&gt;${logDir}/${app.name}_info.log&lt;/File&gt;   &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;      &lt;level&gt;INFO&lt;/level&gt;   &lt;/filter&gt;   &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;      &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;      &lt;charset&gt;UTF-8&lt;/charset&gt;   &lt;/encoder&gt;&lt;/appender&gt;&lt;appender name=&quot;ERROR_FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt;   &lt;File&gt;${logDir}/${app.name}_error.log&lt;/File&gt;   &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;      &lt;level&gt;WARN&lt;/level&gt;   &lt;/filter&gt;   &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;      &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;      &lt;charset&gt;UTF-8&lt;/charset&gt;   &lt;/encoder&gt;&lt;/appender&gt;&lt;root level=&quot;INFO&quot;&gt;   &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt;   &lt;appender-ref ref=&quot;INFO_FILE&quot;/&gt;   &lt;appender-ref ref=&quot;ERROR_FILE&quot;/&gt;&lt;/root&gt;&lt;/configuration&gt;</code></pre></li></ol><p>老师给出了这段配置的官方解答: 第 31 到 35 行定义的 root 引用了三个 Appender。第 5 到 9 行是第一个 ConsoleAppender，用于把所有日志输出到控制台。第 10 到 19 行定义了一个 FileAppender，用于记录文件日志，并定义了文件名、记录日志的格式和编码等信息。最关键的是，第 12 到 14 行定义的 LevelFilter 过滤日志，将过滤级别设置为 INFO，目的是希望 _info.log 文件中可以记录 INFO 级别的日志。第 20 到 30 行定义了一个类似的 FileAppender，并使用 ThresholdFilter 来过滤日志，过滤级别设置为 WARN，目的是把 WARN 以上级别的日志记录到另一个 _error.log 文件中。</p><p>但是运行结果显示,info.log中包含了info,warn,error级别的日志,error.log包含了warn和error两个级别的日志,可见我们的过滤配置并没有生效.  </p><p>原因其实也很简单,我们可以先介绍一下不同的filter,对于ThresholdFilter,当日志级别大于配置级别时继续调用过滤链上的下一个过滤器,否则直接拒绝记录日志;对于LevelFilter,如果是匹配就调用onMatch定义的处理方式,默认是交给下一个过滤器处理,否则,调用onMismatch的处理方式,默认也是交给下一个级别处理;<br>因此本例的错误原因就是LevelFilter只配置了level,没有配置onMatch或者onMismatch,过滤器失效了.<br>修复的办法也很简单,onMatch为accept,onMismatch为Deny,具体如下:</p><pre><code>&lt;appender name=&quot;INFO_FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt;  &lt;File&gt;${logDir}/${app.name}_info.log&lt;/File&gt;  &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;    &lt;level&gt;INFO&lt;/level&gt;    &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;    &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;  &lt;/filter&gt;  ...&lt;/appender&gt;</code></pre><h3 id="案例2-使用异步日志改善性能的坑"><a href="#案例2-使用异步日志改善性能的坑" class="headerlink" title="案例2: 使用异步日志改善性能的坑"></a>案例2: 使用异步日志改善性能的坑</h3><ul><li>问题描述</li></ul><p>在加入日志记录到文件的配置之后,我们必须要考虑避免日志记录成为应用的性能瓶颈.<br>这里先使用老师的测试代码来复现一下日志的性能问题,FILE是一个FileAppender,用于记录所有的日志;CONSOLE是一个ConsoleAppender,用于记录带time标记的日志.</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;configuration&gt;    &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt;        &lt;file&gt;app.log&lt;/file&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;            &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;        &lt;/layout&gt;        &lt;filter class=&quot;ch.qos.logback.core.filter.EvaluatorFilter&quot;&gt;            &lt;evaluator class=&quot;ch.qos.logback.classic.boolex.OnMarkerEvaluator&quot;&gt;                &lt;marker&gt;time&lt;/marker&gt;            &lt;/evaluator&gt;            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;        &lt;/filter&gt;    &lt;/appender&gt;    &lt;root level=&quot;INFO&quot;&gt;        &lt;appender-ref ref=&quot;FILE&quot;/&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;@GetMapping(&quot;performance&quot;)public void performance(@RequestParam(name = &quot;count&quot;, defaultValue = &quot;1000&quot;) int count) {    long begin = System.currentTimeMillis();    String payload = IntStream.rangeClosed(1, 1000000)            .mapToObj(__ -&gt; &quot;a&quot;)            .collect(Collectors.joining(&quot;&quot;)) + UUID.randomUUID().toString();    IntStream.rangeClosed(1, count).forEach(i -&gt; log.info(&quot;{} {}&quot;, i, payload));    Marker timeMarker = MarkerFactory.getMarker(&quot;time&quot;);    log.info(timeMarker, &quot;took {} ms&quot;, System.currentTimeMillis() - begin);}</code></pre><p>但是结果不太理想,我们会发现记录1000次日志耗时6.3秒,为什么会这么慢呢?<br>我们看下FileAppender的源码:</p><pre><code>public class OutputStreamAppender&lt;E&gt; extends UnsynchronizedAppenderBase&lt;E&gt; {  private OutputStream outputStream;  boolean immediateFlush = true;  @Override    protected void append(E eventObject) {        if (!isStarted()) {            return;        }        subAppend(eventObject);    }    protected void subAppend(E event) {        if (!isStarted()) {            return;        }        try {            //编码LoggingEvent            byte[] byteArray = this.encoder.encode(event);            //写字节流            writeBytes(byteArray);        } catch (IOException ioe) {            ...        }    }    private void writeBytes(byte[] byteArray) throws IOException {        if(byteArray == null || byteArray.length == 0)            return;        lock.lock();        try {            //这个OutputStream其实是一个ResilientFileOutputStream，其内部使用的是带缓冲的BufferedOutputStream            this.outputStream.write(byteArray);            if (immediateFlush) {                this.outputStream.flush();//刷入OS            }        } finally {            lock.unlock();        }    }}</code></pre><p>第30到33行,我们是直接把数据写入到outputstream,所以是同步写入的,所以会很慢.<br>但是实际上,记录日志和业务流程并没有什么关系,完全没必要同步写入,我们可以使用logback提供的AsyncAppender来包装一下原有的.</p><pre><code>&lt;appender name=&quot;ASYNCFILE&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt;    &lt;appender-ref ref=&quot;FILE&quot;/&gt;&lt;/appender&gt;&lt;root level=&quot;INFO&quot;&gt;    &lt;appender-ref ref=&quot;ASYNCFILE&quot;/&gt;    &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;&lt;/root&gt;</code></pre><p>测试一下发现,1000次日志压缩到了735毫秒!历史的进步!<br>但是事实真的如此吗?并不是,异步并没有记录下所有的日志.老师在课程中总结了三类异步的坑:</p><ol><li>记录异步日志撑爆内存；</li><li>记录异步日志出现日志丢失；</li><li>记录异步日志出现阻塞。<br>为了解释这三种坑,我们来模拟一个慢日志记录场景: 自定义一个继承自 ConsoleAppender 的 MySlowAppender，作为记录到控制台的输出器，写入日志时休眠 1 秒。<pre><code>public class MySlowAppender extends ConsoleAppender { @Override protected void subAppend(Object event) {     try {         // 模拟慢日志         TimeUnit.MILLISECONDS.sleep(1);     } catch (InterruptedException e) {         e.printStackTrace();     }     super.subAppend(event); }}</code></pre>然后，在配置文件中使用 AsyncAppender，将 MySlowAppender 包装为异步日志记录：<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;configuration&gt;&lt;appender name=&quot;CONSOLE&quot; class=&quot;org.geekbang.time.commonmistakes.logging.async.MySlowAppender&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;         &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt; &lt;/layout&gt;&lt;/appender&gt;&lt;appender name=&quot;ASYNC&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt;&lt;/appender&gt;&lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;ASYNC&quot; /&gt;&lt;/root&gt;&lt;/configuration&gt;</code></pre></li></ol><p>再定义一段测试代码,循环记录一定次数的日志,最后输出方法执行耗时:</p><pre><code>@GetMapping(&quot;manylog&quot;)public void manylog(@RequestParam(name = &quot;count&quot;, defaultValue = &quot;1000&quot;) int count) {    long begin = System.currentTimeMillis();    IntStream.rangeClosed(1, count).forEach(i -&gt; log.info(&quot;log-{}&quot;, i));    System.out.println(&quot;took &quot; + (System.currentTimeMillis() - begin) + &quot; ms&quot;);}</code></pre><p>查看结果可以发现,耗时很短但出现了日志丢失：我们要记录 1000 条日志，最终控制台只能搜索到 215 条日志，而且日志的行号变为了一个问号。<br>出现这个问题的原因在于,AsyncAppender提供了一些配置参数,但是我们没配置:</p><ol><li><p>includeCallerData 用于控制是否收集调用方数据，默认是 false，此时方法行号、方法名等信息将不能显示（源码第 2 行以及 7 到 11 行）。</p></li><li><p>queueSize 用于控制阻塞队列大小，使用的 ArrayBlockingQueue 阻塞队列（源码第 15 到 17 行），默认大小是 256，即内存中最多保存 256 条日志。</p></li><li><p>discardingThreshold 是控制丢弃日志的阈值，主要是防止队列满后阻塞。默认情况下，队列剩余量低于队列长度的 20%，就会丢弃 TRACE、DEBUG 和 INFO 级别的日志。（参见源码第 3 到 6 行、18 到 19 行、26 到 27 行、33 到 34 行、40 到 42 行）</p></li><li><p>neverBlock 用于控制队列满的时候，加入的数据是否直接丢弃，不会阻塞等待，默认是 false（源码第 44 到 68 行）。这里需要注意一下 offer 方法和 put 方法的区别，当队列满的时候 offer 方法不阻塞，而 put 方法会阻塞；neverBlock 为 true 时，使用 offer 方法。</p><pre><code>public class AsyncAppender extends AsyncAppenderBase&lt;ILoggingEvent&gt; { boolean includeCallerData = false;//是否收集调用方数据 protected boolean isDiscardable(ILoggingEvent event) {     Level level = event.getLevel();     return level.toInt() &lt;= Level.INFO_INT;//丢弃&lt;=INFO级别的日志 } protected void preprocess(ILoggingEvent eventObject) {     eventObject.prepareForDeferredProcessing();     if (includeCallerData)         eventObject.getCallerData(); }}public class AsyncAppenderBase&lt;E&gt; extends UnsynchronizedAppenderBase&lt;E&gt; implements AppenderAttachable&lt;E&gt; { BlockingQueue&lt;E&gt; blockingQueue;//异步日志的关键，阻塞队列 public static final int DEFAULT_QUEUE_SIZE = 256;//默认队列大小 int queueSize = DEFAULT_QUEUE_SIZE; static final int UNDEFINED = -1; int discardingThreshold = UNDEFINED; boolean neverBlock = false;//控制队列满的时候加入数据时是否直接丢弃，不会阻塞等待 @Override public void start() {      ...     blockingQueue = new ArrayBlockingQueue&lt;E&gt;(queueSize);     if (discardingThreshold == UNDEFINED)         discardingThreshold = queueSize / 5;//默认丢弃阈值是队列剩余量低于队列长度的20%，参见isQueueBelowDiscardingThreshold方法     ... } @Override protected void append(E eventObject) {     if (isQueueBelowDiscardingThreshold() &amp;&amp; isDiscardable(eventObject)) { //判断是否可以丢数据         return;     }     preprocess(eventObject);     put(eventObject); } private boolean isQueueBelowDiscardingThreshold() {     return (blockingQueue.remainingCapacity() &lt; discardingThreshold); } private void put(E eventObject) {     if (neverBlock) { //根据neverBlock决定使用不阻塞的offer还是阻塞的put方法         blockingQueue.offer(eventObject);     } else {         putUninterruptibly(eventObject);     } } //以阻塞方式添加数据到队列 private void putUninterruptibly(E eventObject) {     boolean interrupted = false;     try {         while (true) {             try {                 blockingQueue.put(eventObject);                 break;             } catch (InterruptedException e) {                 interrupted = true;             }         }     } finally {         if (interrupted) {             Thread.currentThread().interrupt();         }     } }}  </code></pre></li></ol><p>继续来分析出现坑的原因:</p><ol><li>queueSize 设置得特别大，就可能会导致 OOM。</li><li>queueSize 设置得比较小（默认值就非常小），且 discardingThreshold 设置为大于 0 的值（或者为默认值），队列剩余容量少于 discardingThreshold 的配置就会丢弃 &lt;=INFO 的日志。这里的坑点有两个。一是，因为 discardingThreshold 的存在，设置 queueSize 时容易踩坑。比如，本例中最大日志并发是 1000，即便设置 queueSize 为 1000 同样会导致日志丢失。二是，discardingThreshold 参数容易有歧义，它不是百分比，而是日志条数。对于总容量 10000 的队列，如果希望队列剩余容量少于 1000 条的时候丢弃，需要配置为 1000。</li><li>neverBlock 默认为 false，意味着总可能会出现阻塞。如果 discardingThreshold 为 0，那么队列满时再有日志写入就会阻塞；如果 discardingThreshold 不为 0，也只会丢弃 &lt;=INFO 级别的日志，那么出现大量错误日志时，还是会阻塞程序。</li></ol><p>因此我们总结3点:</p><ol><li>如果考虑性能为先,更强调绝不阻塞,就设置neverBlock为true.</li><li>如果考虑绝对不丢数据,就把discardingThreshold设置为0,把queueSize设置的大一些</li><li>也可以折中,根据业务去权衡.</li></ol><h3 id="案例3-使用日志占位符就不需要进行日志级别判断了？"><a href="#案例3-使用日志占位符就不需要进行日志级别判断了？" class="headerlink" title="案例3: 使用日志占位符就不需要进行日志级别判断了？"></a>案例3: 使用日志占位符就不需要进行日志级别判断了？</h3><ul><li>问题描述</li></ul><p>有这么一种传言: SLF4J 的{}占位符语法，到真正记录日志时才会获取实际参数，因此解决了日志数据获取的性能问题。这句话对吗?<br>我们来写一个slowString方法来测试一下,返回结果耗时1秒</p><pre><code>private String slowString(String s) {    System.out.println(&quot;slowString called via &quot; + s);    try {        TimeUnit.SECONDS.sleep(1);    } catch (InterruptedException e) {    }    return &quot;OK&quot;;}</code></pre><p>如果我们记录 DEBUG 日志，并设置只记录 &gt;=INFO 级别的日志，程序是否也会耗时 1 秒呢？我们使用三种方法来测试：拼接字符串方式记录 slowString；使用占位符方式记录 slowString；先判断日志级别是否启用 DEBUG。</p><pre><code>StopWatch stopWatch = new StopWatch();stopWatch.start(&quot;debug1&quot;);log.debug(&quot;debug1:&quot; + slowString(&quot;debug1&quot;));stopWatch.stop();stopWatch.start(&quot;debug2&quot;);log.debug(&quot;debug2:{}&quot;, slowString(&quot;debug2&quot;));stopWatch.stop();stopWatch.start(&quot;debug3&quot;);if (log.isDebugEnabled())    log.debug(&quot;debug3:{}&quot;, slowString(&quot;debug3&quot;));stopWatch.stop();</code></pre><p>结果是前两种方法都调用了,所以耗时都是1秒.所以使用<code>{}</code>占位符是不能延迟参数内容获取的.<br>正确的做法是使用一个lambda表达式,借助lambda表达式自带的延迟参数获取机制来优化性能.但是slf4j目前不支持lambda,所以需要把注解替换为@log4j2注解,这时候再调用debug方法就可以了,因为debug方法的第二个参数签名是<code>Supplier&lt;?&gt;</code></p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_12</title>
      <link href="/2021/01/16/java-kai-fa-chang-jian-cuo-wu-12/"/>
      <url>/2021/01/16/java-kai-fa-chang-jian-cuo-wu-12/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="12-异常处理：别让自己在出问题的时候变为瞎子"><a href="#12-异常处理：别让自己在出问题的时候变为瞎子" class="headerlink" title="12.异常处理：别让自己在出问题的时候变为瞎子"></a>12.异常处理：别让自己在出问题的时候变为瞎子</h2><h3 id="案例1-统一异常处理"><a href="#案例1-统一异常处理" class="headerlink" title="案例1: 统一异常处理"></a>案例1: 统一异常处理</h3><ul><li>问题描述</li></ul><p>后端开发新人在刚接触工作时,往往会有一个习惯,就是不加try…catch代码块,然后在测试的时候就会被NPE折磨的不能自已;<br>之后就会在所有写了函数的地方都加上try-catch,这样虽然没错,但是会是一种非常偷懒的做法,在真正出现问题的时候,往往很难快速找到对应的异常点,而且对于代码能力的提高很有害.<br>最好的做法是,在编码层面上注意哪里会抛异常,只在对应的范围内包裹try…catch,并且给每个异常都添加独有的异常message,把传入参数也一同打印在日志中.  </p><p>我们再来看看大多数应用的三层架构:<br>Controller-Service-Repository<br>一般在Repository是不允许出现异常的,有异常最好抛出到service层;在Service层对不同的业务异常进行流程跳转,看是走到不同的分支还是进行降级熔断操作;如果异常被抛出到了Controller层,那么就应该包装成可以解读的返回语句并返回错误码,进行兜底操作.</p><p>比如下面这个代码的做法就非常标准:</p><pre><code>@RestControllerAdvice@Slf4jpublic class RestControllerExceptionHandler {    private static int GENERIC_SERVER_ERROR_CODE = 2000;    private static String GENERIC_SERVER_ERROR_MESSAGE = &quot;服务器忙，请稍后再试&quot;;    @ExceptionHandler    public APIResponse handle(HttpServletRequest req, HandlerMethod method, Exception ex) {        if (ex instanceof BusinessException) {            BusinessException exception = (BusinessException) ex;            log.warn(String.format(&quot;访问 %s -&gt; %s 出现业务异常！&quot;, req.getRequestURI(), method.toString()), ex);            return new APIResponse(false, null, exception.getCode(), exception.getMessage());        } else {            log.error(String.format(&quot;访问 %s -&gt; %s 出现系统异常！&quot;, req.getRequestURI(), method.toString()), ex);            return new APIResponse(false, null, GENERIC_SERVER_ERROR_CODE, GENERIC_SERVER_ERROR_MESSAGE);        }    }}</code></pre><h3 id="案例二-捕获了异常后直接生吞"><a href="#案例二-捕获了异常后直接生吞" class="headerlink" title="案例二: 捕获了异常后直接生吞."></a>案例二: 捕获了异常后直接生吞.</h3><ul><li>问题描述</li></ul><p>任何时候,捕获了异常都必须要加一条日志或者是进行其他的处理,绝对不能生吞.<br>因为这样的异常一旦导致了bug,就很难在程序中找到蛛丝马迹</p><h3 id="案例三-丢弃异常的原始信息"><a href="#案例三-丢弃异常的原始信息" class="headerlink" title="案例三: 丢弃异常的原始信息."></a>案例三: 丢弃异常的原始信息.</h3><ul><li>问题描述</li></ul><p>当捕获一个异常时,最好不要随意转换异常,否则会无法得知异常的原始抛出点,导致无法排查.</p><pre><code>@GetMapping(&quot;wrong1&quot;)public void wrong1(){    try {        readFile();    } catch (IOException e) {        //原始异常信息丢失          throw new RuntimeException(&quot;系统忙请稍后再试&quot;);    }}</code></pre><p>比如这个例子,我们查看日志只能知道我们异常是个RuntimeException,但是最开始是在哪抛出来的就不知道了.<br>最好的方式如下:</p><pre><code>catch (IOException e) {    log.error(&quot;文件读取错误&quot;, e);    throw new RuntimeException(&quot;系统忙请稍后再试&quot;);}或者把原始的异常作为转换后新异常的cause,异常信息同样不会丢失catch (IOException e) {    throw new RuntimeException(&quot;系统忙请稍后再试&quot;, e);}</code></pre><h3 id="案例四-抛出异常时不指定任何消息"><a href="#案例四-抛出异常时不指定任何消息" class="headerlink" title="案例四: 抛出异常时不指定任何消息."></a>案例四: 抛出异常时不指定任何消息.</h3><ul><li>问题描述</li></ul><p>比如下面这个偷懒同学的做法:</p><pre><code>throw new RuntimeException();这个异常在被拦截之后,产生了这样的日志[13:25:18.031] [http-nio-45678-exec-3] [ERROR] [c.e.d.RestControllerExceptionHandler:24  ] - 访问 /handleexception/wrong3 -&gt; org.geekbang.time.commonmistakes.exception.demo1.HandleExceptionController#wrong3(String) 出现系统异常！java.lang.RuntimeException: null...</code></pre><p>看到这个null,当时以为是空指针,排查了半天,结果发现其实是异常的message为空.  </p><p>一般来说,如果捕获了异常,除了使用日志来记录以外,通常还有三种处理模式:</p><ol><li>转换,转换为一个新的异常抛出,带上具体的信息</li><li>重试,即过一段时间重试,常见于远程调用</li><li>回复,即使用默认值来代替原始数据.</li></ol><h3 id="案例五-小心finally中的异常"><a href="#案例五-小心finally中的异常" class="headerlink" title="案例五: 小心finally中的异常"></a>案例五: 小心finally中的异常</h3><ul><li>问题描述</li></ul><p>一般来说,我们在finally代码块中执行释放资源等操作,有时我们会跳过catch代码块.<br>那么如果finally和try中都抛出了异常,会怎么办呢?</p><pre><code>@GetMapping(&quot;wrong&quot;)public void wrong() {    try {        log.info(&quot;try&quot;);        //异常丢失        throw new RuntimeException(&quot;try&quot;);    } finally {        log.info(&quot;finally&quot;);        throw new RuntimeException(&quot;finally&quot;);    }}</code></pre><p>最后在日志中只出现了finally的异常,try中的就被覆盖了,这其实是非常危险的一个举措,会导致try中的异常无法被正确定位到,也就是被吞了,因为一个方法只能抛出一个异常.<br>解决的办法也很简单,finally中自己包含异常的处理,或者是try中的异常作为主异常,使用addSuppressed方法把finally中的异常附加到主异常上:</p><pre><code>@GetMapping(&quot;right&quot;)public void right() {    try {        log.info(&quot;try&quot;);        throw new RuntimeException(&quot;try&quot;);    } finally {        log.info(&quot;finally&quot;);        try {            throw new RuntimeException(&quot;finally&quot;);        } catch (Exception ex) {            log.error(&quot;finally&quot;, ex);        }    }}@GetMapping(&quot;right2&quot;)public void right2() throws Exception {    Exception e = null;    try {        log.info(&quot;try&quot;);        throw new RuntimeException(&quot;try&quot;);    } catch (Exception ex) {        e = ex;    } finally {        log.info(&quot;finally&quot;);        try {            throw new RuntimeException(&quot;finally&quot;);        } catch (Exception ex) {            if (e!= null) {                e.addSuppressed(ex);            } else {                e = ex;            }        }    }    throw e;}</code></pre><p>第二种做法其实就是try-with-resource语句的做法,对于实现了AutoCloseable接口的资源,建议使用try-with-resources语句来释放,可以把try和finally中的异常信息都保留下来. </p><h3 id="案例六-把异常定义为常量"><a href="#案例六-把异常定义为常量" class="headerlink" title="案例六: 把异常定义为常量"></a>案例六: 把异常定义为常量</h3><ul><li>问题描述</li></ul><p>某救火排查项目生产问题的时候,出现了一个非常诡异的事情:<br>异常堆信息显示的方法调用路径，在当前入参的情况下根本不可能产生，项目的业务逻辑又很复杂，就始终没往异常信息是错的这方面想，总觉得是因为某个分支流程导致业务没有按照期望的流程进行。<br>最后发现,是因为实习生把异常定义为了静态变量,进而把异常信息固化, 这就和异常的栈一定要根据当前调用来动态获取冲突了.  </p><p>解决的办法很简单,通过不同的方法把每一种异常都new出来抛出即可.</p><pre><code>public class Exceptions {    public static BusinessException orderExists(){        return new BusinessException(&quot;订单已经存在&quot;, 3001);    }}</code></pre><h3 id="案例七-提交线程池的任务出了异常直接抛出"><a href="#案例七-提交线程池的任务出了异常直接抛出" class="headerlink" title="案例七: 提交线程池的任务出了异常直接抛出"></a>案例七: 提交线程池的任务出了异常直接抛出</h3><ul><li>问题描述</li></ul><p>我们先看一个例子,提交10个任务到线程池异步处理,第五个任务抛出一个RuntimeException,每个任务完成后输出一行日志:</p><pre><code>@GetMapping(&quot;execute&quot;)public void execute() throws InterruptedException {    String prefix = &quot;test&quot;;    ExecutorService threadPool = Executors.newFixedThreadPool(1, new ThreadFactoryBuilder().setNameFormat(prefix+&quot;%d&quot;).get());    //提交10个任务到线程池处理，第5个任务会抛出运行时异常    IntStream.rangeClosed(1, 10).forEach(i -&gt; threadPool.execute(() -&gt; {        if (i == 5) throw new RuntimeException(&quot;error&quot;);        log.info(&quot;I&#39;m done : {}&quot;, i);    }));    threadPool.shutdown();    threadPool.awaitTermination(1, TimeUnit.HOURS);}输出日志如下:...[14:33:55.990] [test0] [INFO ] [e.d.ThreadPoolAndExceptionController:26  ] - I&#39;m done : 4Exception in thread &quot;test0&quot; java.lang.RuntimeException: error  at org.geekbang.time.commonmistakes.exception.demo3.ThreadPoolAndExceptionController.lambda$null$0(ThreadPoolAndExceptionController.java:25)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  at java.lang.Thread.run(Thread.java:748)[14:33:55.990] [test1] [INFO ] [e.d.ThreadPoolAndExceptionController:26  ] - I&#39;m done : 6...</code></pre><p>通过观察可以发现,</p><ol><li>在任务5抛出异常之后,本来执行任务的线程test0退出了,变成了test1来执行任务;也就是说,如果每个任务都出现异常,线程池很有可能不得不每次都创建一个新线程,也就完全起不到线程复用的作用了.  </li><li>因为没有异常的捕获和处理程序,ThreadGroup采用了默认处理,向标准错误输出打印了出现异常的线程名称和异常信息.</li></ol><p>对应的,修复过程也有两步:</p><ol><li>在创建的任务内部做好线程异常处理.</li><li>在声明线程池的时候自定义线程池的未捕获异常处理程序.<pre><code>new ThreadFactoryBuilder().setNameFormat(prefix+&quot;%d&quot;).setUncaughtExceptionHandler((thread, throwable)-&gt; log.error(&quot;ThreadPool {} got exception&quot;, thread, throwable)).get()</code></pre></li></ol><p>那么我们换一种提交方式,如果是用submit方式来提交,结果会怎么样?查看日志我们发现:<br><strong>异常会被直接生吞!</strong></p><p>当前,其实异常并没有被吞,查看源码我们会发现,其实异常是存到了outcome字段中,只有在get的时候才会以ExecutionException的形式重新抛出.</p><pre><code>public void run() {...    try {        Callable&lt;V&gt; c = callable;        if (c != null &amp;&amp; state == NEW) {            V result;            boolean ran;            try {                result = c.call();                ran = true;            } catch (Throwable ex) {                result = null;                ran = false;                setException(ex);            }...}protected void setException(Throwable t) {    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {        outcome = t;        UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state        finishCompletion();    }}public V get() throws InterruptedException, ExecutionException {    int s = state;    if (s &lt;= COMPLETING)        s = awaitDone(false, 0L);    return report(s);}private V report(int s) throws ExecutionException {    Object x = outcome;    if (s == NORMAL)        return (V)x;    if (s &gt;= CANCELLED)        throw new CancellationException();    throw new ExecutionException((Throwable)x);}</code></pre><p>修改之后的submit提交代码如下所示:</p><pre><code>List&lt;Future&gt; tasks = IntStream.rangeClosed(1, 10).mapToObj(i -&gt; threadPool.submit(() -&gt; {    if (i == 5) throw new RuntimeException(&quot;error&quot;);    log.info(&quot;I&#39;m done : {}&quot;, i);})).collect(Collectors.toList());tasks.forEach(task-&gt; {    try {        task.get();    } catch (Exception e) {        log.error(&quot;Got exception&quot;, e);    }});</code></pre><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><ol><li>如果在 finally 代码块中返回值，你觉得程序会以 try 或 catch 中返回值为准，还是以 finally 中的返回值为准呢？</li></ol><p>答: 这个答案一定是finally为准,不论是什么命令最后是一定会执行finally的.详细的解释来自于这个课的评论高赞第一名:<br>首先需要明白的是在编译生成的字节码中，每个方法都附带一个异常表。异常表中的每一个条目代表一个异常处理器，并且由 from 指针、to 指针、target 指针以及所捕获的异常类型构成。这些指针的值是字节码索引（bytecode index，bci），用以定位字节码。其中，from 指针和 to 指针标示了该异常处理器所监控的范围，例如 try 代码块所覆盖的范围。target 指针则指向异常处理器的起始位置，例如 catch 代码块的起始位置；<br>当程序触发异常时，Java 虚拟机会从上至下遍历异常表中的所有条目。当触发异常的字节码的索引值在某个异常表条目的监控范围内，Java 虚拟机会判断所抛出的异常和该条目想要捕获的异常是否匹配。如果匹配，Java 虚拟机会将控制流转移至该条目 target 指针指向的字节码。如果遍历完所有异常表条目，Java 虚拟机仍未匹配到异常处理器，那么它会弹出当前方法对应的 Java 栈帧，并且在调用者（caller）中重复上述操作。在最坏情况下，Java 虚拟机需要遍历当前线程 Java 栈上所有方法的异常表。所以异常操作是一个非常耗费性能的操作；<br>finally 代码块的原理是复制 finally 代码块的内容，分别放在 try-catch 代码块所有正常执行路径以及异常执行路径的出口中。所以不管是是正常还是异常执行，finally都是最后执行的，所以肯定是finally语句块中为准。</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_11</title>
      <link href="/2021/01/13/java-kai-fa-chang-jian-cuo-wu-11/"/>
      <url>/2021/01/13/java-kai-fa-chang-jian-cuo-wu-11/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="11-空值处理：分不清楚的null和恼人的空指针"><a href="#11-空值处理：分不清楚的null和恼人的空指针" class="headerlink" title="11.空值处理：分不清楚的null和恼人的空指针"></a>11.空值处理：分不清楚的null和恼人的空指针</h2><h3 id="案例一"><a href="#案例一" class="headerlink" title="案例一:"></a>案例一:</h3><p>这段代码的确会引发空指针异常,问题是这种情况下我们很难判断到底是哪抛出了npe,在真实的业务场景中,npe有可能是在非常特殊的场景或者分支中才会出现,很难复现.<br>这里推荐使用阿里开源的 Java 故障诊断神器Arthas, link: <a href="https://arthas.aliyun.com/doc/" target="_blank" rel="noopener">https://arthas.aliyun.com/doc/</a><br>当然,故障诊断只是一方面,我们最好还是在程序设计上避免空指针的出现,对于最常见的null类型没有字段问题,一般的写法是使用if else语句,但是更具有可读性的写法是用Optional类,一行代码解决判空和处理的问题.<br>朱老师在课上给出了对应每种情况的修复准则:</p><ol><li>对于Integer的判空,使用Optional.ofNullable来构造一个Optional,然后使用ofElse来把null替换为默认值.  </li><li>对于String和字面量的比较,可以把字符量放在前面,这样即使是null也不会出现空指针;而对于都可能是null的变量,可以使用Objects.equals方法.</li><li>对于ConcurrentHashMap,在存之前多加一步判空处理比较好.  </li><li>对于级联调用,还是使用Optional方法.这里如果非null对应的是一个函数操作,可以写一个方法把对应的函数指针传进去,或者使用Optional的map方法,使用方式类似于stream.  </li><li>对于返回值,使用Optional的orElse方法,不过一般还是做一个判空处理比较好.  </li></ol><pre><code>private List&lt;String&gt; rightMethod(FooService fooService, Integer i, String s, String t) {    log.info(&quot;result {} {} {} {}&quot;, Optional.ofNullable(i).orElse(0) + 1, &quot;OK&quot;.equals(s), Objects.equals(s, t), new HashMap&lt;String, String&gt;().put(null, null));    Optional.ofNullable(fooService)            .map(FooService::getBarService)            .filter(barService -&gt; &quot;OK&quot;.equals(barService.bar()))            .ifPresent(result -&gt; log.info(&quot;OK&quot;));    return new ArrayList&lt;&gt;();}@GetMapping(&quot;right&quot;)public int right(@RequestParam(value = &quot;test&quot;, defaultValue = &quot;1111&quot;) String test) {    return Optional.ofNullable(rightMethod(test.charAt(0) == &#39;1&#39; ? null : new FooService(),            test.charAt(1) == &#39;1&#39; ? null : 1,            test.charAt(2) == &#39;1&#39; ? null : &quot;OK&quot;,            test.charAt(3) == &#39;1&#39; ? null : &quot;OK&quot;))            .orElse(Collections.emptyList()).size();}</code></pre><h3 id="案例二-POJO中的属性null到底代表了什么"><a href="#案例二-POJO中的属性null到底代表了什么" class="headerlink" title="案例二: POJO中的属性null到底代表了什么"></a>案例二: POJO中的属性null到底代表了什么</h3><ul><li>问题描述</li></ul><p>对于数据库中的null,产生的原因有很多.这里先加一些说明,POJO指的是数据库相关的一些抽象映射,DTO一般指我们可以控制的字段,Entity一般指数据库对应的实体表结构.可以理解为DTO是用来生成Entity插入到数据库中的,我们一般会写service来生成DTO.<br>比如新添加了一个字段但是没有给老记录插入这个字段对应的数据,或者是更新的时候给这个字段塞了一个null,等等.<br>我们看一个例子,有一个 User 的 POJO，同时扮演 DTO 和数据库 Entity 角色，包含用户 ID、姓名、昵称、年龄、注册时间等属性：</p><pre><code>@Data@Entitypublic class User {    @Id    @GeneratedValue(strategy = IDENTITY)    private Long id;    private String name;    private String nickname;    private Integer age;    private Date createDate = new Date();}</code></pre><p>一个post接口用于更新用户数据</p><pre><code>@Autowiredprivate UserRepository userRepository;@PostMapping(&quot;wrong&quot;)public User wrong(@RequestBody User user) {    user.setNickname(String.format(&quot;guest%s&quot;, user.getName()));    return userRepository.save(user);}@Repositorypublic interface UserRepository extends JpaRepository&lt;User, Long&gt; {}</code></pre><p>之后我们在数据库初始化一个用户,然后使用curl测试下Post接口,传入一个id=1,name=null的Json字符串,</p><pre><code>curl -H &quot;Content-Type:application/json&quot; -X POST -d &#39;{ &quot;id&quot;:1, &quot;name&quot;:null}&#39; http://localhost:45678/pojonull/wrong{&quot;id&quot;:1,&quot;name&quot;:null,&quot;nickname&quot;:&quot;guestnull&quot;,&quot;age&quot;:null,&quot;createDate&quot;:&quot;2020-01-05T02:01:03.784+0000&quot;}%</code></pre><p>接口返回后,暴露了三个问题”</p><ol><li>调用方只希望重置用户名,但是age也被设置为null;</li><li>nickname是用户类型+名,应该是guest,但是结果是null guest,类型null也被序列化出来了.</li><li>用户的创建时间发生了改动.</li></ol><p>归根节点,是下面五个方面的问题:</p><ol><li>JSON的反序列化是有歧义的,客户端传null和不传效果相同,但是实际上一个是维护原始数据,一个是清空数据.</li><li>POJO的字段有默认值,如果客户端不传就会赋予默认值,创建时间的更新就是一个例子,本来创建时间是不应该变动的.</li><li>null值可能被反序列化为”null”</li><li>DTO和ENtity共用了一个POJO,对于用户昵称的设置应该是在程序中控制,不应该暴露给数据库方.  </li><li>数据库字段允许保存null会进一步增加出错的可能性.</li></ol><p>明确了以上这些之后呢,我们修复了一下上面的类:</p><ol><li>DTO中只保存id,name,age,且使用Optional来包装,以区分客户端不传数据还是故意传null.</li><li>在UserEntity字段上添加@Column注解,把数据库字段设定成notNULL,并且设定默认时间,由数据库来生成创建时间. </li><li>使用 Hibernate 的 @DynamicUpdate 注解实现更新 SQL 的动态生成，实现只更新修改后的字段，不过需要先查询一次实体，让 Hibernate 可以“跟踪”实体属性的当前状态，以确保有效。</li></ol><pre><code>@Datapublic class UserDto {    private Long id;    private Optional&lt;String&gt; name;    private Optional&lt;Integer&gt; age;; @Data@Entity@DynamicUpdatepublic class UserEntity {    @Id    @GeneratedValue(strategy = IDENTITY)    private Long id;    @Column(nullable = false)    private String name;    @Column(nullable = false)    private String nickname;    @Column(nullable = false)    private Integer age;    @Column(nullable = false, columnDefinition = &quot;TIMESTAMP DEFAULT CURRENT_TIMESTAMP&quot;)    private Date createDate;}</code></pre><p>首先,如果Optional对象本身为空,那么就是客户端没传这个字段,可以直接跳过对这个字段的更新;如果对象不为空,我们再去判断他的值是不是空,进行后续处理.<br>之后我们在更新的时候,对于姓名,如果传null是为了重置,那么直接把null转换为空字符串即可.<br>对于年龄,传null可以直接抛出异常,不允许重置;对于昵称,由于姓名不会为空,所以直接取出来即可.  </p><pre><code>@PostMapping(&quot;right&quot;)public UserEntity right(@RequestBody UserDto user) {    if (user == null || user.getId() == null)        throw new IllegalArgumentException(&quot;用户Id不能为空&quot;);    UserEntity userEntity = userEntityRepository.findById(user.getId())            .orElseThrow(() -&gt; new IllegalArgumentException(&quot;用户不存在&quot;));    if (user.getName() != null) {        userEntity.setName(user.getName().orElse(&quot;&quot;));    }    userEntity.setNickname(&quot;guest&quot; + userEntity.getName());    if (user.getAge() != null) {        userEntity.setAge(user.getAge().orElseThrow(() -&gt; new IllegalArgumentException(&quot;年龄不能为空&quot;)));    }    return userEntityRepository.save(userEntity);}</code></pre><h3 id="案例三-小心Mysql中关于null的三个坑"><a href="#案例三-小心Mysql中关于null的三个坑" class="headerlink" title="案例三: 小心Mysql中关于null的三个坑"></a>案例三: 小心Mysql中关于null的三个坑</h3><ul><li>问题描述</li></ul><p>为了方便演示,首先定义一个只有id和score两个字段的实体:</p><pre><code>@Entity@Datapublic class User {    @Id    @GeneratedValue(strategy = IDENTITY)    private Long id;    private Long score;}程序启动的时候,往实体初始化一条数据,其id是自增列自动设置的1,score是NULL:@Autowiredprivate UserRepository userRepository;@PostConstructpublic void init() {    userRepository.save(new User());}</code></pre><p>之后我们再测试下面三个用例,来看看结合数据库中的null值可能会出现的坑:</p><ol><li>sum函数统计一个只有NULL值的列总和</li><li>select记录数量, count一个允许为NULL的字段</li><li>使用=NuLL条件查询字段值为NULL的记录</li></ol><pre><code>@Repositorypublic interface UserRepository extends JpaRepository&lt;User, Long&gt; {    @Query(nativeQuery=true,value = &quot;SELECT SUM(score) FROM `user`&quot;)    Long wrong1();    @Query(nativeQuery = true, value = &quot;SELECT COUNT(score) FROM `user`&quot;)    Long wrong2();    @Query(nativeQuery = true, value = &quot;SELECT * FROM `user` WHERE score=null&quot;)    List&lt;User&gt; wrong3();}</code></pre><p>得到的结果分别是null,0和空List,和我们预期的0,1,查询到一个记录不符.<br>原因是sum函数在没统计到任何记录时,会返回null,可以使用IFNULL函数把null转换为0;<br>count字段不记录null值,count(*)才是统计所有记录数量的方式;<br>和NULL比较不能使用=号,而是要使用ISNULL<br>修改后的SQL:  </p><pre><code>@Query(nativeQuery = true, value = &quot;SELECT IFNULL(SUM(score),0) FROM `user`&quot;)Long right1();@Query(nativeQuery = true, value = &quot;SELECT COUNT(*) FROM `user`&quot;)Long right2();@Query(nativeQuery = true, value = &quot;SELECT * FROM `user` WHERE score IS NULL&quot;)List&lt;User&gt; right3();</code></pre><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><ol><li>ConcurrentHashMap 的 Key 和 Value 都不能为 null，而 HashMap 却可以，你知道这么设计的原因是什么吗？TreeMap、Hashtable 等 Map 的 Key 和 Value 是否支持 null 呢？</li></ol><p>主要是歧义性,如果一个值为null,查询这个键可能会返回一个null,就无法确认到底是根本没有这个键,还是这个键存在但是值为null;尤其是在并发环境中,可能两次校验之间值已经被修改了.</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_10</title>
      <link href="/2021/01/11/java-kai-fa-chang-jian-cuo-wu-10/"/>
      <url>/2021/01/11/java-kai-fa-chang-jian-cuo-wu-10/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="10-集合类：坑满地的List列表操作"><a href="#10-集合类：坑满地的List列表操作" class="headerlink" title="10.集合类：坑满地的List列表操作"></a>10.集合类：坑满地的List列表操作</h2><h3 id="案例一-使用-Arrays-asList-把数据转换为-List-的三个坑"><a href="#案例一-使用-Arrays-asList-把数据转换为-List-的三个坑" class="headerlink" title="案例一: 使用 Arrays.asList 把数据转换为 List 的三个坑"></a>案例一: 使用 Arrays.asList 把数据转换为 List 的三个坑</h3><ul><li>问题描述</li></ul><p>在引入java8的stream之后,各种集合类的操作被大大简化,因此我们一般会把原始的数组转换为List类数据结构来进行操作,最常用的就是Arrays.asList/</p><pre><code>int[] arr = {1, 2, 3};List list = Arrays.asList(arr);log.info(&quot;list:{} size:{} class:{}&quot;, list, list.size(), list.get(0).getClass());</code></pre><p>但是我们查看日志的输出结果就会发现,这样操作生成的list的元素个数是1,元素类型是一个整数数组.<br>原因很简单,我们可以把int装箱为Integer,不可能把int数组装箱为Integer数组.<br>解决的办法非常简单,先使用stream方法把数组转换成流,然后把其中的每一个元素转换成对应的包装类,最后再传入List即可,代码如下:</p><pre><code>int[] arr1 = {1, 2, 3};List list1 = Arrays.stream(arr1).boxed().collect(Collectors.toList());log.info(&quot;list:{} size:{} class:{}&quot;, list1, list1.size(), list1.get(0).getClass());Integer[] arr2 = {1, 2, 3};List list2 = Arrays.asList(arr2);log.info(&quot;list:{} size:{} class:{}&quot;, list2, list2.size(), list2.get(0).getClass());</code></pre><p>继续往后看,是不是装换为装箱类型就没事了呢?我们再做一个测试:<br>把三个字符串 1、2、3 构成的字符串数组，使用 Arrays.asList 转换为 List 后，将原始字符串数组的第二个字符修改为 4，然后为 List 增加一个字符串 5，最后数组和 List 会是怎样呢？</p><pre><code>String[] arr = {&quot;1&quot;, &quot;2&quot;, &quot;3&quot;};List list = Arrays.asList(arr);arr[1] = &quot;4&quot;;try {    list.add(&quot;5&quot;);} catch (Exception ex) {    ex.printStackTrace();}log.info(&quot;arr:{} list:{}&quot;, Arrays.toString(arr), list);</code></pre><p>查看日志可以发现,日志里有一个UnsupportedOperationException,并且asList中的第二个元素也被修改为4了.<br>因此我们可以得出两个结论,</p><ol><li>Arrays.asList返回的list不支持增删操作,原因是这个方法返回的并不是我们想要的java.util.ArrayList,而是Arrays的内部类ArrayList.这个内部类继承自AbstractList类,并没有覆盖父类的add方法,父类中 add 方法的实现，就是抛出 UnsupportedOperationException.  </li></ol><pre><code>public static &lt;T&gt; List&lt;T&gt; asList(T... a) {    return new ArrayList&lt;&gt;(a);}private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;    implements RandomAccess, java.io.Serializable{    private final E[] a;    ArrayList(E[] array) {        a = Objects.requireNonNull(array);    }    @Override    public E set(int index, E element) {        E oldValue = a[index];        a[index] = element;        return oldValue;    }    ...}public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; {...public void add(int index, E element) {        throw new UnsupportedOperationException();    }}</code></pre><ol start="2"><li>对原始数组的修改会影响到我们获得的那个list,因为看源码可知,ArrayList是直接使用了原始的数组.<br>解决的办法也很简单,重新new一个ArrayList初始化Arrays.asList返回的List即可.<pre><code>//正确的一个实现String[] arr = {&quot;1&quot;, &quot;2&quot;, &quot;3&quot;};List list = new ArrayList(Arrays.asList(arr));</code></pre></li></ol><h3 id="案例二-使用-List-subList-进行切片操作居然会导致-OOM"><a href="#案例二-使用-List-subList-进行切片操作居然会导致-OOM" class="headerlink" title="案例二: 使用 List.subList 进行切片操作居然会导致 OOM"></a>案例二: 使用 List.subList 进行切片操作居然会导致 OOM</h3><ul><li>问题描述</li></ul><p>业务开发时常常要对 List 做切片处理，即取出其中部分元素构成一个新的 List，我们通常会想到使用 List.subList 方法。但，和 Arrays.asList 的问题类似，List.subList 返回的子 List 不是一个普通的 ArrayList。这个子 List 可以认为是原始 List 的视图，会和原始 List 相互影响。<br>所以我们在使用切片的同时,也要按照之前的方法,单独new一个新的出来.<br>如果不想new一个新的,也可以使用stream的skip和limit方法来选出一部分连续的数.</p><pre><code>//方式一：List&lt;Integer&gt; subList = new ArrayList&lt;&gt;(list.subList(1, 4));//方式二：List&lt;Integer&gt; subList = list.stream().skip(1).limit(3).collect(Collectors.toList());</code></pre><h3 id="案例三-让合适的数据结构做合适的事情"><a href="#案例三-让合适的数据结构做合适的事情" class="headerlink" title="案例三: 让合适的数据结构做合适的事情"></a>案例三: 让合适的数据结构做合适的事情</h3><ul><li>问题描述</li></ul><p>现在我们要实现一个列表,有基于连续存储的数组和基于指针串联的链表两种方式.那么按照教科书上的解释,在大量元素插入,很少随机访问的业务场景下,是不是应该使用linkedList呢?<br>我们来写一段代码测试一下,定义四个参数一致的方法，分别对元素个数为 elementCount 的 LinkedList 和 ArrayList，循环 loopCount 次，进行随机访问和增加元素到随机位置的操作：</p><pre><code>//LinkedList访问private static void linkedListGet(int elementCount, int loopCount) {    List&lt;Integer&gt; list = IntStream.rangeClosed(1, elementCount).boxed().collect(Collectors.toCollection(LinkedList::new));    IntStream.rangeClosed(1, loopCount).forEach(i -&gt; list.get(ThreadLocalRandom.current().nextInt(elementCount)));}//ArrayList访问private static void arrayListGet(int elementCount, int loopCount) {    List&lt;Integer&gt; list = IntStream.rangeClosed(1, elementCount).boxed().collect(Collectors.toCollection(ArrayList::new));    IntStream.rangeClosed(1, loopCount).forEach(i -&gt; list.get(ThreadLocalRandom.current().nextInt(elementCount)));}//LinkedList插入private static void linkedListAdd(int elementCount, int loopCount) {    List&lt;Integer&gt; list = IntStream.rangeClosed(1, elementCount).boxed().collect(Collectors.toCollection(LinkedList::new));    IntStream.rangeClosed(1, loopCount).forEach(i -&gt; list.add(ThreadLocalRandom.current().nextInt(elementCount),1));}//ArrayList插入private static void arrayListAdd(int elementCount, int loopCount) {    List&lt;Integer&gt; list = IntStream.rangeClosed(1, elementCount).boxed().collect(Collectors.toCollection(ArrayList::new));    IntStream.rangeClosed(1, loopCount).forEach(i -&gt; list.add(ThreadLocalRandom.current().nextInt(elementCount),1));}测试代码:int elementCount = 100000;int loopCount = 100000;StopWatch stopWatch = new StopWatch();stopWatch.start(&quot;linkedListGet&quot;);linkedListGet(elementCount, loopCount);stopWatch.stop();stopWatch.start(&quot;arrayListGet&quot;);arrayListGet(elementCount, loopCount);stopWatch.stop();System.out.println(stopWatch.prettyPrint());StopWatch stopWatch2 = new StopWatch();stopWatch2.start(&quot;linkedListAdd&quot;);linkedListAdd(elementCount, loopCount);stopWatch2.stop();stopWatch2.start(&quot;arrayListAdd&quot;);arrayListAdd(elementCount, loopCount);stopWatch2.stop();System.out.println(stopWatch2.prettyPrint());</code></pre><p>结果是ArrayList全面占优,随机访问我们可以解释,为什么随机插入也是ArrayList快呢?</p><ul><li>问题分析</li></ul><p>翻看源码可知,插入操作时间复杂度为O(1)是有前提的,那就是我们已经拿到了那个节点的指针,但是在实现的时候,我们只能通过循环去获取到那个节点的指针,然后再执行插入操作,因此效率大大降低.</p><pre><code>public void add(int index, E element) {    checkPositionIndex(index);    if (index == size)        linkLast(element);    else        linkBefore(element, node(index));}Node&lt;E&gt; node(int index) {    // assert isElementIndex(index);    if (index &lt; (size &gt;&gt; 1)) {        Node&lt;E&gt; x = first;        for (int i = 0; i &lt; index; i++)            x = x.next;        return x;    } else {        Node&lt;E&gt; x = last;        for (int i = size - 1; i &gt; index; i--)            x = x.prev;        return x;    }}</code></pre><p>因此,在各种场景下,实际上LinkedList都不能在性能上胜出ArrayList.老师在书中还提到一点,LinkedList的作者自己都不用LinkedList作为一种备选数据结构2333.  </p><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><ol><li>调用类型是 Integer 的 ArrayList 的 remove 方法删除元素，传入一个 Integer 包装类的数字和传入一个 int 基本类型的数字，结果一样吗？</li></ol><p>答: 不一样,传不同的类型会触发重载机制,int是按照索引删除,Integer是按照Object删除元素.</p><ol start="2"><li>循环遍历 List，调用 remove 方法删除元素，往往会遇到 ConcurrentModificationException 异常，原因是什么，修复方式又是什么呢？</li></ol><p>答: 用迭代器时，可以删除原来集合的元素，但是！一定要用迭代器的remove方法而不是集合自身的remove方法，否则抛异常, 因为不管是迭代器里面的remove()还是next()方法,都会checkForComodification();而这个方法是判断modCount和expectedModCount是否相等，这个modCount是这个list集合修改的次数，每一次add或者remove都会增加这个变量，然后迭代器每次去next或者去remove的时候检查checkForComodification();发现expectedModCount(这个迭代器修改的次数)和modCount(这个集合实际修改的次数)不相等，就会抛出ConcurrentModificationException，</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_9</title>
      <link href="/2021/01/10/java-kai-fa-chang-jian-cuo-wu-9/"/>
      <url>/2021/01/10/java-kai-fa-chang-jian-cuo-wu-9/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="9-数值计算：注意精度、舍入和溢出问题"><a href="#9-数值计算：注意精度、舍入和溢出问题" class="headerlink" title="9.数值计算：注意精度、舍入和溢出问题"></a>9.数值计算：注意精度、舍入和溢出问题</h2><h3 id="案例一-“危险”的-Double"><a href="#案例一-“危险”的-Double" class="headerlink" title="案例一: “危险”的 Double"></a>案例一: “危险”的 Double</h3><ul><li>问题描述</li></ul><p>如果我们使用0.1+0.2,结果会是多少?<br>不是0.3,是0.30000000000000004.<br>原因就在于计算机存储浮点数是使用二进制的,这也就是为什么我们在大量使用浮点数计算的场合是必须使用BigDecimal类的.<br>但是,我们使用BigDecimal类也要遵循一些原则:</p><ol><li><p>务必使用字符串的构造方法来初始化BigDecimal类.  </p><pre><code>System.out.println(new BigDecimal(&quot;0.1&quot;).add(new BigDecimal(&quot;0.2&quot;)));System.out.println(new BigDecimal(&quot;1.0&quot;).subtract(new BigDecimal(&quot;0.8&quot;)));System.out.println(new BigDecimal(&quot;4.015&quot;).multiply(new BigDecimal(&quot;100&quot;)));System.out.println(new BigDecimal(&quot;123.3&quot;).divide(new BigDecimal(&quot;100&quot;)));</code></pre><p>结果如下,可以看出来BD这个键是按照字符串的最小位来判断结果的最小位的.<br>```</p></li><li><p>3</p></li><li><p>2</p></li><li><p>500</p></li><li><p>233</p><pre><code>从这个案例我们可以引出,BD这个类的两个属性,scale: 小数点右边的位数, precision: 有效数字的长度.  因此,对于double类型转换成BD类型,我们需要显式的进行浮点数舍入和格式化.</code></pre></li><li><p>浮点数的字符串格式化也要通过 BigDecimal 进行。<br>首先用 double 和 float 初始化两个 3.35 的浮点数，然后通过 String.format 使用 %.1f 来格式化这 2 个数字：</p><pre><code>double num1 = 3.35;float num2 = 3.35f;System.out.println(String.format(&quot;%.1f&quot;, num1));//四舍五入System.out.println(String.format(&quot;%.1f&quot;, num2));</code></pre><p>得到的结果是3,4和3.3!<br>原因就是double的3.35实际上是3.350xxx,而float的3.35实际上上3.349xxx,而String.format默认是使用四舍五入进行舍入的.<br>正确的做法如下:</p><pre><code>BigDecimal num1 = new BigDecimal(&quot;3.35&quot;);BigDecimal num2 = num1.setScale(1, BigDecimal.ROUND_DOWN);System.out.println(num2);BigDecimal num3 = num1.setScale(1, BigDecimal.ROUND_HALF_UP);System.out.println(num3);</code></pre></li><li><p>比较BigDecimal类型的时候,最好使用compareTo方法.</p></li></ol><p>由于BigDecimal的equals方法是使用value和scale来实现的,所以会出现value相同scale不相同的问题.而compareTo方法是只比较value的.</p><ol start="4"><li>如果存在数值溢出可能,使用大数类BigInteger.</li></ol><p>比如最常见的Long最大值溢出,使用BI这个类就不会出现任何问题了.  </p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_8</title>
      <link href="/2021/01/08/java-kai-fa-chang-jian-cuo-wu-8/"/>
      <url>/2021/01/08/java-kai-fa-chang-jian-cuo-wu-8/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="8-判等问题：程序里如何确定你就是你？"><a href="#8-判等问题：程序里如何确定你就是你？" class="headerlink" title="8.判等问题：程序里如何确定你就是你？"></a>8.判等问题：程序里如何确定你就是你？</h2><h3 id="案例一-equals-和-的区别"><a href="#案例一-equals-和-的区别" class="headerlink" title="案例一: equals 和 == 的区别"></a>案例一: equals 和 == 的区别</h3><ul><li>问题描述</li></ul><p>一般情况下,对于==, 只是比较两个变量的值的大小;对于equals,往往是比较两个对象是否相同;所以==往往只用于基本类型的比较,而其余类型都使用equals.<br>但是在对一些包装类进行处理时,比如Integer和String,使用==有时可以得到正确结果,有时候却不可以,这是为什么呢?<br>老师在课上给出了这样一个例子:</p><pre><code>Integer a = 127; //Integer.valueOf(127)Integer b = 127; //Integer.valueOf(127)log.info(&quot;\nInteger a = 127;\n&quot; +        &quot;Integer b = 127;\n&quot; +        &quot;a == b ? {}&quot;,a == b);    // trueInteger c = 128; //Integer.valueOf(128)Integer d = 128; //Integer.valueOf(128)log.info(&quot;\nInteger c = 128;\n&quot; +        &quot;Integer d = 128;\n&quot; +        &quot;c == d ? {}&quot;, c == d);   //falseInteger e = 127; //Integer.valueOf(127)Integer f = new Integer(127); //new instancelog.info(&quot;\nInteger e = 127;\n&quot; +        &quot;Integer f = new Integer(127);\n&quot; +        &quot;e == f ? {}&quot;, e == f);   //falseInteger g = new Integer(127); //new instanceInteger h = new Integer(127); //new instancelog.info(&quot;\nInteger g = new Integer(127);\n&quot; +        &quot;Integer h = new Integer(127);\n&quot; +        &quot;g == h ? {}&quot;, g == h);  //falseInteger i = 128; //unboxint j = 128;log.info(&quot;\nInteger i = 128;\n&quot; +        &quot;int j = 128;\n&quot; +        &quot;i == j ? {}&quot;, i == j); //true</code></pre><p>这段代码可能看起来比较迷惑,具体解析一下就是:<br>使用 == 对两个值为 127 的直接赋值的 Integer 对象判等；使用 == 对两个值为 128 的直接赋值的 Integer 对象判等；使用 == 对一个值为 127 的直接赋值的 Integer 和另一个通过 new Integer 声明的值为 127 的对象判等；使用 == 对两个通过 new Integer 声明的值为 127 的对象判等；使用 == 对一个值为 128 的直接赋值的 Integer 对象和另一个值为 128 的 int 基本类型判等。</p><ul><li>问题分析</li></ul><p>在第一种情况下, 编译器会把127转换为Integer.valueOf(127), 查看源码就会发现,这个写法是个缓存写法,所以指向了一个对象.</p><pre><code>public static Integer valueOf(int i) {    if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)        return IntegerCache.cache[i + (-IntegerCache.low)];    return new Integer(i);}</code></pre><p>同理,第二种情况的时候, 由于默认是缓存[-128, 127]的数值,而128处于这个区间之外,所以只要设置下JVM的参数就可以返回true了;<br>对于第三和第四种情况,new 出来的对象始终是不走缓存的, 而==比较的是对象的地址,所以肯定是不同的.<br>最后一种情况, 由于我们比对的是装箱类型和基本类型,会自动的拆箱拿出来具体的值进行比对,所以是true.  </p><p>总而言之,对于非基本类型或者null的比较,一律使用equals方法几乎是不会出错的.  </p><p>看一个业务中比较经典的例子:</p><pre><code>有这么一个枚举定义了订单状态和对于状态的描述：enum StatusEnum {    CREATED(1000, &quot;已创建&quot;),    PAID(1001, &quot;已支付&quot;),    DELIVERED(1002, &quot;已送到&quot;),    FINISHED(1003, &quot;已完成&quot;);    private final Integer status; //注意这里的Integer    private final String desc;    StatusEnum(Integer status, String desc) {        this.status = status;        this.desc = desc;    }}开发同学使用了 == 对枚举和入参 OrderQuery 中的 status 属性进行判等：@Datapublic class OrderQuery {    private Integer status;    private String name;}@PostMapping(&quot;enumcompare&quot;)public void enumcompare(@RequestBody OrderQuery orderQuery){    StatusEnum statusEnum = StatusEnum.DELIVERED;    log.info(&quot;orderQuery:{} statusEnum:{} result:{}&quot;, orderQuery, statusEnum, statusEnum.status == orderQuery.getStatus());}</code></pre><p>这里有几个坑人的点,<br>首先只看枚举的定义,CREATED(1000, “已创建”),会以为这是一个基本类型;<br>其次,由于127法则,在订单刚创建时程序不会出错,所以在测试环境没测出来,到生产环境可能才会发现.  </p><p>我们再看看为什么String类型也会有这个问题:</p><ul><li>对两个直接声明的值都为 1 的 String 使用 == 判等；</li><li>对两个 new 出来的值都为 2 的 String 使用 == 判等；</li><li>对两个 new 出来的值都为 3 的 String 先进行 intern 操作，再使用 == 判等；</li><li>对两个 new 出来的值都为 4 的 String 通过 equals 判等。<pre><code>String a = &quot;1&quot;;String b = &quot;1&quot;;log.info(&quot;\nString a = \&quot;1\&quot;;\n&quot; +      &quot;String b = \&quot;1\&quot;;\n&quot; +      &quot;a == b ? {}&quot;, a == b); //true</code></pre></li></ul><p>String c = new String(“2”);<br>String d = new String(“2”);<br>log.info(“\nString c = new String(\”2\”);\n” +<br>        “String d = new String(\”2\”);” +<br>        “c == d ? {}”, c == d); //false</p><p>String e = new String(“3”).intern();<br>String f = new String(“3”).intern();<br>log.info(“\nString e = new String(\”3\”).intern();\n” +<br>        “String f = new String(\”3\”).intern();\n” +<br>        “e == f ? {}”, e == f); //true</p><p>String g = new String(“4”);<br>String h = new String(“4”);<br>log.info(“\nString g = new String(\”4\”);\n” +<br>        “String h = new String(\”4\”);\n” +<br>        “g == h ? {}”, g.equals(h)); //true</p><pre><code>首先复习一下Java的字符串常量池机制,当代码中出现双引号形式创建字符串对象的时候,JVM会优先返回常量池内对这个字符串对象的引用;如果不存在,就创建一个新的,放入常量池,然后再返回引用,这称为字符串的驻留;  注意,当我们只使用new String这个方法的时候,是不会调用常量池的,一定是创建一个新的出来,而不放入常量池中.而如果我们同时调用了intern方法,就会走常量池机制.  我们再看一个测试代码,来深入研究字符串常量池的具体机制.写代码测试一下，通过循环把 1 到 1000 万之间的数字以字符串形式 intern 后，存入一个 List：</code></pre><p>List<string> list = new ArrayList&lt;&gt;();</string></p><p>@GetMapping(“internperformance”)<br>public int internperformance(@RequestParam(value = “size”, defaultValue = “10000000”)int size) {<br>    //-XX:+PrintStringTableStatistics<br>    //-XX:StringTableSize=10000000<br>    long begin = System.currentTimeMillis();<br>    list = IntStream.rangeClosed(1, size)<br>            .mapToObj(i-&gt; String.valueOf(i).intern())<br>            .collect(Collectors.toList());<br>    log.info(“size:{} took:{}”, size, System.currentTimeMillis() - begin);<br>    return list.size();<br>}</p><pre><code>输出如下:</code></pre><p>[11:01:57.770] [http-nio-45678-exec-2] [INFO ] [.t.c.e.d.IntAndStringEqualController:54  ] - size:10000000 took:44907<br>StringTable statistics:<br>Number of buckets       :     60013 =    480104 bytes, avg   8.000<br>Number of entries       :  10030230 = 240725520 bytes, avg  24.000<br>Number of literals      :  10030230 = 563005568 bytes, avg  56.131<br>Total footprint         :           = 804211192 bytes<br>Average bucket size     :   167.134<br>Variance of bucket size :    55.808<br>Std. dev. of bucket size:     7.471<br>Maximum bucket size     :       198</p><pre><code>可以看出,1000w次的intern操作耗时居然超过了44秒.其实,原因在于字符串常量池是一个固定容量的Map,如果容量太小,字符串太多,每一个桶中的字符串数量就会过多,搜索就会很慢.Average bucket size 这个参数就是平均桶长度.  那么我们解决的办法也很简单,设置 -XX:StringTableSize=10000000, 加大桶的数量即可.通过上述测试,我们得到了一个结论: 没事别轻易用 intern，如果要用一定要注意控制驻留的字符串的数量，并留意常量表的各项指标。### 案例二: 实现一个equals没有这么简单- 问题描述在Object类里,equals比较的其实是对象引用,那么为什么Integer这样的包装类都能使用equals来进行判等呢?其实是因为他们都重写了这个方法.  那么如何写出一个比较好的equals方法呢?需要遵循以下几个流程- 先进行指针判等- 判空- 比较两个对象的类型,使用o.getClass()方法- 确保类型相同的情况下进行类型强制转换,然后逐一判断所有字段.  - 确保要覆盖hashCode方法- 确保要覆盖compareTo方法,尤其是在有可能会涉及到排序的时候在能够使用ide和lombok自带的equals以及hashCode方法的时候,尽量避免自己写.### 案例三: 小心Lombok自动生成代码产生的坑- 问题描述lombok的@Data注解会帮我们实现equals和hashCode方法,但是有继承关系的时候,Lombok的自动生成方法可能就不是我们期望的了.  先定义一个Person类型,包含姓名和身份证两个字段:</code></pre><p>@Data<br>class Person {<br>    private String name;<br>    private String identity;</p><pre><code>public Person(String name, String identity) {    this.name = name;    this.identity = identity;}</code></pre><p>}</p><p>写一个 Employee 类继承 Person，并新定义一个公司属性</p><p>@Data<br>class Employee extends Person {</p><pre><code>private String company;public Employee(String name, String identity, String company) {    super(name, identity);    this.company = company;}</code></pre><p>}</p><pre><code>然后写一个测试代码,来判断一下,姓名和身份证不相同,公司相同的两个人是否相同:</code></pre><p>Employee employee1 = new Employee(“zhuye”,”001”, “bkjk.com”);<br>Employee employee2 = new Employee(“Joseph”,”002”, “bkjk.com”);<br>log.info(“employee1.equals(employee2) ? {}”, employee1.equals(employee2));  </p><pre><code>结果显示true, 很明显, @Data注解默认没使用父类属性.想要修复也非常简单,我们需要手动修改下callSuper</code></pre><p>@Data<br>@EqualsAndHashCode(callSuper = true)<br>class Employee extends Person {</p><pre><code>### 思考题#### 在文章里是使用getClass来判断两个对象的类型,我们经常使用的还有instanceof方法,你了解这二者有什么区别吗?答: instanceof判断的逻辑是,你是该类或者该类的子类,都返回true;getClass就是对类名进行检查,不判断继承关系.#### treeSet和HashSet的contains方法有什么区别吗?hashSet的contains方法是根据equals和hashCode去判断是否重复的,但是TreeSet是红黑树组成的,在放入元素时指定comparator,本质是campareTo方法实现的.</code></pre>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_7</title>
      <link href="/2021/01/05/java-kai-fa-chang-jian-cuo-wu-7/"/>
      <url>/2021/01/05/java-kai-fa-chang-jian-cuo-wu-7/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h2 id="7-数据库索引-索引并不是万能药"><a href="#7-数据库索引-索引并不是万能药" class="headerlink" title="7.数据库索引: 索引并不是万能药"></a>7.数据库索引: 索引并不是万能药</h2><h3 id="案例一-InnoDB是如何存储数据的"><a href="#案例一-InnoDB是如何存储数据的" class="headerlink" title="案例一: InnoDB是如何存储数据的?"></a>案例一: InnoDB是如何存储数据的?</h3><ul><li>问题分析</li></ul><p>虽然数据是保存在磁盘中,但是处理数据是在内存中进行的,为了减少磁盘的随机读取次数,InnoDB采用页面(而不是行)来保存数据,一个页一般是16KB.<br>各个数据页组成一个双向链表,每个数据页中的记录按照主键顺序组成单向链表,每个数据页中有一个页目录,方便按照主键查询记录.<br>结构如下<br><img src="https://s3.ax1x.com/2021/01/05/sFcu26.png" alt="数据页结构"></p><p>页目录通过槽把记录分为不同小组,记录中最前面的小方块中的数字代表的是当前分组的记录条数,这样我们再按照主键搜索页中记录时,就可以采用二分法快速搜索,无需从最小记录开始遍历整个页中的记录链表.  </p><p>举一个例子，如果要搜索主键（PK）=15 的记录：先二分得出槽中间位是 (0+6)/2=3，看到其指向的记录是 12＜15，所以需要从 #3 槽后继续搜索记录；再使用二分搜索出 #3 槽和 #6 槽的中间位是 (3+6)/2=4.5 取整 4，#4 槽对应的记录是 16＞15，所以记录一定在 #4 槽中；再从 #3 槽指向的 12 号记录开始向下搜索 3 次，定位到 15 号记录。</p><h4 id="聚簇索引和二级索引"><a href="#聚簇索引和二级索引" class="headerlink" title="聚簇索引和二级索引"></a>聚簇索引和二级索引</h4><p>InnoDB使用B+树来实现索引结构,如下图所示:<br><img src="https://s3.ax1x.com/2021/01/06/sVVNRK.png" alt="B+树结构"></p><p>B+ 树的特点包括：</p><ul><li>最底层的节点叫作叶子节点，用来存放数据；</li><li>其他上层节点叫作非叶子节点，仅用来存放目录项，作为索引；</li><li>非叶子节点分为不同层次，通过分层来降低每一层的搜索量；</li><li>所有节点按照索引键大小排序，构成一个双向链表，加速范围查找。</li></ul><p>因为数据在物理上只会保存一份,所以聚簇索引必定是唯一的,InnoDB会自动使用主键(唯一定义一条记录的单个或多个字段)作为聚簇索引的索引键,上图方框中的数字代表了索引键的值.  </p><p>为了实现对非主键字段的快速搜索,就需要建立二级索引,和聚簇索引的区别在于二级索引的叶子节点中存的不是数据而是主键,根据主键再走聚簇索引获得真正数据的过程就称为回表.  </p><h4 id="考虑额外创建二级索引的代价"><a href="#考虑额外创建二级索引的代价" class="headerlink" title="考虑额外创建二级索引的代价"></a>考虑额外创建二级索引的代价</h4><p>主要分为 维护代价,空间代价和回表代价三个方面.<br>首先是维护代价, 每多一个二级索引,就要多创建一个B+树,新增数据时不但要更新聚簇索引,还要更新这些二级索引.<br>这里补充一下,页中的记录都是按照索引值从小到大的顺序存放的，新增记录就需要往页中插入数据，现有的页满了就需要新创建一个页，把现有页的部分数据移过去，这就是页分裂；如果删除了许多数据使得页比较空闲，还需要进行页合并。页分裂和合并，都会有 IO 代价，并且可能在操作过程中产生死锁。<br>其次是空间代价, 虽然二级索引不保存原始数据,但是要保存索引列的数据,所以会占用更多的空间,比如4.7M的数据的索引可能有8.4M.<br>最后是回表代价, 走二级索引查询非索引列数据时,会走二级索引寻找主键之后再走聚簇索引,这个过程耗时会比单一查询更久.(注意当只查索引列数据时效率是一样的,这种情况称为索引覆盖)</p><p>出于对于以上三种代价的考虑,老师总结了关于索引的两个最佳实践:<br>1, 无需一开始就建立索引,而是等待数据量超过1w,查询变慢之后再针对需要查询,排序或者分组的字段创建索引.<br>2, 尽量索引轻量级的字段,比如能索引int就不要索引varchar,索引字段也可以是部分前缀,在创建的时候指定字段索引长度; 如果一定要针对长文本搜索,使用es等专门用于文本搜索的索引数据库.<br>3, 尽量不使用select * 而是select必要的字段,甚至可以使用联合索引来包含我们要搜索的字段,这样既可以实现索引加速,又可以避免回表的开销.  </p><h4 id="不是所有针对索引列的查询都能用上索引"><a href="#不是所有针对索引列的查询都能用上索引" class="headerlink" title="不是所有针对索引列的查询都能用上索引"></a>不是所有针对索引列的查询都能用上索引</h4><p>我们先提出来两个问题:</p><ul><li>是不是建了索引一定可以用上？</li><li>怎么选择创建联合索引还是多个独立索引？</li></ul><p>先解决第一个,索引在什么情况下会失效呢?</p><p>1, 索引只能匹配列前缀. 举一个例子,搜索 name 后缀为 name123 的用户无法走索引，执行计划的 type=ALL 代表了全表扫描：</p><pre><code>EXPLAIN SELECT * FROM person WHERE NAME LIKE &#39;%name123&#39; LIMIT 100</code></pre><p>但是只要把百分号放在后面,就可以走索引,type=range 表示走索引扫描，key=name_score 看到实际走了 name_score 索引：</p><pre><code>EXPLAIN SELECT * FROM person WHERE NAME LIKE &#39;name123%&#39; LIMIT 100</code></pre><p>原因是B+树中的行数据是按照索引值排序的,而字符串是根据前缀来比较的,如果要按照后缀搜索也走索引的话,可以把数据反过来存,获取的时候再反过来取;(这里其实和最大堆最小堆的实现是一个道理)</p><p>2, 条件设计函数操作无法走索引. 比如length()函数, 原因是索引保存的是索引列的原始值,而不是经过函数计算后的值,如果需要针对函数调用走数据库索引,可以保存一份计算后的值,然后针对这个计算结果列重新做一个索引.  </p><p>3, 联合索引只能匹配左边的列,比如说对name和score建了联合索引,对name查询可以走这个索引,但是只对score查询就不能走.<br>注意因为有查询优化器,所以name作为where子句的第几个条件并不重要.</p><p>现在再来看看第二个, 如果你的搜索条件经常会使用多个字段进行搜索，那么可以考虑针对这几个字段建联合索引；同时，针对多字段建立联合索引，使用索引覆盖的可能更大。如果只会查询单个字段，可以考虑建单独的索引，毕竟联合索引保存了不必要字段也有成本。</p><h4 id="数据库基于成本决定是否走索引"><a href="#数据库基于成本决定是否走索引" class="headerlink" title="数据库基于成本决定是否走索引"></a>数据库基于成本决定是否走索引</h4><p>通过前面的案例我们发现,一次对于非主键的查询,既可以直接走聚簇索引全表扫描, 也可以走二级索引扫描后回到聚簇索引回表,那么mysql是咋确定走哪种的呢?<br>其实mysql在查询数据前,会先对可能的方案做执行计划,然后依据成本决定走哪个执行计划. 成本包括IO 成本和CPU成本.  </p><ul><li>IO 成本，是从磁盘把数据加载到内存的成本。默认情况下，读取数据页的 IO 成本常数是 1（也就是读取 1 个页成本是 1）。</li><li>CPU 成本，是检测数据是否满足条件和排序等 CPU 操作的成本。默认情况下，检测记录的成本是 0.2。</li></ul><p>我们分析一下全表扫描的成本,<br>全表扫描意味着我们要把聚簇索引中的记录依次和给定的条件作比对,所以成本由两部分构成: 聚簇索引占用的页面处,用来计算读取数据的IO成本;表中的记录数,用来记录搜索的CPU成本.<br>mysql并不是实时统计这些信息的,只是维护了表的统计信息,可以使用如下的命令查看:</p><pre><code>SHOW TABLE STATUS LIKE &#39;person&#39;</code></pre><p>我们再举一个例子,分析下 MySQL 如何基于成本来制定执行计划。现在，我要用下面的 SQL 查询 name&gt;‘name84059’ AND create_time&gt;‘2020-01-24 05:00:00’</p><pre><code>EXPLAIN SELECT * FROM person WHERE NAME &gt;&#39;name84059&#39; AND create_time&gt;&#39;2020-01-24 05:00:00&#39;</code></pre><p>执行的计划是全表扫描.但是如果把create_time条件中的5点改成6点,就变成走索引了,由此可以看出,mysql是依据成本管理来决定是否走索引的,当然我们也可以强制mysql走我们指定的索引,比如;</p><pre><code>EXPLAIN SELECT * FROM person FORCE INDEX(name_score) WHERE NAME &gt;&#39;name84059&#39; AND create_time&gt;&#39;2020-01-24 05:00:00&#39; </code></pre><p>我们也可以通过optimizer trace功能查看优化器生成执行计划的整个过程,具体操作如下:</p><pre><code>SET optimizer_trace=&quot;enabled=on&quot;;SELECT * FROM person WHERE NAME &gt;&#39;name84059&#39; AND create_time&gt;&#39;2020-01-24 05:00:00&#39;;SELECT * FROM information_schema.OPTIMIZER_TRACE;SET optimizer_trace=&quot;enabled=off&quot;;</code></pre><p>可以清晰的看到不同方案之间的对比,以及mysql选择的理由.  </p><h3 id="重点回顾-老师的总结"><a href="#重点回顾-老师的总结" class="headerlink" title="重点回顾(老师的总结)"></a>重点回顾<code>(老师的总结)</code></h3><p>今天，我先和你分析了 MySQL InnoDB 存储引擎页、聚簇索引和二级索引的结构，然后分析了关于索引的两个误区。第一个误区是，考虑到索引的维护代价、空间占用和查询时回表的代价，不能认为索引越多越好。索引一定是按需创建的，并且要尽可能确保足够轻量。一旦创建了多字段的联合索引，我们要考虑尽可能利用索引本身完成数据查询，减少回表的成本。第二个误区是，不能认为建了索引就一定有效，对于后缀的匹配查询、查询中不包含联合索引的第一列、查询条件涉及函数计算等情况无法使用索引。此外，即使 SQL 本身符合索引的使用条件，MySQL 也会通过评估各种查询方式的代价，来决定是否走索引，以及走哪个索引。因此，在尝试通过索引进行 SQL 性能优化的时候，务必通过执行计划或实际的效果来确认索引是否能有效改善性能问题，否则增加了索引不但没解决性能问题，还增加了数据库增删改的负担。如果对 EXPLAIN 给出的执行计划有疑问的话，你还可以利用 optimizer_trace 查看详细的执行计划做进一步分析。</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_6</title>
      <link href="/2021/01/02/java-kai-fa-chang-jian-cuo-wu-6/"/>
      <url>/2021/01/02/java-kai-fa-chang-jian-cuo-wu-6/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="6-20-的业务代码的Spring声明式事务，可能都没处理正确"><a href="#6-20-的业务代码的Spring声明式事务，可能都没处理正确" class="headerlink" title="6.20%的业务代码的Spring声明式事务，可能都没处理正确"></a>6.20%的业务代码的Spring声明式事务，可能都没处理正确</h2><h3 id="案例一-小心Spring的事务可能没有失效"><a href="#案例一-小心Spring的事务可能没有失效" class="headerlink" title="案例一: 小心Spring的事务可能没有失效"></a>案例一: 小心Spring的事务可能没有失效</h3><ul><li>问题描述</li></ul><p>大多数的SpringBoot项目只需要在方法上标记@Transaction注解,即可一键开启方法的事务性配置.<br>事务没有被正确处理，一般来说不会过于影响正常流程，也不容易在测试阶段被发现。但当系统越来越复杂、压力越来越大之后，就会带来大量的数据不一致问题，随后就是大量的人工介入查看和修复数据。<br>实现下面的 Demo 需要一些基础类，首先定义一个具有 ID 和姓名属性的 UserEntity，也就是一个包含两个字段的用户表：</p><pre><code>@Entity@Datapublic class UserEntity {    @Id    @GeneratedValue(strategy = AUTO)    private Long id;    private String name;    public UserEntity() { }    public UserEntity(String name) {        this.name = name;    }}</code></pre><p>新增一个根据用户名查询所有数据的方法：</p><pre><code>@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; {    List&lt;UserEntity&gt; findByName(String name);}</code></pre><p>定义一个 UserService 类，负责业务逻辑处理。如果不清楚 @Transactional 的实现方式，只考虑代码逻辑的话，这段代码看起来没有问题。定义一个入口方法 createUserWrong1 来调用另一个私有方法 createUserPrivate，私有方法上标记了 @Transactional 注解。当传入的用户名包含 test 关键字时判断为用户名不合法，抛出异常，让用户创建操作失败，期望事务可以回滚：</p><pre><code>@Service@Slf4jpublic class UserService {    @Autowired    private UserRepository userRepository;    //一个公共方法供Controller调用，内部调用事务性的私有方法    public int createUserWrong1(String name) {        try {            this.createUserPrivate(new UserEntity(name));        } catch (Exception ex) {            log.error(&quot;create user failed because {}&quot;, ex.getMessage());        }        return userRepository.findByName(name).size();    }    //标记了@Transactional的private方法    @Transactional    private void createUserPrivate(UserEntity entity) {        userRepository.save(entity);        if (entity.getName().contains(&quot;test&quot;))            throw new RuntimeException(&quot;invalid username!&quot;);    }    //根据用户名查询用户数    public int getUserCount(String name) {        return userRepository.findByName(name).size();    }}</code></pre><p>下面是 Controller 的实现，只是调用一下刚才定义的 UserService 中的入口方法 createUserWrong1。</p><pre><code>@Autowiredprivate UserService userService;@GetMapping(&quot;wrong1&quot;)public int wrong1(@RequestParam(&quot;name&quot;) String name) {    return userService.createUserWrong1(name);}</code></pre><p>调用接口后发现，即便用户名不合法，用户也能创建成功。刷新浏览器，多次发现有十几个的非法用户注册。</p><ul><li>问题分析</li></ul><p>这里给出 @Transactional 生效原则 1，除非特殊配置（比如使用 AspectJ 静态织入实现 AOP），否则只有定义在 public 方法上的 @Transactional 才能生效。原因是，Spring 默认通过动态代理的方式实现 AOP，对目标方法进行增强，private 方法无法代理到，Spring 自然也无法动态增强事务处理逻辑。</p><p>根据这个原则1,我们进行一个小修改: 把标记了事务注解的 createUserPrivate 方法改为 public 即可。在 UserService 中再建一个入口方法 createUserWrong2，来调用这个 public 方法再次尝试：</p><pre><code>public int createUserWrong2(String name) {    try {        this.createUserPublic(new UserEntity(name));    } catch (Exception ex) {        log.error(&quot;create user failed because {}&quot;, ex.getMessage());    }  return userRepository.findByName(name).size();}//标记了@Transactional的public方法@Transactionalpublic void createUserPublic(UserEntity entity) {    userRepository.save(entity);    if (entity.getName().contains(&quot;test&quot;))        throw new RuntimeException(&quot;invalid username!&quot;);}</code></pre><p>测试发现,调用新的接口,方法事务同样不生效,由此我们得到了原则2: 必须通过代理的类从外部调用目标方法才能生效.<br>Spring通过AOP方法对方法进行增强,要调用增强过的方法必然是调用代理后的对象, 我们尝试修改下UserService的代码,注入一个self,然后再通过self实例调用标记有@Transactional注解的方法.<br>设置断点可以看到，self 是由 Spring 通过 CGLIB 方式增强过的类：</p><ul><li>CGLIB 通过继承方式实现代理类，private 方法在子类不可见，自然也就无法进行事务增强；</li><li>this 指针代表对象自己，Spring 不可能注入 this，所以通过 this 访问方法必然不是代理。</li></ul><p>把 this 改为 self 后测试发现，在 Controller 中调用 createUserRight 方法可以验证事务是生效的，非法的用户注册操作可以回滚。虽然在 UserService 内部注入自己调用自己的 createUserPublic 可以正确实现事务，但更合理的实现方式是，让 Controller 直接调用之前定义的 UserService 的 createUserPublic 方法，因为注入自己调用自己很奇怪，也不符合分层实现的规范：</p><pre><code>@GetMapping(&quot;right2&quot;)public int right2(@RequestParam(&quot;name&quot;) String name) {    try {        userService.createUserPublic(new UserEntity(name));    } catch (Exception ex) {        log.error(&quot;create user failed because {}&quot;, ex.getMessage());    }    return userService.getUserCount(name);}</code></pre><p>这里使用老师给的一个图来回顾一下三种方法的区别:<br><img src="https://s3.ax1x.com/2021/01/03/sCpOkn.png" alt="三种方法实现代理"></p><p>从图中可以发现,通过this自调用,没有机会走到spring的代理类;后两种改进方案调用的是spring注入的UserService,通过调用就有机会对createUserPublic方法进行动态增强.  </p><p>这里你可能会提出一个疑问: 直接把 createUserWrong2 方法加上 @Transactional 注解，然后在 Controller 中直接调用这个方法。这样一来，既能从外部（Controller 中）调用 UserService 中的方法，方法又是 public 的能够被动态代理 AOP 增强。为什么不这么做呢?</p><p>这就引出了第二个问题: 因为没有正确处理异常,导致事务即使生效也不一定回滚.  </p><h3 id="案例2-事务生效-但是回滚失败"><a href="#案例2-事务生效-但是回滚失败" class="headerlink" title="案例2: 事务生效,但是回滚失败"></a>案例2: 事务生效,但是回滚失败</h3><ul><li>问题描述</li></ul><p>通过AOP实现事务处理时,我们实际上是使用try-catch来包裹标记了@Transactional的注解的方法,当方法出现了异常并且满足<strong>一定条件</strong>的时候,在catch里面我们可以设置事务回滚,没有异常则直接提交事务.<br>这里的一定条件主要包含两点:<br>第一,只有异常传播出了标记@Transactional方法的时候才能回滚,在 Spring 的 TransactionAspectSupport 里有个 invokeWithinTransaction 方法，里面就是处理事务的逻辑。可以看到，只有捕获到异常才能进行后续事务处理：</p><pre><code>try {   // This is an around advice: Invoke the next interceptor in the chain.   // This will normally result in a target object being invoked.   retVal = invocation.proceedWithInvocation();}catch (Throwable ex) {   // target invocation exception   completeTransactionAfterThrowing(txInfo, ex);   throw ex;}finally {   cleanupTransactionInfo(txInfo);}</code></pre><p>第二,默认情况下,出现RuntimeException或者error的时候才会回滚<br>打开 Spring 的 DefaultTransactionAttribute 类能看到如下代码块，可以发现相关证据，通过注释也能看到 Spring 这么做的原因，大概的意思是受检异常一般是业务异常，或者说是类似另一种方法的返回值，出现这样的异常可能业务还能完成，所以不会主动回滚；而 Error 或 RuntimeException 代表了非预期的结果，应该回滚：</p><pre><code>/** * The default behavior is as with EJB: rollback on unchecked exception * ({@link RuntimeException}), assuming an unexpected outcome outside of any * business rules. Additionally, we also attempt to rollback on {@link Error} which * is clearly an unexpected outcome as well. By contrast, a checked exception is * considered a business exception and therefore a regular expected outcome of the * transactional business method, i.e. a kind of alternative return value which * still allows for regular completion of resource operations. * &lt;p&gt;This is largely consistent with TransactionTemplate&#39;s default behavior, * except that TransactionTemplate also rolls back on undeclared checked exceptions * (a corner case). For declarative transactions, we expect checked exceptions to be * intentionally declared as business exceptions, leading to a commit by default. * @see org.springframework.transaction.support.TransactionTemplate#execute */@Overridepublic boolean rollbackOn(Throwable ex) {   return (ex instanceof RuntimeException || ex instanceof Error);}</code></pre><ul><li>问题分析</li></ul><p>针对第一种情况, 我们可以手动设置让当前事务处于回滚状态.  </p><pre><code>@Transactionalpublic void createUserRight1(String name) {    try {        userRepository.save(new UserEntity(name));        throw new RuntimeException(&quot;error&quot;);    } catch (Exception ex) {        log.error(&quot;create user failed&quot;, ex);        TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();    }}</code></pre><p>针对第二种情况,在注解中声明,希望遇到的所有Exception都回滚事务</p><pre><code>@Transactional(rollbackFor = Exception.class)public void createUserRight2(String name) throws IOException {    userRepository.save(new UserEntity(name));    otherTask();}</code></pre><h3 id="案例3-请确认事务传播的配置是否符合自己的业务逻辑"><a href="#案例3-请确认事务传播的配置是否符合自己的业务逻辑" class="headerlink" title="案例3: 请确认事务传播的配置是否符合自己的业务逻辑"></a>案例3: 请确认事务传播的配置是否符合自己的业务逻辑</h3><ul><li>问题描述</li></ul><p>有这么一个场景：一个用户注册的操作，会插入一个主用户到用户表，还会注册一个关联的子用户。我们希望将子用户注册的数据库操作作为一个独立事务来处理，即使失败也不会影响主流程，即不影响主用户的注册。</p><pre><code>@Autowiredprivate UserRepository userRepository;@Autowiredprivate SubUserService subUserService;@Transactionalpublic void createUserWrong(UserEntity entity) {    createMainUser(entity);    subUserService.createSubUserWithExceptionWrong(entity);}private void createMainUser(UserEntity entity) {    userRepository.save(entity);    log.info(&quot;createMainUser finish&quot;);}</code></pre><p>SubUserService 的 createSubUserWithExceptionWrong 实现正如其名，因为最后我们抛出了一个运行时异常，错误原因是用户状态无效，所以子用户的注册肯定是失败的。我们期望子用户的注册作为一个事务单独回滚，不影响主用户的注册，这样的逻辑可以实现吗？</p><pre><code>@Service@Slf4jpublic class SubUserService {    @Autowired    private UserRepository userRepository;    @Transactional    public void createUserWrong2(UserEntity entity) {        createMainUser(entity);        try{            subUserService.createSubUserWithExceptionWrong(entity);        } catch (Exception ex) {            // 虽然捕获了异常，但是因为没有开启新事务，而当前事务因为异常已经被标记为rollback了，所以最终还是会回滚。            log.error(&quot;create sub user error:{}&quot;, ex.getMessage());        }    }}我们在 Controller 里实现一段测试代码，调用 UserService：@GetMapping(&quot;wrong&quot;)public int wrong(@RequestParam(&quot;name&quot;) String name) {    try {        userService.createUserWrong(new UserEntity(name));    } catch (Exception ex) {        log.error(&quot;createUserWrong failed, reason:{}&quot;, ex.getMessage());    }    return userService.getUserCount(name);}</code></pre><p>调用后产出以下日志:</p><pre><code>[22:57:21.722] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :370 ] - Creating new transaction with name [org.geekbang.time.commonmistakes.transaction.demo3.UserService.createUserWrong2]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT[22:57:21.739] [http-nio-45678-exec-3] [INFO ] [t.c.transaction.demo3.SubUserService:19  ] - createSubUserWithExceptionWrong start[22:57:21.739] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :356 ] - Found thread-bound EntityManager [SessionImpl(1794007607&lt;open&gt;)] for JPA transaction[22:57:21.739] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :471 ] - Participating in existing transaction[22:57:21.740] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :843 ] - Participating transaction failed - marking existing transaction as rollback-only[22:57:21.740] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :580 ] - Setting JPA transaction on EntityManager [SessionImpl(1794007607&lt;open&gt;)] rollback-only[22:57:21.740] [http-nio-45678-exec-3] [ERROR] [.g.t.c.transaction.demo3.UserService:37  ] - create sub user error:invalid status[22:57:21.740] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :741 ] - Initiating transaction commit[22:57:21.740] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :529 ] - Committing JPA transaction on EntityManager [SessionImpl(1794007607&lt;open&gt;)][22:57:21.743] [http-nio-45678-exec-3] [DEBUG] [o.s.orm.jpa.JpaTransactionManager       :620 ] - Closing JPA EntityManager [SessionImpl(1794007607&lt;open&gt;)] after transaction[22:57:21.743] [http-nio-45678-exec-3] [ERROR] [t.d.TransactionPropagationController:33  ] - createUserWrong2 failed, reason:Transaction silently rolled back because it has been marked as rollback-onlyorg.springframework.transaction.UnexpectedRollbackException: Transaction silently rolled back because it has been marked as rollback-only...</code></pre><p>这里面有一个奇怪的事情: 第11和12行显示,Controller里出现了一个UnexpectedRollbackException,异常描述显示这个事务回滚了,而且是静默回滚的,静默的原因是虽然没有出现异常,但是提交之后发现子方法已经把当前的事务设置为了回滚.<br>这里就得出了一个结论: 在同一个事务中,如果子逻辑标记了事务需要回滚,主逻辑也不能提交.  </p><p>修复的方法也非常简单,有一个专门的注解: <code>@Transactional(propagation = Propagation.REQUIRES_NEW)</code><br>效果是执行到这个方法的时候需要开启新的事务, 并挂起当前事务.  </p><pre><code>@Transactional(propagation = Propagation.REQUIRES_NEW)public void createSubUserWithExceptionRight(UserEntity entity) {    log.info(&quot;createSubUserWithExceptionRight start&quot;);    userRepository.save(entity);    throw new RuntimeException(&quot;invalid status&quot;);}</code></pre><p>主方法没什么变化,同样需要捕获异常,防止异常泄漏出去导致主事务回滚,重新命名为createUserRight: </p><pre><code>@Transactionalpublic void createUserRight(UserEntity entity) {    createMainUser(entity);    try{        subUserService.createSubUserWithExceptionRight(entity);    } catch (Exception ex) {        // 捕获异常，防止主方法回滚        log.error(&quot;create sub user error:{}&quot;, ex.getMessage());    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_5</title>
      <link href="/2020/12/30/java-kai-fa-chang-jian-cuo-wu-5/"/>
      <url>/2020/12/30/java-kai-fa-chang-jian-cuo-wu-5/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="5-HTTP调用：你考虑到超时、重试、并发了吗？"><a href="#5-HTTP调用：你考虑到超时、重试、并发了吗？" class="headerlink" title="5.HTTP调用：你考虑到超时、重试、并发了吗？"></a>5.HTTP调用：你考虑到超时、重试、并发了吗？</h2><h3 id="案例1-http请求的超时处理"><a href="#案例1-http请求的超时处理" class="headerlink" title="案例1: http请求的超时处理"></a>案例1: http请求的超时处理</h3><p>进行 HTTP 调用本质上是通过 HTTP 协议进行一次网络请求。网络请求必然有超时的可能性，因此我们必须考虑到这三点：<br>1, 框架设置的默认超时是否合理；<br>2, 考虑到网络的不稳定性,超时后的请求重试是一个不错的选择,但需要考虑服务端接口的幂等性的设计;<br>3, 需要考虑并发连接数的限制.  </p><p>如果使用 Spring Cloud 进行微服务开发，就会使用 Feign 进行声明式的服务调用。如果不使用 Spring Cloud，而直接使用 Spring Boot 进行微服务开发的话，可能会直接使用 Java 中最常用的 HTTP 客户端 Apache HttpClient 进行服务调用.  </p><ul><li>问题描述</li></ul><p>对于 HTTP 调用，虽然应用层走的是 HTTP 协议，但网络层面始终是 TCP/IP 协议。TCP/IP 是面向连接的协议，在传输数据之前需要建立连接。几乎所有的网络框架都会提供这么两个超时参数：<br>连接超时参数 ConnectTimeout，让用户配置建连阶段的最长等待时间；<br>读取超时参数 ReadTimeout，用来控制从 Socket 上读取数据的最长等待时间。  </p><p>连接超时常见误区有如下几点:<br>1, 连接超时配置得特别长，比如 60 秒,一般来说TCP三次握手在毫秒级别即可完成,因此只需要配置个位数秒即可,这样在下游服务离线无法连接的时候可以快速失败报错.<br>2, 排查连接超时问题，却没理清连的是哪里。通常情况下，我们的服务会有多个节点，如果别的客户端通过客户端负载均衡技术来连接服务端，那么客户端和服务端会直接建立连接，此时出现连接超时大概率是服务端的问题；而如果服务端通过类似 Nginx 的反向代理来负载均衡，客户端连接的其实是 Nginx，而不是服务端，此时出现连接超时应该排查 Nginx.  </p><p>读取超时参数和读取超时则会有更多的误区:<br><strong>第一个误区</strong>:<br>认为出现了读取超时,服务端的执行就会中断.  </p><p>我们来简单测试下。定义一个 client 接口，内部通过 HttpClient 调用服务端接口 server，客户端读取超时 2 秒，服务端接口执行耗时 5 秒。</p><pre><code>@RestController@RequestMapping(&quot;clientreadtimeout&quot;)@Slf4jpublic class ClientReadTimeoutController {    private String getResponse(String url, int connectTimeout, int readTimeout) throws IOException {        return Request.Get(&quot;http://localhost:45678/clientreadtimeout&quot; + url)                .connectTimeout(connectTimeout)                .socketTimeout(readTimeout)                .execute()                .returnContent()                .asString();    }    @GetMapping(&quot;client&quot;)    public String client() throws IOException {        log.info(&quot;client1 called&quot;);        //服务端5s超时，客户端读取超时2秒        return getResponse(&quot;/server?timeout=5000&quot;, 1000, 2000);    }    @GetMapping(&quot;server&quot;)    public void server(@RequestParam(&quot;timeout&quot;) int timeout) throws InterruptedException {        log.info(&quot;server called&quot;);        TimeUnit.MILLISECONDS.sleep(timeout);        log.info(&quot;Done&quot;);    }}</code></pre><p>执行日志:</p><pre><code>[11:35:11.943] [http-nio-45678-exec-1] [INFO ] [.t.c.c.d.ClientReadTimeoutController:29  ] - client1 called[11:35:12.032] [http-nio-45678-exec-2] [INFO ] [.t.c.c.d.ClientReadTimeoutController:36  ] - server called[11:35:14.042] [http-nio-45678-exec-1] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exceptionjava.net.SocketTimeoutException: Read timed out  at java.net.SocketInputStream.socketRead0(Native Method)  ...[11:35:17.036] [http-nio-45678-exec-2] [INFO ] [.t.c.c.d.ClientReadTimeoutController:38  ] - Done</code></pre><p>从日志中可以看出,客户端两秒之后出现了SocketTimeoutException,但是服务端没有受到任何影响,在3秒后执行完成.<br>因此类似Tomcat这样的Web服务器都是把服务端请求提交到线程池处理的,只要服务端收到了请求,网络层面的超时或者断开就不会影响服务端的执行,这也是不能盲目重试的一个重要原因.</p><p><strong>第二个误区</strong><br>认为读取超时只是Socket网络层面的概念,是数据传输的最长耗时,因此配置的非常短.  </p><p>当发生了读取超时的时候,网络层面无法区分是服务端没有返回数据,还是数据在网络上耗时较久,但是因为TCP是先建立连接后传输数据,对于网络情况不是特别糟糕的服务调用,连接超时一般是网络问题或者服务不在线,而出现读取超时一般是服务处理超时.</p><p><strong>第三个误区</strong><br>认为超时时间越长,任务接口的成功率就越高,将读取超时参数配置的太长.  </p><p>进行 HTTP 请求一般是需要获得结果的，属于同步调用。如果超时时间很长，在等待服务端返回数据的同时，客户端线程（通常是 Tomcat线程）也在等待，当下游服务出现大量超时的时候，程序可能也会受到拖累创建大量线程，最终崩溃。对定时任务或异步任务来说，读取超时配置得长些问题不大。但面向用户响应的请求或是微服务短平快的同步接口调用，并发量一般较大，我们应该设置一个较短的读取超时时间，以防止被下游服务拖慢，通常不会设置超过 30 秒的读取超时。<br>你可能会说，如果把读取超时设置为 2 秒，服务端接口需要 3<br> 秒，岂不是永远都拿不到执行结果了？的确是这样，因此设置读取超时一定要根据实际情况，过长可能会让下游抖动影响到自己，过短又可能影响成功率。甚至，有些时候我们还要根据下游服务的 SLA，为不同的服务端接口设置不同的客户端读取超时。  </p><h3 id="案例2-Feign-和-Ribbon-配合使用，你知道怎么配置超时吗？"><a href="#案例2-Feign-和-Ribbon-配合使用，你知道怎么配置超时吗？" class="headerlink" title="案例2: Feign 和 Ribbon 配合使用，你知道怎么配置超时吗？"></a>案例2: Feign 和 Ribbon 配合使用，你知道怎么配置超时吗？</h3><ul><li><p>问题描述</p><p>为 Feign 配置超时参数的复杂之处在于，Feign 自己有两个超时参数，它使用的负载均衡组件 Ribbon 本身还有相关配置。</p></li></ul><p>为测试服务端的超时，假设有这么一个服务端接口，什么都不干只休眠 10 分钟：</p><pre><code>@PostMapping(&quot;/server&quot;)public void server() throws InterruptedException {    TimeUnit.MINUTES.sleep(10);}</code></pre><p>定义一个Feign来调用这个接口,并通过Feign Client进行接口调用:</p><pre><code>@FeignClient(name = &quot;clientsdk&quot;)public interface Client {    @PostMapping(&quot;/feignandribbon/server&quot;)    void server();}@GetMapping(&quot;client&quot;)public void timeout() {    long begin=System.currentTimeMillis();    try{        client.server();    }catch (Exception ex){        log.warn(&quot;执行耗时：{}ms 错误：{}&quot;, System.currentTimeMillis() - begin, ex.getMessage());    }}</code></pre><p>在配置文件仅指定服务端地址的情况下,得到如下输出:</p><pre><code>clientsdk.ribbon.listOfServers=localhost:45678[15:40:16.094] [http-nio-45678-exec-3] [WARN ] [o.g.t.c.h.f.FeignAndRibbonController    :26  ] - 执行耗时：1007ms 错误：Read timed out executing POST http://clientsdk/feignandribbon/server</code></pre><p>从这个输出中我们可以得到结论一: <strong>默认情况下,Feign的读取超时时间是1秒.</strong>(非常的短)<br>打开RibbonClientConfiguration看下,会发现DefaultClientConfigImpl被创建出来之后ReadTimeout 和 ConnectTimeout 被设置为 1s.</p><pre><code>/** * Ribbon client default connect timeout. */public static final int DEFAULT_CONNECT_TIMEOUT = 1000;/** * Ribbon client default read timeout. */public static final int DEFAULT_READ_TIMEOUT = 1000;@Bean@ConditionalOnMissingBeanpublic IClientConfig ribbonClientConfig() {   DefaultClientConfigImpl config = new DefaultClientConfigImpl();   config.loadProperties(this.name);   config.set(CommonClientConfigKey.ConnectTimeout, DEFAULT_CONNECT_TIMEOUT);   config.set(CommonClientConfigKey.ReadTimeout, DEFAULT_READ_TIMEOUT);   config.set(CommonClientConfigKey.GZipPayload, DEFAULT_GZIP_PAYLOAD);   return config;}</code></pre><p>因此如果要修改Feign客户端默认的两个全局超时时间,可以设置:</p><pre><code>feign.client.config.default.readTimeout=3000feign.client.config.default.connectTimeout=3000</code></pre><p>注意,这里会有一个错误,如果你希望只修改读取超时而只修改了readTimeout,配置是无法生效的!<br>因此我们得到结论二: <strong>如果要配置 Feign 的读取超时，就必须同时配置连接超时，才能生效。</strong><br>原因是,打开 FeignClientFactoryBean 可以看到，只有同时设置 ConnectTimeout 和 ReadTimeout，Request.Options 才会被覆盖：</p><pre class="line-numbers language-$xslt"><code class="language-$xslt">if (config.getConnectTimeout() != null && config.getReadTimeout() != null) {   builder.options(new Request.Options(config.getConnectTimeout(),         config.getReadTimeout()));}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>更进一步,如果你希望单独针对Feign Client设置超时时间,可以把default替换为Client的name:</p><pre><code>feign.client.config.default.readTimeout=3000feign.client.config.default.connectTimeout=3000feign.client.config.clientsdk.readTimeout=2000feign.client.config.clientsdk.connectTimeout=2000</code></pre><p>由此得出结论三: <strong>单独的超时可以覆盖全局超时</strong></p><p>这里还要提出一个结论四: <strong>除了可以配置 Feign，也可以配置 Ribbon 组件的参数来修改两个超时时间。这里的坑点是，参数首字母要大写，和 Feign 的配置不同。</strong></p><pre><code>ribbon.ReadTimeout=4000ribbon.ConnectTimeout=4000</code></pre><p>结论五: <strong>同时配置 Feign 和 Ribbon 的超时，以 Feign 为准</strong><br>原因是在 LoadBalancerFeignClient 源码中可以看到，如果 Request.Options 不是默认值，就会创建一个 FeignOptionsClientConfig 代替原来 Ribbon的 DefaultClientConfigImpl，导致 Ribbon 的配置被 Feign 覆盖.  </p><pre><code>IClientConfig getClientConfig(Request.Options options, String clientName) {   IClientConfig requestConfig;   if (options == DEFAULT_OPTIONS) {      requestConfig = this.clientFactory.getClientConfig(clientName);   }   else {      requestConfig = new FeignOptionsClientConfig(options);   }   return requestConfig;}</code></pre><p>但是如果这么配置的话最终生效的是Ribbon,其实这还是坑2所致,单独配置Feign的读取超时并不能生效.  </p><h3 id="案例3-Ribbon会自动重试请求"><a href="#案例3-Ribbon会自动重试请求" class="headerlink" title="案例3: Ribbon会自动重试请求"></a>案例3: Ribbon会自动重试请求</h3><p>之前遇到过一个短信重复发送的问题，但短信服务的调用方用户服务，反复确认代码里没有重试逻辑。那问题究竟出在哪里了？我们来重现一下这个案例。首先，定义一个 Get 请求的发送短信接口，里面没有任何逻辑，休眠 2 秒模拟耗时：</p><pre><code>@RestController@RequestMapping(&quot;ribbonretryissueserver&quot;)@Slf4jpublic class RibbonRetryIssueServerController {    @GetMapping(&quot;sms&quot;)    public void sendSmsWrong(@RequestParam(&quot;mobile&quot;) String mobile, @RequestParam(&quot;message&quot;) String message, HttpServletRequest request) throws InterruptedException {        //输出调用参数后休眠2秒        log.info(&quot;{} is called, {}=&gt;{}&quot;, request.getRequestURL().toString(), mobile, message);        TimeUnit.SECONDS.sleep(2);    }}配置一个 Feign 供客户端调用：@FeignClient(name = &quot;SmsClient&quot;)public interface SmsClient {    @GetMapping(&quot;/ribbonretryissueserver/sms&quot;)    void sendSmsWrong(@RequestParam(&quot;mobile&quot;) String mobile, @RequestParam(&quot;message&quot;) String message);}Feign 内部有一个 Ribbon 组件负责客户端负载均衡，通过配置文件设置其调用的服务端为两个节点：SmsClient.ribbon.listOfServers=localhost:45679,localhost:45678写一个客户端接口，通过 Feign 调用服务端：@RestController@RequestMapping(&quot;ribbonretryissueclient&quot;)@Slf4jpublic class RibbonRetryIssueClientController {    @Autowired    private SmsClient smsClient;    @GetMapping(&quot;wrong&quot;)    public String wrong() {        log.info(&quot;client is called&quot;);        try{            //通过Feign调用发送短信接口            smsClient.sendSmsWrong(&quot;13600000000&quot;, UUID.randomUUID().toString());        } catch (Exception ex) {            //捕获可能出现的网络错误            log.error(&quot;send sms failed : {}&quot;, ex.getMessage());        }        return &quot;done&quot;;    }}</code></pre><p>在 45678 和 45679 两个端口上分别启动服务端，然后访问 45678 的客户端接口进行测试。因为客户端和服务端控制器在一个应用中，所以 45678 同时扮演了客户端和服务端的角色。<br>在 45678 日志中可以看到，29 秒时客户端收到请求开始调用服务端接口发短信，同时服务端收到了请求，2 秒后（注意对比第一条日志和第三条日志）客户端输出了读取超时的错误信息：</p><pre><code>[12:49:29.020] [http-nio-45678-exec-4] [INFO ] [c.d.RibbonRetryIssueClientController:23  ] - client is called[12:49:29.026] [http-nio-45678-exec-5] [INFO ] [c.d.RibbonRetryIssueServerController:16  ] - http://localhost:45678/ribbonretryissueserver/sms is called, 13600000000=&gt;a2aa1b32-a044-40e9-8950-7f0189582418[12:49:31.029] [http-nio-45678-exec-4] [ERROR] [c.d.RibbonRetryIssueClientController:27  ] - send sms failed : Read timed out executing GET http://SmsClient/ribbonretryissueserver/sms?mobile=13600000000&amp;message=a2aa1b32-a044-40e9-8950-7f0189582418</code></pre><p>而在另一个服务端 45679 的日志中还可以看到一条请求，30 秒时收到请求，也就是客户端接口调用后的 1 秒：</p><pre><code>[12:49:30.029] [http-nio-45679-exec-2] [INFO ] [c.d.RibbonRetryIssueServerController:16  ] - http://localhost:45679/ribbonretryissueserver/sms is called, 13600000000=&gt;a2aa1b32-a044-40e9-8950-7f0189582418</code></pre><p>客户端接口被调用的日志只输出了一次，而服务端的日志输出了两次。虽然 Feign 的默认读取超时时间是 1 秒，但客户端 2 秒后才出现超时错误。显然，这说明客户端自作主张进行了一次重试，导致短信重复发送。<br>翻看 Ribbon 的源码可以发现，MaxAutoRetriesNextServer 参数默认为 1，也就是 Get 请求在某个服务端节点出现问题（比如读取超时）时，Ribbon 会自动重试一次：</p><pre><code>// DefaultClientConfigImplpublic static final int DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER = 1;public static final int DEFAULT_MAX_AUTO_RETRIES = 0;// RibbonLoadBalancedRetryPolicypublic boolean canRetry(LoadBalancedRetryContext context) {   HttpMethod method = context.getRequest().getMethod();   return HttpMethod.GET == method || lbContext.isOkToRetryOnAllOperations();}@Overridepublic boolean canRetrySameServer(LoadBalancedRetryContext context) {   return sameServerCount &lt; lbContext.getRetryHandler().getMaxRetriesOnSameServer()         &amp;&amp; canRetry(context);}@Overridepublic boolean canRetryNextServer(LoadBalancedRetryContext context) {   // this will be called after a failure occurs and we increment the counter   // so we check that the count is less than or equals to too make sure   // we try the next server the right number of times   return nextServerCount &lt;= lbContext.getRetryHandler().getMaxRetriesOnNextServer()         &amp;&amp; canRetry(context);}</code></pre><ul><li>问题解决</li></ul><p>解决的办法有两个,把Get改成Post请求,或者在配置中把重试次数置为0;</p><h3 id="案例四-并发限制了爬虫的抓取能力"><a href="#案例四-并发限制了爬虫的抓取能力" class="headerlink" title="案例四: 并发限制了爬虫的抓取能力"></a>案例四: 并发限制了爬虫的抓取能力</h3><p>之前遇到过一个爬虫项目，整体爬取数据的效率很低，增加线程池数量也无济于事，只能堆更多的机器做分布式的爬虫。现在，我们就来模拟下这个场景，看看问题出在了哪里。<br>假设要爬取的服务端如下:</p><pre><code>@GetMapping(&quot;server&quot;)public int server() throws InterruptedException {    TimeUnit.SECONDS.sleep(1);    return 1;}</code></pre><p>爬虫需要多次调用这个接口进行数据抓取，为了确保线程池不是并发的瓶颈，我们使用一个没有线程上限的 newCachedThreadPool 作为爬取任务的线程池（再次强调，除非你非常清楚自己的需求，否则一般不要使用没有线程数量上限的线程池），然后使用 HttpClient 实现 HTTP 请求，把请求任务循环提交到线程池处理，最后等待所有任务执行完成后输出执行耗时：</p><pre><code>private int sendRequest(int count, Supplier&lt;CloseableHttpClient&gt; client) throws InterruptedException {    //用于计数发送的请求个数    AtomicInteger atomicInteger = new AtomicInteger();    //使用HttpClient从server接口查询数据的任务提交到线程池并行处理    ExecutorService threadPool = Executors.newCachedThreadPool();    long begin = System.currentTimeMillis();    IntStream.rangeClosed(1, count).forEach(i -&gt; {        threadPool.execute(() -&gt; {            try (CloseableHttpResponse response = client.get().execute(new HttpGet(&quot;http://127.0.0.1:45678/routelimit/server&quot;))) {                atomicInteger.addAndGet(Integer.parseInt(EntityUtils.toString(response.getEntity())));            } catch (Exception ex) {                ex.printStackTrace();            }        });    });    //等到count个任务全部执行完毕    threadPool.shutdown();    threadPool.awaitTermination(1, TimeUnit.HOURS);    log.info(&quot;发送 {} 次请求，耗时 {} ms&quot;, atomicInteger.get(), System.currentTimeMillis() - begin);    return atomicInteger.get();}</code></pre><p>首先，使用默认的 PoolingHttpClientConnectionManager 构造的 CloseableHttpClient，测试一下爬取 10 次的耗时：</p><pre><code>static CloseableHttpClient httpClient1;static {    httpClient1 = HttpClients.custom().setConnectionManager(new PoolingHttpClientConnectionManager()).build();}@GetMapping(&quot;wrong&quot;)public int wrong(@RequestParam(value = &quot;count&quot;, defaultValue = &quot;10&quot;) int count) throws InterruptedException {    return sendRequest(count, () -&gt; httpClient1);}</code></pre><p>按道理说,10个线程并发执行,应该和一个线程耗时相同,但是实际上日志显示耗时5秒;<br>查看 PoolingHttpClientConnectionManager 源码，可以注意到有两个重要参数：<br>defaultMaxPerRoute=2，也就是同一个主机 / 域名的最大并发请求数为 2。我们的爬虫需要 10 个并发，显然是默认值太小限制了爬虫的效率。<br>maxTotal=20，也就是所有主机整体最大并发为 20，这也是 HttpClient 整体的并发度。目前，我们请求数是 10 最大并发是 10，20 不会成为瓶颈。举一个例子，使用同一个 HttpClient 访问 10 个域名，defaultMaxPerRoute 设置为 10，为确保每一个域名都能达到 10 并发，需要把 maxTotal 设置为 100。</p><pre><code>public PoolingHttpClientConnectionManager(    final HttpClientConnectionOperator httpClientConnectionOperator,    final HttpConnectionFactory&lt;HttpRoute, ManagedHttpClientConnection&gt; connFactory,    final long timeToLive, final TimeUnit timeUnit) {    ...        this.pool = new CPool(new InternalConnectionFactory(            this.configData, connFactory), 2, 20, timeToLive, timeUnit);   ...} public CPool(        final ConnFactory&lt;HttpRoute, ManagedHttpClientConnection&gt; connFactory,        final int defaultMaxPerRoute, final int maxTotal,        final long timeToLive, final TimeUnit timeUnit) {    ...}}</code></pre><p>既然知道了问题所在，我们就尝试声明一个新的 HttpClient 放开相关限制，设置 maxPerRoute 为 50、maxTotal 为 100，然后修改一下刚才的 wrong 方法，使用新的客户端进行测试：</p><pre><code>httpClient2 = HttpClients.custom().setMaxConnPerRoute(10).setMaxConnTotal(20).build();</code></pre><p>效率得到了极大的提升.  </p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_4</title>
      <link href="/2020/12/28/java-kai-fa-chang-jian-cuo-wu-4/"/>
      <url>/2020/12/28/java-kai-fa-chang-jian-cuo-wu-4/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="4-连接池：别让连接池帮了倒忙"><a href="#4-连接池：别让连接池帮了倒忙" class="headerlink" title="4.连接池：别让连接池帮了倒忙"></a>4.连接池：别让连接池帮了倒忙</h2><p>连接池一般对外提供获得连接,归还连接的接口给客户端使用,并暴露最小空闲连接数,最大连接数等可配置参数.<br>在内部则实现连接建立,连接心跳保持,空闲连接回收,连接可用性检测等功能.<br>如下图所示:<br><img src="https://s3.ax1x.com/2020/12/28/rIje2j.png" alt="连接池架构"><br>业务中主要使用的连接池一般是数据库连接池,Redis连接池,HTTP连接池.</p><h3 id="案例1-注意鉴别SDK是否基于连接池"><a href="#案例1-注意鉴别SDK是否基于连接池" class="headerlink" title="案例1: 注意鉴别SDK是否基于连接池"></a>案例1: 注意鉴别SDK是否基于连接池</h3><ul><li>问题描述</li></ul><p>首先介绍TCP协议:<br>TCP 是面向连接的基于字节流的协议,面向连接，意味着连接需要先创建再使用，创建连接的三次握手有一定开销；基于字节流，意味着字节是发送数据的最小单元，TCP 协议本身无法区分哪几个字节是完整的消息体，也无法感知是否有多个客户端在使用同一个 TCP 连接，TCP 只是一个读写数据的管道。</p><p>所以如果SDK没有使用连接池,而是直接使用TCP连接,那么就要考虑每次建立TCP连接的开销.并且因为TCP基于字节流,如果在多线程并发的情况下对同一连接进行复用,可能会产生线程安全问题.  </p><p>所以当我们面对一个第三方连接客户端的时候,首先要判断本方法是属于以下哪种情形:<br>1, 连接池和连接分离的API, 有一个XXXPool类负责连接池实现,先从其获得XXXConnection,然后用获得的链接进行服务端请求,完成后使用者需要归还连接.通常Pool是线程安全的,可以并发获取和归还连接.而XXXConnection是非线程安全的,对应到连接池的结构示意图中，XXXPool 就是右边连接池那个框，左边的客户端是我们自己的代码。<br>2, 内部带有连接池的 API：对外提供一个 XXXClient 类，通过这个类可以直接进行服务端请求；这个类内部维护了连接池，SDK 使用者无需考虑连接的获取和归还问题。一般而言，XXXClient 是线程安全的。对应到连接池的结构示意图中，整个 API 就是蓝色框包裹的部分。<br>3, 非连接池的 API：一般命名为 XXXConnection，以区分其是基于连接池还是单连接的，而不建议命名为 XXXClient 或直接是 XXX。直接连接方式的 API 基于单一连接，每次使用都需要创建和断开连接，性能一般，且通常不是线程安全的。对应到连接池的结构示意图中，这种形式相当于没有右边连接池那个框，客户端直接连接服务端创建连接。<br>切记一定要查看官方文档了解其最佳实践,或者在Stack Overflow上搜一下这个对应的库是否可以正常工作,或者一层层看源码,定位到原始的socket来判断Socket和客户端API之间的对应关系.</p><p>在明确了sdk连接池的实现方式只会,我们就可以按照如下原则判断使用:<br>如果是分离方式，那么连接池本身一般是线程安全的，可以复用。每次使用需要从连接池获取连接，使用后归还，归还的工作由使用者负责。<br>如果是内置连接池，SDK 会负责连接的获取和归还，使用的时候直接复用客户端.<br>如果 SDK 没有实现连接池（大多数中间件、数据库的客户端 SDK 都会支持连接池），那通常不是线程安全的，而且短连接的方式性能不会很高，使用的时候需要考虑是否自己封装一个连接池(<strong>强烈建议不要使用这种方式</strong>)</p><p>这里举一个Jedis的例子:<br>首先，向 Redis 初始化 2 组数据，Key=a、Value=1，Key=b、Value=2</p><pre><code>@PostConstructpublic void init() {    try (Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379)) {        Assert.isTrue(&quot;OK&quot;.equals(jedis.set(&quot;a&quot;, &quot;1&quot;)), &quot;set a = 1 return OK&quot;);        Assert.isTrue(&quot;OK&quot;.equals(jedis.set(&quot;b&quot;, &quot;2&quot;)), &quot;set b = 2 return OK&quot;);    }}</code></pre><p>然后，启动两个线程，共享操作同一个 Jedis 实例，每一个线程循环 1000 次，分别读取 Key 为 a 和 b 的 Value，判断是否分别为 1 和 2：</p><pre><code>Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);new Thread(() -&gt; {    for (int i = 0; i &lt; 1000; i++) {        String result = jedis.get(&quot;a&quot;);        if (!result.equals(&quot;1&quot;)) {            log.warn(&quot;Expect a to be 1 but found {}&quot;, result);            return;        }    }}).start();new Thread(() -&gt; {    for (int i = 0; i &lt; 1000; i++) {        String result = jedis.get(&quot;b&quot;);        if (!result.equals(&quot;2&quot;)) {            log.warn(&quot;Expect b to be 2 but found {}&quot;, result);            return;        }    }}).start();TimeUnit.SECONDS.sleep(5);</code></pre><p>执行程序多次,会发现日志中出现了很多奇怪的异常信息,包含非正常结束,参数错误,连接关闭异常等等</p><pre><code>//错误1[14:56:19.069] [Thread-28] [WARN ] [.t.c.c.redis.JedisMisreuseController:45  ] - Expect b to be 2 but found 1//错误2redis.clients.jedis.exceptions.JedisConnectionException: Unexpected end of stream.  at redis.clients.jedis.util.RedisInputStream.ensureFill(RedisInputStream.java:202)  at redis.clients.jedis.util.RedisInputStream.readLine(RedisInputStream.java:50)  at redis.clients.jedis.Protocol.processError(Protocol.java:114)  at redis.clients.jedis.Protocol.process(Protocol.java:166)  at redis.clients.jedis.Protocol.read(Protocol.java:220)  at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:318)  at redis.clients.jedis.Connection.getBinaryBulkReply(Connection.java:255)  at redis.clients.jedis.Connection.getBulkReply(Connection.java:245)  at redis.clients.jedis.Jedis.get(Jedis.java:181)  at org.geekbang.time.commonmistakes.connectionpool.redis.JedisMisreuseController.lambda$wrong$1(JedisMisreuseController.java:43)  at java.lang.Thread.run(Thread.java:748)//错误3java.io.IOException: Socket Closed  at java.net.AbstractPlainSocketImpl.getOutputStream(AbstractPlainSocketImpl.java:440)  at java.net.Socket$3.run(Socket.java:954)  at java.net.Socket$3.run(Socket.java:952)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.Socket.getOutputStream(Socket.java:951)  at redis.clients.jedis.Connection.connect(Connection.java:200)  ... 7 more</code></pre><ul><li>问题分析</li></ul><p>分析一下Jedis的源码:</p><pre><code>public class Jedis extends BinaryJedis implements JedisCommands, MultiKeyCommands,    AdvancedJedisCommands, ScriptingCommands, BasicCommands, ClusterCommands, SentinelCommands, ModuleCommands {}public class BinaryJedis implements BasicCommands, BinaryJedisCommands, MultiKeyBinaryCommands,    AdvancedBinaryJedisCommands, BinaryScriptingCommands, Closeable {  protected Client client = null;      ...}public class Client extends BinaryClient implements Commands {}public class BinaryClient extends Connection {}public class Connection implements Closeable {  private Socket socket;  private RedisOutputStream outputStream;  private RedisInputStream inputStream;}</code></pre><p>可以看到,Jedis继承了BinaryJedis,BinaryJedis保存了单个Client实例,Client继承了Connection,Connection中保存了Socket实例,和Socket对应的两个读写流.<br>BinaryClient 封装了各种 Redis 命令，其最终会调用基类 Connection 的方法，使用 Protocol 类发送命令。看一下 Protocol 类的 sendCommand 方法的源码，可以发现其发送命令时是直接操作 RedisOutputStream 写入字节。我们在多线程环境下复用 Jedis 对象，其实就是在复用 RedisOutputStream。如果多个线程在执行操作，那么既无法确保整条命令以一个原子操作写入 Socket，也无法确保写入后、读取前没有其他数据写到远端：</p><pre><code>private static void sendCommand(final RedisOutputStream os, final byte[] command,    final byte[]... args) {  try {    os.write(ASTERISK_BYTE);    os.writeIntCrLf(args.length + 1);    os.write(DOLLAR_BYTE);    os.writeIntCrLf(command.length);    os.write(command);    os.writeCrLf();    for (final byte[] arg : args) {      os.write(DOLLAR_BYTE);      os.writeIntCrLf(arg.length);      os.write(arg);      os.writeCrLf();    }  } catch (IOException e) {    throw new JedisConnectionException(e);  }}</code></pre><ul><li>问题总结</li></ul><p>看到这大家应该明白了,Jedis实例在多线程情况下是不可复用的,修复的方法也很简单,使用 Jedis 提供的另一个线程安全的类 JedisPool 来获得 Jedis 的实例。JedisPool 可以声明为 static 在多个线程之间共享，扮演连接池的角色。使用时，按需使用 try-with-resources 模式从 JedisPool 获得和归还 Jedis 实例。</p><pre><code>private static JedisPool jedisPool = new JedisPool(&quot;127.0.0.1&quot;, 6379);new Thread(() -&gt; {    try (Jedis jedis = jedisPool.getResource()) {        for (int i = 0; i &lt; 1000; i++) {            String result = jedis.get(&quot;a&quot;);            if (!result.equals(&quot;1&quot;)) {                log.warn(&quot;Expect a to be 1 but found {}&quot;, result);                return;            }        }    }}).start();new Thread(() -&gt; {    try (Jedis jedis = jedisPool.getResource()) {        for (int i = 0; i &lt; 1000; i++) {            String result = jedis.get(&quot;b&quot;);            if (!result.equals(&quot;2&quot;)) {                log.warn(&quot;Expect b to be 2 but found {}&quot;, result);                return;            }        }    }}).start();</code></pre><p>此外,我们还需要通过shutdownhook,在程序退出之前关闭JedisPool:</p><pre><code>@PostConstructpublic void init() {    Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; {        jedisPool.close();    }));}</code></pre><p>我们再看一下Jedis的close方法,如果Jedis是从连接池获取的话,close方法会调用连接池的return方法归还连接.  </p><pre><code>public class Jedis extends BinaryJedis implements JedisCommands, MultiKeyCommands,    AdvancedJedisCommands, ScriptingCommands, BasicCommands, ClusterCommands, SentinelCommands, ModuleCommands {  protected JedisPoolAbstract dataSource = null;  @Override  public void close() {    if (dataSource != null) {      JedisPoolAbstract pool = this.dataSource;      this.dataSource = null;      if (client.isBroken()) {        pool.returnBrokenResource(this);      } else {        pool.returnResource(this);      }    } else {      super.close();    }  }}</code></pre><p>如果不是的话,就直接关闭连接,其最终调用Connection 类的disconnect 方法来关闭TCP连接:</p><pre><code>public void disconnect() {  if (isConnected()) {    try {      outputStream.flush();      socket.close();    } catch (IOException ex) {      broken = true;      throw new JedisConnectionException(ex);    } finally {      IOUtils.closeQuietly(socket);    }  }}</code></pre><p>我们再看看JedisPool的实现:</p><pre><code>public class JedisPool extends JedisPoolAbstract {@Override  public Jedis getResource() {    Jedis jedis = super.getResource();    jedis.setDataSource(this);    return jedis;  }  @Override  protected void returnResource(final Jedis resource) {    if (resource != null) {      try {        resource.resetState();        returnResourceObject(resource);      } catch (Exception e) {        returnBrokenResource(resource);        throw new JedisException(&quot;Resource is returned to the pool as broken&quot;, e);      }    }  }}public class JedisPoolAbstract extends Pool&lt;Jedis&gt; {}public abstract class Pool&lt;T&gt; implements Closeable {  protected GenericObjectPool&lt;T&gt; internalPool;}</code></pre><p>JedisPool 的 getResource 方法在拿到 Jedis 对象后，将自己设置为了连接池。连接池 JedisPool，继承了 JedisPoolAbstract，而后者继承了抽象类 Pool，Pool 内部维护了 Apache Common 的通用池 GenericObjectPool。JedisPool 的连接池就是基于 GenericObjectPool 的.</p><p>总结,Jedis的API是我们说的三种类型里的第一种,连接和连接池分离,既可以单独使用,也可以复用.  </p><h3 id="案例2-线程池务必确保复用"><a href="#案例2-线程池务必确保复用" class="headerlink" title="案例2: 线程池务必确保复用"></a>案例2: 线程池务必确保复用</h3><ul><li>问题描述</li></ul><p>在上一节我们强调过,池一定是用来复用的,否则每次会比创建单一对象更大,原因:</p><p>1, 创建连接池的时候很可能一次性创建了多个连接，大多数连接池考虑到性能，会在初始化的时候维护一定数量的最小连接（毕竟初始化连接池的过程一般是一次性的），可以直接使用。如果每次使用连接池都按需创建连接池，那么很可能你只用到一个连接，但是创建了 N 个连接。<br>2, 连接池一般会有一些管理模块，也就是连接池的结构示意图中的绿色部分。举个例子，大多数的连接池都有闲置超时的概念。连接池会检测连接的闲置时间，定期回收闲置的连接，把活跃连接数降到最低（闲置）连接的配置值，减轻服务端的压力。一般情况下，闲置连接由独立线程管理，启动了空闲检测的连接池相当于还会启动一个线程。<br>3, 此外，有些连接池还需要独立线程负责连接保活等功能。因此，启动一个连接池相当于启动了 N 个线程。</p><p>除了使用代价，连接池不释放，还可能会引起线程泄露.这是一个连接池不复用的例子:<br>首先，创建一个 CloseableHttpClient，设置使用 PoolingHttpClientConnectionManager 连接池并启用空闲连接驱逐策略，最大空闲时间为 60 秒，然后使用这个连接来请求一个会返回 OK 字符串的服务端接口：</p><pre><code>@GetMapping(&quot;wrong1&quot;)public String wrong1() {    CloseableHttpClient client = HttpClients.custom()            .setConnectionManager(new PoolingHttpClientConnectionManager())            .evictIdleConnections(60, TimeUnit.SECONDS).build();    try (CloseableHttpResponse response = client.execute(new HttpGet(&quot;http://127.0.0.1:45678/httpclientnotreuse/test&quot;))) {        return EntityUtils.toString(response.getEntity());    } catch (Exception ex) {        ex.printStackTrace();    }    return null;}</code></pre><p>访问几次这个接口,然后查看应用线程情况,发现有大量的Connection evictor线程,且不会被销毁;对这个接口进行几秒的压测（压测使用 wrk，1 个并发 1 个连接）可以看到，已经建立了三千多个 TCP 连接到 45678 端口（其中有 1 个是压测客户端到 Tomcat 的连接，大部分都是 HttpClient 到 Tomcat 的连接）;<br>这就证明CloseableHttpClient 属于第二种模式，即内部带有连接池的 API，其背后是连接池，最佳实践一定是复用。<br>而复用的方法也很简单,可以把CloseableHttpClient声明为static,只创建一次,并且在JVM关闭之前通过addShutdownHook钩子关闭连接池,在使用的时候直接使用CloseableHttpClient即可,无需每次都创建. </p><ul><li>问题解决<br>首先，定义一个 right 接口来实现服务端接口调用：<pre><code>private static CloseableHttpClient httpClient = null;static {  //当然，也可以把CloseableHttpClient定义为Bean，然后在@PreDestroy标记的方法内close这个HttpClient  httpClient = HttpClients.custom().setMaxConnPerRoute(1).setMaxConnTotal(1).evictIdleConnections(60, TimeUnit.SECONDS).build();  Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; {      try {          httpClient.close();      } catch (IOException ignored) {      }  }));}@GetMapping(&quot;right&quot;)public String right() {  try (CloseableHttpResponse response = httpClient.execute(new HttpGet(&quot;http://127.0.0.1:45678/httpclientnotreuse/test&quot;))) {      return EntityUtils.toString(response.getEntity());  } catch (Exception ex) {      ex.printStackTrace();  }  return null;}</code></pre></li></ul><p>然后，重新定义一个 wrong2 接口，修复之前按需创建 CloseableHttpClient 的代码，每次用完之后确保连接池可以关闭：</p><pre><code>@GetMapping(&quot;wrong2&quot;)public String wrong2() {    try (CloseableHttpClient client = HttpClients.custom()            .setConnectionManager(new PoolingHttpClientConnectionManager())            .evictIdleConnections(60, TimeUnit.SECONDS).build();         CloseableHttpResponse response = client.execute(new HttpGet(&quot;http://127.0.0.1:45678/httpclientnotreuse/test&quot;))) {            return EntityUtils.toString(response.getEntity());        } catch (Exception ex) {        ex.printStackTrace();    }    return null;}</code></pre><p>使用 wrk 对 wrong2 和 right 两个接口分别压测 60 秒，可以看到两种使用方式性能上的差异，每次创建连接池的 QPS 是 337，而复用连接池的 QPS 是 2022：<br><img src="https://s3.ax1x.com/2020/12/30/rLtOET.png" alt="压测命令实例"></p><p>如此大的性能差异是由于TCP连接的复用导致的,刚才定义连接池时,我们将最大连接数设置为1,所以复用连接池复用的始终是同一个链接,新建连接池每次会创建一个新的TCP,因此影响了性能.  </p><h3 id="案例三-连接池配置"><a href="#案例三-连接池配置" class="headerlink" title="案例三: 连接池配置"></a>案例三: 连接池配置</h3><ul><li>问题描述</li></ul><p>连接池的配置不是一成不变的.<br>连接池提供了许多参数,最小(闲置)连接,最大连接,闲置连接生存时间,连接生存时间等;最重要的参数是最大连接数,它决定了连接池能使用的连接数量上限,如果到达上限,新来的请求需要等待其他请求释放连接.<br>但是最大连接数不是越大越好,如果每个客户端都保持大量的连接,服务端的压力会非常的大.服务端是一个TCP连接一个线程的话,几千个连接意味着几千个线程,线程切换开销很大.<br>如果设置的太小,很可能会因为获取连接的等待时间太长,导致吞吐量低下.<br>接下来,我们就模拟一下压力增大导致数据库连接池打满的情况,来实践下如何确认连接池的使用情况,以及有针对性地进行参数优化.<br>首先定义一个用户注册方法,通过@Transactional注解为方法开启事务,其中包含了500毫秒的休眠,一个数据库事务对应一个TCP连接,所以500多毫秒的时间都会占用数据库连接:</p><pre><code>@Transactionalpublic User register(){    User user=new User();    user.setName(&quot;new-user-&quot;+System.currentTimeMillis());    userRepository.save(user);    try {        TimeUnit.MILLISECONDS.sleep(500);    } catch (InterruptedException e) {        e.printStackTrace();    }    return user;}</code></pre><p>随后，修改配置文件启用 register-mbeans，使 Hikari 连接池能通过 JMX MBean 注册连接池相关统计信息，方便观察连接池：</p><pre><code>spring.datasource.hikari.register-mbeans=true</code></pre><p>启动程序并通过 JConsole 连接进程后，可以看到默认情况下最大连接数为 10.<br>使用wrk对应用进行压测,可以看到连接数一下子从0到了10,有20个线程在等待获取连接.<br>不久就出现了无法获取数据库连接的异常,如下所示:</p><pre><code>[15:37:56.156] [http-nio-45678-exec-15] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.dao.DataAccessResourceFailureException: unable to obtain isolated JDBC connection; nested exception is org.hibernate.exception.JDBCConnectionException: unable to obtain isolated JDBC connection] with root causejava.sql.SQLTransientConnectionException: HikariPool-1 - Connection is not available, request timed out after 30000ms.</code></pre><p>解决问题的办法很简单,把配置中的最大连接参数改成50即可.<br>真实情况下,可以选择在遇到连接超限的时候先设置一个足够大的连接数,然后观察最终应用的并发,再按照实际并发数留出一半的余量来设置最终的最大连接,或<br>者是对数据库连接池这种重要资源进行持续监测,设定一半的使用量作为报警阈值,出现预警后及时扩容.  </p><p>这里要强调的是,修改配置参数务必验证是否生效,并且在监控系统中确认是否生效.</p><p>比如原先使用的是druid连接池,但是后来框架升级,连接池替换为了Hikari实现,原来的配置相当于都无效了.</p><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><p><strong>有了连接池之后，获取连接是从连接池获取，没有足够连接时连接池会创建连接。这时，获取连接操作往往有两个超时时间：一个是从连接池获取连接的最长等待时间，通常叫作请求连接超时 connectRequestTimeout 或连接等待超时 connectWaitTimeout；一个是连接池新建 TCP 连接三次握手的连接超时，通常叫作连接超时 connectTimeout。针对 JedisPool、Apache HttpClient 和 Hikari 数据库连接池，你知道如何设置这 2 个参数吗</strong></p><p>答案: </p><pre><code>假设我们希望设置连接超时5s，获取连接超时10s：hikari两个参数设置方式：spring.datasource.hikari.connection-timeout=10000spring.datasource.url=jdbc:mysql://localhost:6657/common_mistakes?connectTimeout=5000&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;rewriteBatchedStatements=truejedis两个参数设置：JedisPoolConfig config = new JedisPoolConfig();        config.setMaxWaitMillis(10000);        try (JedisPool jedisPool = new JedisPool(config, &quot;127.0.0.1&quot;, 6379, 5000);             Jedis jedis = jedisPool.getResource()) {            return jedis.set(&quot;test&quot;, &quot;test&quot;);        }httpclient两个参数设置：RequestConfig requestConfig = RequestConfig.custom()                .setConnectTimeout(5000)                .setConnectionRequestTimeout(10000)                .build();        HttpGet httpGet = new HttpGet(&quot;http://127.0.0.1:45678/twotimeoutconfig/test&quot;);        httpGet.setConfig(requestConfig);        try (CloseableHttpResponse response = httpClient.execute(httpGet)) {...</code></pre><p><strong>对于 NoSQL 中的 MongoDB 来说，使用 MongoDB Java 驱动时，MongoClient 类应该是每次都创建还是复用呢？你能否在官方文档中找到答案呢？</strong></p><p>答案: 从文档中得知，MongoClient 对象的正确使用姿势应该是：使用 MongoClients.create()（或者其他有参） 方法创建，并再整个应用程序中使用它.也就是说MongoClient实际上是静态的连接池,对外暴露API.</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_3</title>
      <link href="/2020/12/24/java-kai-fa-chang-jian-cuo-wu-3/"/>
      <url>/2020/12/24/java-kai-fa-chang-jian-cuo-wu-3/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="3-线程池：业务代码最常用也最容易犯错的组件"><a href="#3-线程池：业务代码最常用也最容易犯错的组件" class="headerlink" title="3.线程池：业务代码最常用也最容易犯错的组件"></a>3.线程池：业务代码最常用也最容易犯错的组件</h2><p>线程池提高了线程的复用性,避免了重复创建新线程的开销,因此成为了处理短逻辑小任务的首选.</p><h3 id="案例一-线程池的声明需要手动进行"><a href="#案例一-线程池的声明需要手动进行" class="headerlink" title="案例一: 线程池的声明需要手动进行"></a>案例一: 线程池的声明需要手动进行</h3><ul><li>问题描述</li></ul><p>在阿里的Java开发手册中提到,禁止使用Executors的快捷工具方法来快速创建线程,尤其是newFixedThreadPool和newCachedThreadPool.<br>使用不当很有可能造成OOM从而导致程序的崩溃.<br>比如下面这个案例,初始化一个单线程的 FixedThreadPool，循环 1 亿次向线程池提交任务，每个任务都会创建一个比较大的字符串然后休眠一小时:</p><pre><code>@GetMapping(&quot;oom1&quot;)public void oom1() throws InterruptedException {    ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(1);    //打印线程池的信息，稍后我会解释这段代码    printStats(threadPool);     for (int i = 0; i &lt; 100000000; i++) {        threadPool.execute(() -&gt; {            String payload = IntStream.rangeClosed(1, 1000000)                    .mapToObj(__ -&gt; &quot;a&quot;)                    .collect(Collectors.joining(&quot;&quot;)) + UUID.randomUUID().toString();            try {                TimeUnit.HOURS.sleep(1);            } catch (InterruptedException e) {            }            log.info(payload);        });    }    threadPool.shutdown();    threadPool.awaitTermination(1, TimeUnit.HOURS);}</code></pre><p>程序运行不久就出现了OOM.</p><ul><li>问题分析</li></ul><p>newFixedThreadPool的源码显示,线程池的工作队列直接new了一个LinkedBlockingQueue,而默认构造方法的LinkedBlockingQueue是一个整型最大值长度的队列,可以认为是无界的.<br>因此任务会在队列中快速积压,最终导致OOM.<br>如果我们使用newCachedThreadPool会产生一样的结果,这个线程池的最大线程数同样是整型最大值,而其工作队列是一个无存储空间的阻塞队列,也就是说当任务到来时必须马上分配一个线程,如果没有就会创建一个新的.  </p><ul><li>问题解决</li></ul><p>我们需要根据自己的场景、并发情况来评估线程池的几个核心参数，包括核心线程数、最大线程数、线程回收策略、工作队列的类型，以及拒绝策略，确保线程池的工作行为符合需求，一般都需要设置有界的工作队列和可控的线程数.  </p><ul><li>问题总结</li></ul><p>任何时候，都应该为自定义线程池指定有意义的名称，以方便排查问题。当出现线程数量暴增、线程死锁、线程占用大量 CPU、线程执行出现异常等问题时，我们往往会抓取线程栈。此时，有意义的线程名称，就可以方便我们定位问题.<br>我们要同时使用一些监控手段来观察线程池的状态, 线程池几乎不会抛出异常,所以我们需要提前观察到线程池队列的积压或者线程数量的快速膨胀.  </p><h3 id="案例二-线程池管理策略详解"><a href="#案例二-线程池管理策略详解" class="headerlink" title="案例二: 线程池管理策略详解"></a>案例二: 线程池管理策略详解</h3><ul><li>问题描述</li></ul><p>在上面的代码中,我们实现了一个对线程池最简单的监控,包括线程数,活跃线程数,完成了多少任务,队列中还有多少任务.</p><pre><code>private void printStats(ThreadPoolExecutor threadPool) {   Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        log.info(&quot;=========================&quot;);        log.info(&quot;Pool Size: {}&quot;, threadPool.getPoolSize());        log.info(&quot;Active Threads: {}&quot;, threadPool.getActiveCount());        log.info(&quot;Number of Tasks Completed: {}&quot;, threadPool.getCompletedTaskCount());        log.info(&quot;Number of Tasks in Queue: {}&quot;, threadPool.getQueue().size());        log.info(&quot;=========================&quot;);    }, 0, 1, TimeUnit.SECONDS);}</code></pre><p>我们使用这么一个例子来观察下自定义线程池:<br>首先，自定义一个线程池。这个线程池具有 2 个核心线程、5 个最大线程、使用容量为 10 的 ArrayBlockingQueue 阻塞队列作为工作队列，使用默认的 AbortPolicy 拒绝策略，也就是任务添加到线程池失败会抛出 RejectedExecutionException。此外，我们借助了 Jodd 类库的 ThreadFactoryBuilder 方法来构造一个线程工厂，实现线程池线程的自定义命名。然后，我们写一段测试代码来观察线程池管理线程的策略。测试代码的逻辑为，每次间隔 1 秒向线程池提交任务，循环 20 次，每个任务需要 10 秒才能执行完成，代码如下：</p><pre><code>@GetMapping(&quot;right&quot;)public int right() throws InterruptedException {    //使用一个计数器跟踪完成的任务数    AtomicInteger atomicInteger = new AtomicInteger();    //创建一个具有2个核心线程、5个最大线程，使用容量为10的ArrayBlockingQueue阻塞队列作为工作队列的线程池，使用默认的AbortPolicy拒绝策略    ThreadPoolExecutor threadPool = new ThreadPoolExecutor(            2, 5,            5, TimeUnit.SECONDS,            new ArrayBlockingQueue&lt;&gt;(10),            new ThreadFactoryBuilder().setNameFormat(&quot;demo-threadpool-%d&quot;).get(),            new ThreadPoolExecutor.AbortPolicy());    printStats(threadPool);    //每隔1秒提交一次，一共提交20次任务    IntStream.rangeClosed(1, 20).forEach(i -&gt; {        try {            TimeUnit.SECONDS.sleep(1);        } catch (InterruptedException e) {            e.printStackTrace();        }        int id = atomicInteger.incrementAndGet();        try {            threadPool.submit(() -&gt; {                log.info(&quot;{} started&quot;, id);                //每个任务耗时10秒                try {                    TimeUnit.SECONDS.sleep(10);                } catch (InterruptedException e) {                }                log.info(&quot;{} finished&quot;, id);            });        } catch (Exception ex) {            //提交出现异常的话，打印出错信息并为计数器减一            log.error(&quot;error submitting task {}&quot;, id, ex);            atomicInteger.decrementAndGet();        }    });    TimeUnit.SECONDS.sleep(60);    return atomicInteger.intValue();}</code></pre><p>结果60秒后页面输出17,有3次提交失败.日志中也出现了三次类似的信息:</p><pre><code>[14:24:52.879] [http-nio-45678-exec-1] [ERROR] [.t.c.t.demo1.ThreadPoolOOMController:103 ] - error submitting task 18java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@163a2dec rejected from java.util.concurrent.ThreadPoolExecutor@18061ad2[Running, pool size = 5, active threads = 5, queued tasks = 10, completed tasks = 2]</code></pre><p>如果观察我们的监控记录,就可以得出以下结论:</p><ul><li>不会初始化 corePoolSize 个线程，有任务来了才创建工作线程；</li><li>当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列中；</li><li>当工作队列满了后扩容线程池，一直到线程个数达到 maximumPoolSize 为止；</li><li>如果队列已满且达到了最大线程后还有任务进来，按照拒绝策略处理；</li><li>当线程数大于核心线程数时，线程等待 keepAliveTime 后还是没有任务需要处理的话，收缩线程到核心线程数。</li></ul><p>当然这些操作是可以通过一些命令来改变的,比如:</p><ul><li>声明线程池后立即调用 prestartAllCoreThreads 方法，来启动所有核心线程；</li><li>传入 true 给 allowCoreThreadTimeOut 方法，来让线程池在空闲的时候同样回收核心线程。</li></ul><p>思考题: 如果队列创建的很大,最大线程数就没有意义了,有没有办法能够在队列没有满的情况下优先创建新线程,等待线程达到最大值的时候再插入队列呢?<br>答案在本文末尾揭晓.</p><h3 id="案例三-线程池本身没有被复用"><a href="#案例三-线程池本身没有被复用" class="headerlink" title="案例三: 线程池本身没有被复用"></a>案例三: 线程池本身没有被复用</h3><ul><li>问题描述</li></ul><p>某项目生产环境时不时有报警提示线程数过多，超过 2000 个，收到报警后查看监控发现，瞬时线程数比较多但过一会儿又会降下来，线程数抖动很厉害，而应用的访问量变化不大。抓取后发现内存中有 1000 多个自定义线程池。一般而言，线程池肯定是复用的，有 5 个以内的线程池都可以认为正常，而 1000 多个线程池肯定不正常。<br>代码如下: </p><pre><code>@GetMapping(&quot;wrong&quot;)public String wrong() throws InterruptedException {    ThreadPoolExecutor threadPool = ThreadPoolHelper.getThreadPool();    IntStream.rangeClosed(1, 10).forEach(i -&gt; {        threadPool.execute(() -&gt; {            ...            try {                TimeUnit.SECONDS.sleep(1);            } catch (InterruptedException e) {            }        });    });    return &quot;OK&quot;;}</code></pre><ul><li>问题分析</li></ul><p>看起来似乎没啥问题,原因就出在getThreadPool()这个方法上,</p><pre><code>class ThreadPoolHelper {    public static ThreadPoolExecutor getThreadPool() {        //线程池没有复用        return (ThreadPoolExecutor) Executors.newCachedThreadPool();    }}</code></pre><p>这个方法每次居然是new一个新的出来!<br>所以说在使用第三方库的方法的时候最好还是点进去看一眼,要修复这个问题非常简单,手动创建一个我们需要的线程池,并且get方法只是返回这个引用就可以了.</p><pre><code>class ThreadPoolHelper {  private static ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(    10, 50,    2, TimeUnit.SECONDS,    new ArrayBlockingQueue&lt;&gt;(1000),    new ThreadFactoryBuilder().setNameFormat(&quot;demo-threadpool-%d&quot;).get());  public static ThreadPoolExecutor getRightThreadPool() {    return threadPoolExecutor;  }}</code></pre><h3 id="案例四-线程池的混用策略"><a href="#案例四-线程池的混用策略" class="headerlink" title="案例四: 线程池的混用策略"></a>案例四: 线程池的混用策略</h3><ul><li>问题描述</li></ul><p>线程池的价值在于复用,但是我们不可能把所有的任务都提交给一个线程池,对于执行比较慢,数量不大的IO任务,需要更多的线程数,不需要太大的队列长度. 对于吞吐量较大的计算任务,线程数量不宜过多,但是需要更长的队列来做缓冲.<br>比如一段业务代码使用了线程池异步处理一些内存中的数据，但通过监控发现处理得非常慢，整个处理过程都是内存中的计算不涉及 IO 操作，也需要数秒的处理时间，应用程序 CPU 占用也不是特别高，经排查发现，业务代码使用的线程池，还被一个后台的文件批处理任务用到了。或许是够用就好的原则，这个线程池只有 2 个核心线程，最大线程也是 2，使用了容量为 100 的 ArrayBlockingQueue 作为工作队列，使用了 CallerRunsPolicy 拒绝策略：</p><pre><code>private static ThreadPoolExecutor threadPool = new ThreadPoolExecutor(        2, 2,        1, TimeUnit.HOURS,        new ArrayBlockingQueue&lt;&gt;(100),        new ThreadFactoryBuilder().setNameFormat(&quot;batchfileprocess-threadpool-%d&quot;).get(),        new ThreadPoolExecutor.CallerRunsPolicy());</code></pre><p>模拟一下文件批处理的代码，在程序启动后通过一个线程开启死循环逻辑，不断向线程池提交任务，任务的逻辑是向一个文件中写入大量的数据:</p><pre><code>@PostConstructpublic void init() {    printStats(threadPool);    new Thread(() -&gt; {        //模拟需要写入的大量数据        String payload = IntStream.rangeClosed(1, 1_000_000)                .mapToObj(__ -&gt; &quot;a&quot;)                .collect(Collectors.joining(&quot;&quot;));        while (true) {            threadPool.execute(() -&gt; {                try {                    //每次都是创建并写入相同的数据到相同的文件                    Files.write(Paths.get(&quot;demo.txt&quot;), Collections.singletonList(LocalTime.now().toString() + &quot;:&quot; + payload), UTF_8, CREATE, TRUNCATE_EXISTING);                } catch (IOException e) {                    e.printStackTrace();                }                log.info(&quot;batch file processing done&quot;);            });        }    }).start();}</code></pre><p>这时如果我们看下日志,就会发现线程池的2个线程基本始终处于活跃状态,队列也基本处于打满状态,因为我们的拒绝的策略是CallerRunsPolicy,所以当队列也满的时候,任务会在调用线程池的execute的线程进行调用,也就是说变成同步处理了.<br>所以我们的业务复用这个线程池来进行内存计算,一定是无效的.解决的办法也很简单,直接创建一个专属的线程池来处理这个任务就可以了.</p><p>这里朱老师又提到了另一个坑点,Java 8 的 parallel stream 功能，可以让我们很方便地并行处理集合中的元素，其背后是共享同一个 ForkJoinPool，默认并行度是 CPU 核数 -1。对于 CPU 绑定的任务来说，使用这样的配置比较合适，但如果集合操作涉及同步 IO 操作的话（比如数据库操作、外部服务调用等），建议自定义一个 ForkJoinPool（或普通线程池)</p><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><p>思考题答案:<br><a href="https://github.com/apache/tomcat/blob/a801409b37294c3f3dd5590453fb9580d7e33af2/java/org/apache/tomcat/util/threads/ThreadPoolExecutor.java" target="_blank" rel="noopener">https://github.com/apache/tomcat/blob/a801409b37294c3f3dd5590453fb9580d7e33af2/java/org/apache/tomcat/util/threads/ThreadPoolExecutor.java</a></p><p><strong>思考题2:在第二节中，我们改进了 ThreadPoolHelper 使其能够返回复用的线程池。如果我们不小心每次都创建了这样一个自定义的线程池（10 核心线程，50 最大线程，2 秒回收的），反复执行测试接口线程，最终可以被回收吗？会出现 OOM 问题吗？</strong><br>不会被回收，会OOM，即使是自定义线程池，核心线程是不会回收的，每次需要10个线程，刚好是核心线程数，因此每次请求都会创建10个核心线程数的线程池，请求次数多了后，很快就回OOM。</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_2</title>
      <link href="/2020/12/21/java-kai-fa-chang-jian-cuo-wu-2/"/>
      <url>/2020/12/21/java-kai-fa-chang-jian-cuo-wu-2/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="2-代码加锁：不要让“锁”事成为烦心事"><a href="#2-代码加锁：不要让“锁”事成为烦心事" class="headerlink" title="2.代码加锁：不要让“锁”事成为烦心事"></a>2.代码加锁：不要让“锁”事成为烦心事</h2><p>在开发时盲目使用锁,在某些场景下会严重影响性能.  </p><h3 id="案例1-两个线程分别执行相加和判断"><a href="#案例1-两个线程分别执行相加和判断" class="headerlink" title="案例1: 两个线程分别执行相加和判断"></a>案例1: 两个线程分别执行相加和判断</h3><ul><li>问题描述<br>在一个类里有两个 int 类型的字段 a 和 b，有一个 add 方法循环 1 万次对 a 和 b 进行 ++ 操作，有另一个 compare 方法，同样循环 1 万次判断 a 是否小于 b，条件成立就打印 a 和 b 的值，并判断 a&gt;b 是否成立。</li></ul><pre><code>@Slf4jpublic class Interesting {    volatile int a = 1;    volatile int b = 1;    public void add() {        log.info(&quot;add start&quot;);        for (int i = 0; i &lt; 10000; i++) {            a++;            b++;        }        log.info(&quot;add done&quot;);    }    public void compare() {        log.info(&quot;compare start&quot;);        for (int i = 0; i &lt; 10000; i++) {            //a始终等于b吗？            if (a &lt; b) {                log.info(&quot;a:{},b:{},{}&quot;, a, b, a &gt; b);                //最后的a&gt;b应该始终是false吗？            }        }        log.info(&quot;compare done&quot;);    }}</code></pre><p>使用两个线程来执行:</p><pre><code>Interesting interesting = new Interesting();new Thread(() -&gt; interesting.add()).start();new Thread(() -&gt; interesting.compare()).start();</code></pre><p>按道理，a 和 b 同样进行累加操作，应该始终相等，compare 中的第一次判断应该始终不会成立，不会输出任何日志。但，执行代码后发现不但输出了日志，而且更诡异的是，compare 方法在判断 ab 也成立.<br>更诡异的是,即使给add方法加锁,还是没解决这个问题</p><pre><code>public synchronized void add()</code></pre><ul><li>问题分析</li></ul><p>bug出现的原因是,a++和b++的操作中可以穿插compare方法的比较代码,而且a&gt;b这个比较操作在字节码层面是加载A,加载B,比较,三步.代码虽然是一行,也不是原子性的.  </p><ul><li>问题解决</li></ul><p>给add和compare方法都加上<strong>方法锁</strong>,保证方法执行时的变量是另外一个方法无法读取的.</p><pre><code>public synchronized void add()public synchronized void compare()</code></pre><ul><li>问题总结</li></ul><p>加锁之前一定要想清楚,锁到底是保护哪些东西不可被访问的.</p><h3 id="案例2-加锁前要清楚锁和被保护的对象是不是一个层面的"><a href="#案例2-加锁前要清楚锁和被保护的对象是不是一个层面的" class="headerlink" title="案例2: 加锁前要清楚锁和被保护的对象是不是一个层面的"></a>案例2: 加锁前要清楚锁和被保护的对象是不是一个层面的</h3><ul><li>问题描述</li></ul><p>在类 Data 中定义了一个静态的 int 字段 counter 和一个非静态的 wrong 方法，实现 counter 字段的累加操作。</p><pre><code>class Data {    @Getter    private static int counter = 0;    public static int reset() {        counter = 0;        return counter;    }    public synchronized void wrong() {        counter++;    }}</code></pre><pre><code>一段测试代码: @GetMapping(&quot;wrong&quot;)public int wrong(@RequestParam(value = &quot;count&quot;, defaultValue = &quot;1000000&quot;) int count) {    Data.reset();    //多线程循环一定次数调用Data类不同实例的wrong方法    IntStream.rangeClosed(1, count).parallel().forEach(i -&gt; new Data().wrong());    return Data.getCounter();}</code></pre><p>执行后应该输出100w,但是实际上只有63w.  </p><ul><li>问题分析</li></ul><p>在非静态的 wrong 方法上加锁，只能确保多个线程无法执行同一个实例的 wrong 方法，却不能保证不会执行不同实例的 wrong 方法。而静态的 counter 在多个实例中共享，所以必然会出现线程安全问题。  </p><ul><li>问题解决</li></ul><p>在类中定义一个静态字段,在操作counter之前对这个字段加锁.<br>因为类字段是不能被共享的,所以同一时间只有一个实例可以调用这个wrong方法.  </p><pre><code>class Data {    @Getter    private static int counter = 0;    private static Object locker = new Object();    public void right() {        synchronized (locker) {            counter++;        }    }}</code></pre><h3 id="案例3-多把锁小心死锁问题"><a href="#案例3-多把锁小心死锁问题" class="headerlink" title="案例3: 多把锁小心死锁问题"></a>案例3: 多把锁小心死锁问题</h3><ul><li>问题描述</li></ul><p>下单操作需要锁定订单中多个商品的库存，拿到所有商品的锁之后进行下单扣减库存操作，全部操作完成之后释放所有的锁。代码上线后发现，下单失败概率很高，失败后需要用户重新下单，极大影响了用户体验，还影响到了销量。经排查发现是死锁引起的问题，背后原因是扣减库存的顺序不同，导致并发的情况下多个线程可能相互持有部分商品的锁，又等待其他线程释放另一部分商品的锁，于是出现了死锁问题。</p><p>核心流程代码:<br>首先，定义一个商品类型，包含商品名、库存剩余和商品的库存锁三个属性，每一种商品默认库存 1000 个；然后，初始化 10 个这样的商品对象来模拟商品清单：</p><pre><code>@Data@RequiredArgsConstructorstatic class Item {    final String name; //商品名    int remaining = 1000; //库存剩余    @ToString.Exclude //ToString不包含这个字段     ReentrantLock lock = new ReentrantLock();}</code></pre><p>随后，写一个方法模拟在购物车进行商品选购，每次从商品清单（items 字段）中随机选购三个商品（为了逻辑简单，我们不考虑每次选购多个同类商品的逻辑，购物车中不体现商品数量）：</p><pre><code>private List&lt;Item&gt; createCart() {    return IntStream.rangeClosed(1, 3)            .mapToObj(i -&gt; &quot;item&quot; + ThreadLocalRandom.current().nextInt(items.size()))            .map(name -&gt; items.get(name)).collect(Collectors.toList());}</code></pre><p>下单代码如下：先声明一个 List 来保存所有获得的锁，然后遍历购物车中的商品依次尝试获得商品的锁，最长等待 10 秒，获得全部锁之后再扣减库存；如果有无法获得锁的情况则解锁之前获得的所有锁，返回 false 下单失败。</p><pre><code>private boolean createOrder(List&lt;Item&gt; order) {    //存放所有获得的锁    List&lt;ReentrantLock&gt; locks = new ArrayList&lt;&gt;();    for (Item item : order) {        try {            //获得锁10秒超时            if (item.lock.tryLock(10, TimeUnit.SECONDS)) {                locks.add(item.lock);            } else {                locks.forEach(ReentrantLock::unlock);                return false;            }        } catch (InterruptedException e) {        }    }    //锁全部拿到之后执行扣减库存业务逻辑    try {        order.forEach(item -&gt; item.remaining--);    } finally {        locks.forEach(ReentrantLock::unlock);    }    return true;}</code></pre><p>写一段代码测试下这个操作:</p><pre><code>@GetMapping(&quot;wrong&quot;)public long wrong() {    long begin = System.currentTimeMillis();    //并发进行100次下单操作，统计成功次数    long success = IntStream.rangeClosed(1, 100).parallel()            .mapToObj(i -&gt; {                List&lt;Item&gt; cart = createCart();                return createOrder(cart);            })            .filter(result -&gt; result)            .count();    log.info(&quot;success:{} totalRemaining:{} took:{}ms items:{}&quot;,            success,            items.entrySet().stream().map(item -&gt; item.getValue().remaining).reduce(0, Integer::sum),            System.currentTimeMillis() - begin, items);    return success;}</code></pre><p>执行后使用jdk自带的VisualVM工具监视一下,提示存在死锁.  </p><ul><li>问题分析</li></ul><p>我们仔细回忆一下购物车添加商品的逻辑，随机添加了三种商品，假设一个购物车中的商品是 item1 和 item2，另一个购物车中的商品是 item2 和 item1，一个线程先获取到了 item1 的锁，同时另一个线程获取到了 item2 的锁，然后两个线程接下来要分别获取 item2 和 item1 的锁，这个时候锁已经被对方获取了，只能相互等待一直到 10 秒超时。  </p><ul><li>问题解决</li></ul><p>其实只需要对购物车中的商品排序一下,让所有的线程先获取1再获取2的锁即可.  </p><pre><code>@GetMapping(&quot;right&quot;)public long right() {      long success = IntStream.rangeClosed(1, 100).parallel()            .mapToObj(i -&gt; {                List&lt;Item&gt; cart = createCart().stream()                        .sorted(Comparator.comparing(Item::getName))                        .collect(Collectors.toList());                return createOrder(cart);            })            .filter(result -&gt; result)            .count();    ...    return success;}</code></pre><ul><li>问题总结:</li></ul><p>如果你的业务代码涉及复杂的锁操作，强烈建议 Mock 相关外部接口或数据库操作后对应用代码进行压测，通过压测排除锁误用带来的性能问题和死锁问题。</p><h3 id="课后题"><a href="#课后题" class="headerlink" title="课后题"></a>课后题</h3><ul><li>问题描述</li></ul><p><strong>本文开头的例子里，变量 a、b 都使用了 volatile 关键字，你知道原因吗？我之前遇到过这样一个坑：我们开启了一个线程无限循环来跑一些任务，有一个 bool 类型的变量来控制循环的退出，默认为 true 代表执行，一段时间后主线程将这个变量设置为了 false。如果这个变量不是 volatile 修饰的，子线程可以立刻退出吗？你能否解释其中的原因呢？</strong></p><p>volatile关键字保证了可见性和禁止指令重排序优化,本质上是cpu缓存失效，必须从主内存读取数据；<br>不会立刻退出,因为CPU缓存到主内存的同步不是实时的. </p><p><strong>文末我们又提了两个坑，一是加锁和释放没有配对的问题，二是锁自动释放导致的重复逻辑执行的问题。你有什么方法来发现和解决这两种问题吗？</strong></p><p>可以使用Sonar等代码质量管理工具来帮助管理,同时可以加上超时自动释放来避免死锁.<br>锁超时的问题可以用锁续期,比如redisson的watchdog或者保证业务的幂等性,重复执行也没问题;  </p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发常见错误_1</title>
      <link href="/2020/12/05/java-kai-fa-chang-jian-cuo-wu-1/"/>
      <url>/2020/12/05/java-kai-fa-chang-jian-cuo-wu-1/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="1-使用了并发工具类库，线程安全就高枕无忧了吗"><a href="#1-使用了并发工具类库，线程安全就高枕无忧了吗" class="headerlink" title="1.使用了并发工具类库，线程安全就高枕无忧了吗?"></a>1.使用了并发工具类库，线程安全就高枕无忧了吗?</h2><p>在开发时盲目使用”线程安全”的工具和”并发工具类”,在某些场景下会严重影响性能.  </p><h3 id="案例一-在SpringBoot中盲目使用ThreadLocal"><a href="#案例一-在SpringBoot中盲目使用ThreadLocal" class="headerlink" title="案例一: 在SpringBoot中盲目使用ThreadLocal"></a>案例一: 在SpringBoot中盲目使用ThreadLocal</h3><ul><li>问题描述:<br>用户1存的id等信息会在退出登录后,被用户2取到.</li></ul><pre><code>private static final ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; null);@GetMapping(&quot;wrong&quot;)public Map wrong(@RequestParam(&quot;userId&quot;) Integer userId) {    //设置用户信息之前先查询一次ThreadLocal中的用户信息    String before  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    //设置用户信息到ThreadLocal    currentUser.set(userId);    //设置用户信息之后再查询一次ThreadLocal中的用户信息    String after  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    //汇总输出两次查询结果    Map result = new HashMap();    result.put(&quot;before&quot;, before);    result.put(&quot;after&quot;, after);    return result;}</code></pre><ul><li><p>问题分析:<br>Tomcat的线程池存在线程复用的机制,所以之前用户1用的现场被用户2调用,而threadLocal是一个以线程号作为key的map结构,所以最后取到了用户1的数据.</p></li><li><p>问题解决:<br>在使用完之后,在finally代码块中显式的清空ThreadLocal这类线程标识的存储内容.</p></li><li><p>问题总结:<br>使用线程池类工具时,无论是自定义线程池还是自带线程池要时刻注意减少对线程本身进行标识.  </p></li></ul><h3 id="案例二-盲目使用concurrentHashMap"><a href="#案例二-盲目使用concurrentHashMap" class="headerlink" title="案例二: 盲目使用concurrentHashMap"></a>案例二: 盲目使用concurrentHashMap</h3><ul><li>问题描述:<br>有一个含900个元素的 Map，现在再补充 100 个元素进去，这个补充操作由 10 个线程并发进行.<br>开发人员误以为使用了 ConcurrentHashMap 就不会有线程安全问题，于是不加思索地写出了下面的代码:在每一个线程的代码逻辑中先通过 size 方法拿到当前元素数量，计算 ConcurrentHashMap 目前还需要补充多少元素，并在日志中输出了这个值，然后通过 putAll 方法把缺少的元素添加进去。<br>结果显示,本来要补充100个即可,最后补充了1536个进去.</li></ul><pre><code>//线程个数private static int THREAD_COUNT = 10;//总元素数量private static int ITEM_COUNT = 1000;//帮助方法，用来获得一个指定元素数量模拟数据的ConcurrentHashMapprivate ConcurrentHashMap&lt;String, Long&gt; getData(int count) {    return LongStream.rangeClosed(1, count)            .boxed()            .collect(Collectors.toConcurrentMap(i -&gt; UUID.randomUUID().toString(), Function.identity(),                    (o1, o2) -&gt; o1, ConcurrentHashMap::new));}@GetMapping(&quot;wrong&quot;)public String wrong() throws InterruptedException {    ConcurrentHashMap&lt;String, Long&gt; concurrentHashMap = getData(ITEM_COUNT - 100);    //初始900个元素    log.info(&quot;init size:{}&quot;, concurrentHashMap.size());    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    //使用线程池并发处理逻辑    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&gt; {        //查询还需要补充多少个元素        int gap = ITEM_COUNT - concurrentHashMap.size();        log.info(&quot;gap size:{}&quot;, gap);        //补充元素        concurrentHashMap.putAll(getData(gap));    }));    //等待所有任务完成    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    //最后元素个数会是1000吗？    log.info(&quot;finish size:{}&quot;, concurrentHashMap.size());    return &quot;OK&quot;;}</code></pre><ul><li><p>问题分析<br>忽略了CHM这个类对外提供的方法的限制, chm这个类只保证了他的添加操作是线程安全的,但是诸如size,isEmpty,containsvalue等聚合方法在并发时会反映chm的中间状态,以及putAll这种方法也不是原子的.</p></li><li><p>问题解决<br>如果要使用聚合操作,最简单的方法就是直接对整段逻辑加锁即可.  </p></li><li><p>问题总结<br>在使用高级工具类的时候,最好要弄懂底层原理,严格按照工作场景来使用.<br>另外,补充一下老师在课后给出的两个点评:<br>第一，ConcurrentHashMap提供的那些针对单一Key读写的API可以认为是线程安全的，但是诸如putAll这种涉及到多个Key的操作，并发读取可能无法确保读取到完整的数据。<br>第二，ConcurrentHashMap只能确保提供的API是线程安全的，但是使用者组合使用多个API，ConcurrentHashMap无法从内部确保使用过程中的状态一致。</p></li></ul><h3 id="案例三-不使用高级结构提供的高级API导致代码冗余效率降低"><a href="#案例三-不使用高级结构提供的高级API导致代码冗余效率降低" class="headerlink" title="案例三: 不使用高级结构提供的高级API导致代码冗余效率降低"></a>案例三: 不使用高级结构提供的高级API导致代码冗余效率降低</h3><ul><li>问题描述</li></ul><p>使用 Map 来统计 Key 出现次数, 使用 ConcurrentHashMap 来统计，Key 的范围是 10。<br>使用最多 10 个并发，循环操作 1000 万次，每次操作累加随机的 Key。 如果 Key 不存在的话，首次设置值为 1。 </p><pre><code>//循环次数private static int LOOP_COUNT = 10000000;//线程数量private static int THREAD_COUNT = 10;//元素数量private static int ITEM_COUNT = 10;private Map&lt;String, Long&gt; normaluse() throws InterruptedException {    ConcurrentHashMap&lt;String, Long&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; {        //获得一个随机的Key        String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                synchronized (freqs) {                          if (freqs.containsKey(key)) {                        //Key存在则+1                        freqs.put(key, freqs.get(key) + 1);                    } else {                        //Key不存在则初始化为1                        freqs.put(key, 1L);                    }                }            }    ));    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    return freqs;}</code></pre><ul><li>问题分析</li></ul><p>这段代码吸取了之前的教训,给必要的逻辑部分加锁,但是这样就浪费了chm这个结构的长处,降低了效率.<br>正确的使用方法如下:</p><ul><li>问题解决</li></ul><pre><code>private Map&lt;String, Long&gt; gooduse() throws InterruptedException {    ConcurrentHashMap&lt;String, LongAdder&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; {        String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                //利用computeIfAbsent()方法来实例化LongAdder，然后利用LongAdder来进行线程安全计数                freqs.computeIfAbsent(key, k -&gt; new LongAdder()).increment();            }    ));    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    //因为我们的Value是LongAdder而不是Long，所以需要做一次转换才能返回    return freqs.entrySet().stream()            .collect(Collectors.toMap(                    e -&gt; e.getKey(),                    e -&gt; e.getValue().longValue())            );}</code></pre><p>这段代码存在许多高级之处, 使用chm的原子方法computeIfAbsent来做复合逻辑操作,判断是否key存在value,如果不存在就把lambda运行后的结果放进Map.<br>并且computeIfAbsent这个方法返回的是一个LongAdder对象,是一个线程安全的累加器,可以直接调用increment方法进行累加.</p><ul><li>问题总结</li></ul><p>为什么chm如此高效?<br>chm使用了java自带的unsafe实现的cas,在虚拟机层面确保了写入数据的原子性,比加锁效率高很多.  </p><h3 id="案例四-错误使用针对特定场景的特殊工具"><a href="#案例四-错误使用针对特定场景的特殊工具" class="headerlink" title="案例四: 错误使用针对特定场景的特殊工具"></a>案例四: 错误使用针对特定场景的特殊工具</h3><ul><li>问题描述</li></ul><p>一段简单的非数据库操作的业务逻辑，消耗了超 出预期的时间，在修改数据时操作本地缓存比回写数据库慢许多。查看代码发现，开发同学 使用了 CopyOnWriteArrayList 来缓存大量的数据，而数据变化又比较频繁。<br>CopyOnWrite技术非常时髦,它的特点是线程安全,但是每次修改时都会复制一份数据出来,所以只适用于<strong>读多写少或者无锁读的场景</strong>  </p><p>写一段代码来测试下:</p><pre><code>//测试并发写的性能@GetMapping(&quot;write&quot;)public Map testWrite() {    List&lt;Integer&gt; copyOnWriteArrayList = new CopyOnWriteArrayList&lt;&gt;();    List&lt;Integer&gt; synchronizedList = Collections.synchronizedList(new ArrayList&lt;&gt;());    StopWatch stopWatch = new StopWatch();    int loopCount = 100000;    stopWatch.start(&quot;Write:copyOnWriteArrayList&quot;);    //循环100000次并发往CopyOnWriteArrayList写入随机元素    IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -&gt; copyOnWriteArrayList.add(ThreadLocalRandom.current().nextInt(loopCount)));    stopWatch.stop();    stopWatch.start(&quot;Write:synchronizedList&quot;);    //循环100000次并发往加锁的ArrayList写入随机元素    IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -&gt; synchronizedList.add(ThreadLocalRandom.current().nextInt(loopCount)));    stopWatch.stop();    log.info(stopWatch.prettyPrint());    Map result = new HashMap();    result.put(&quot;copyOnWriteArrayList&quot;, copyOnWriteArrayList.size());    result.put(&quot;synchronizedList&quot;, synchronizedList.size());    return result;}//帮助方法用来填充Listprivate void addAll(List&lt;Integer&gt; list) {    list.addAll(IntStream.rangeClosed(1, 1000000).boxed().collect(Collectors.toList()));}//测试并发读的性能@GetMapping(&quot;read&quot;)public Map testRead() {    //创建两个测试对象    List&lt;Integer&gt; copyOnWriteArrayList = new CopyOnWriteArrayList&lt;&gt;();    List&lt;Integer&gt; synchronizedList = Collections.synchronizedList(new ArrayList&lt;&gt;());    //填充数据       addAll(copyOnWriteArrayList);    addAll(synchronizedList);    StopWatch stopWatch = new StopWatch();    int loopCount = 1000000;    int count = copyOnWriteArrayList.size();    stopWatch.start(&quot;Read:copyOnWriteArrayList&quot;);    //循环1000000次并发从CopyOnWriteArrayList随机查询元素    IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -&gt; copyOnWriteArrayList.get(ThreadLocalRandom.current().nextInt(count)));    stopWatch.stop();    stopWatch.start(&quot;Read:synchronizedList&quot;);    //循环1000000次并发从加锁的ArrayList随机查询元素    IntStream.range(0, loopCount).parallel().forEach(__ -&gt; synchronizedList.get(ThreadLocalRandom.current().nextInt(count)));    stopWatch.stop();    log.info(stopWatch.prettyPrint());    Map result = new HashMap();    result.put(&quot;copyOnWriteArrayList&quot;, copyOnWriteArrayList.size());    result.put(&quot;synchronizedList&quot;, synchronizedList.size());    return result;}</code></pre><ul><li>问题分析</li></ul><p>从代码运行结果来看, 在大量写的场景下,COWA比同步的ArrayList 慢一百倍.<br>在大量读的场景下,又快5倍以上;  </p><p>本质原因就在于,比如add方法,每次都会用Arrays.copyOf()创建一个新数组.</p><pre><code>    /**     * Appends the specified element to the end of this list.     *     * @param e element to be appended to this list     * @return {@code true} (as specified by {@link Collection#add})     */    public boolean add(E e) {        synchronized (lock) {            Object[] elements = getArray();            int len = elements.length;            Object[] newElements = Arrays.copyOf(elements, len + 1);            newElements[len] = e;            setArray(newElements);            return true;        }    }</code></pre><h3 id="课后题"><a href="#课后题" class="headerlink" title="课后题:"></a>课后题:</h3><ul><li>问题描述</li></ul><p><strong>今天我们多次用到了 ThreadLocalRandom，你觉得是否可以把它的实例设置到静态变量中，在多线程情况下重用呢？</strong></p><p>不可以。ThreadLocalRandom文档里写了Usages of this class should typically be of the form:ThreadLocalRandom.current().nextX(…)} (where X is Int, Long, etc)。<br>ThreadLocalRandom类中只封装了一些公用的方法，种子存放在各个线程中。<br>ThreadLocalRandom中存放一个单例的instance，调用current()方法返回这个instance，每个线程首次调用current()方法时，会在各个线程中初始化seed和probe。<br>nextX(）方法会调用nextSeed()，在其中使用各个线程中的种子，计算下一个种子并保存（UNSAFE.getLong(t, SEED) + GAMMA）。<br>所以，如果使用静态变量，直接调用nextX()方法就跳过了各个线程初始化的步骤，只会在每次调用nextSeed()时来更新种子。</p><p><strong>ConcurrentHashMap 还提供了 putIfAbsent 方法，你能否通过查阅JDK 文档，说说 computeIfAbsent 和 putIfAbsent 方法的区别？</strong><br>1.参数不一样，putIfAbsent是值，computeIfAbsent是mappingFunction<br>2.返回值不一样，putIfAbsent是之前的值，computeIfAbsent是现在的值<br>3.putIfAbsent可以存入null，computeIfAbsent计算结果是null只会返回null，不会写入。</p>]]></content>
      
      
      <categories>
          
          <category> 常见业务错误 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合类 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis设计与实现(三)</title>
      <link href="/2020/11/05/redis-she-ji-yu-shi-xian-san/"/>
      <url>/2020/11/05/redis-she-ji-yu-shi-xian-san/</url>
      
        <content type="html"><![CDATA[<p>本文是Redis设计与实现,第二版的读书笔记,来了解一下当下最流行的中间件到底是如何实现的,有哪些值得学习的设计思想.  </p><h1 id="第三部分-多机数据库的实现"><a href="#第三部分-多机数据库的实现" class="headerlink" title="第三部分: 多机数据库的实现"></a>第三部分: 多机数据库的实现</h1><h2 id="15-复制"><a href="#15-复制" class="headerlink" title="15 复制"></a>15 复制</h2><p>主要是通过让主服务器创建并发送RDB文件,以及向从服务器发送保存在缓冲区里的写命令来进行同步.<br>如果出现断线,则只需要把断开期间的写命令发送给从服务器即可.  </p><p>具体如何实现同步可以自行阅读书籍相关部分,设计到的偏移量等细节略过不表.  </p><h3 id="15-7-心跳检测"><a href="#15-7-心跳检测" class="headerlink" title="15.7 心跳检测"></a>15.7 心跳检测</h3><p>在命令传播阶段,从服务器默认以每秒一次的频率,向主服务器发送命令: </p><pre><code>REPLCONF ACK&lt;replication_offset&gt;</code></pre><p>这个命令有以下3个小节的用处.</p><h4 id="15-7-1-检测主从服务器的网络连接状态"><a href="#15-7-1-检测主从服务器的网络连接状态" class="headerlink" title="15.7.1 检测主从服务器的网络连接状态"></a>15.7.1 检测主从服务器的网络连接状态</h4><p>如果超过一秒没有收到心跳,证明网络连接出现故障.</p><h4 id="15-7-2-辅助实现min-slaves配置选项"><a href="#15-7-2-辅助实现min-slaves配置选项" class="headerlink" title="15.7.2 辅助实现min-slaves配置选项"></a>15.7.2 辅助实现min-slaves配置选项</h4><p>在出现网络故障时停止写命令.</p><h4 id="15-7-3-检测命令丢失"><a href="#15-7-3-检测命令丢失" class="headerlink" title="15.7.3 检测命令丢失"></a>15.7.3 检测命令丢失</h4><p>当主服务器发现从服务器和自己的复制偏移量不一致时,将会从自己的复制积压缓冲区里找到从服务器缺少的数据,并且重新发送给从服务器.  </p><p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p><h2 id="16-Sentinel"><a href="#16-Sentinel" class="headerlink" title="16 Sentinel"></a>16 Sentinel</h2><p>Sentinel(哨兵)是Redis的高可用性的解决方案. 这里给出一个书上的例子<br><img src="https://s1.ax1x.com/2020/11/05/B26SPO.png" alt="哨兵机制"></p><p>如果此时故障发生,server1下线时间超过了用户设定的下线时长上限, 哨兵就会对server1执行故障转移操作.<br>首先, 哨兵会选择一个从服务器升级为主服务器.<br>其次, 哨兵会向所有从服务器发送新的复制指令.<br>最后, 当server1恢复的时候,哨兵会让他成为新主服务器的从服务器.  </p><h3 id="16-1-哨兵的启动"><a href="#16-1-哨兵的启动" class="headerlink" title="16.1 哨兵的启动"></a>16.1 哨兵的启动</h3><p>首先初始化服务器,然后将普通服务器使用的代码替换为哨兵专用代码,初始化哨兵状态,初始化哨兵监视的主服务器列表,创建连接向主服务的网络连接.</p><p>具体每一步的创建和实现请参阅课本.</p><h3 id="16-2-获取主服务器的信息"><a href="#16-2-获取主服务器的信息" class="headerlink" title="16.2 获取主服务器的信息"></a>16.2 获取主服务器的信息</h3><p>哨兵默认会以每十秒一次的频率,向主服务器发送info命令,并且获取当前主服务器状态以及所有从服务器的状态, 如下图:<br><img src="https://s1.ax1x.com/2020/11/05/B2WcxU.png" alt="info信息解析"></p><h3 id="16-3-获取从服务器的信息"><a href="#16-3-获取从服务器的信息" class="headerlink" title="16.3 获取从服务器的信息"></a>16.3 获取从服务器的信息</h3><p>当哨兵发现有新的从服务器出现时,哨兵会创建相应的实例结构,以及命令连接和订阅连接.  </p><h3 id="16-4-向主服务器和从服务器发送信息"><a href="#16-4-向主服务器和从服务器发送信息" class="headerlink" title="16.4 向主服务器和从服务器发送信息"></a>16.4 向主服务器和从服务器发送信息</h3><p>在默认情况下哨兵会以每两秒一次的频率,通过命令连接发送消息给所有监视的服务器,消息包含哨兵本身的信息和目标服务器的信息.</p><p>注意当有多个哨兵监视一个服务器的时候, 服务器收到一个哨兵发来的消息的时候,所有哨兵都会收到这条消息,并且更新此服务器的状态,如下图.<br><img src="https://s1.ax1x.com/2020/11/05/B2o0ZF.png" alt="多个哨兵"></p><p>而且监视同一服务器的哨兵互相会使用Sentinels来保存彼此,同时也会创建哨兵网络进行通信,如下图:<br><img src="https://s1.ax1x.com/2020/11/05/B2HkaF.png" alt="哨兵网络"></p><h3 id="16-6-主观和客观下线状态"><a href="#16-6-主观和客观下线状态" class="headerlink" title="16.6 主观和客观下线状态"></a>16.6 主观和客观下线状态</h3><p>默认情况下哨兵会以1秒一次的频率向所有创建了连接的实例发送Ping命令,来判断实例是否在线.<br>如果多次ping都发现没有有效回复,则进入到主观下线的状态,此时这个哨兵会向其他哨兵询问,如果多个哨兵都判断这个服务器已经主观下线,则会进入到客观下线状态,启动故障转移操作.  </p><h3 id="16-8-选举领头哨兵"><a href="#16-8-选举领头哨兵" class="headerlink" title="16.8 选举领头哨兵"></a>16.8 选举领头哨兵</h3><p>当客观下线发生时,监视这个服务器的所有哨兵会协商选举出一个领头哨兵,对下线服务器进行故障转移操作.<br>选举的过程非常复杂,总结就是某个发送命令最快的哨兵将会成为领头.<br>故障转移操作如前文所述,不再重复.  </p><h2 id="17-集群"><a href="#17-集群" class="headerlink" title="17 集群"></a>17 集群</h2><h3 id="17-1-节点"><a href="#17-1-节点" class="headerlink" title="17.1 节点"></a>17.1 节点</h3><p>在刚开始的时候,每个节点都是互相独立的,处于一个只包含自己的集群当中.<br>可以用CLUSTER MEET 命令来进行握手,握手成功了就会把这两个节点添加到一个集群中.  </p><h4 id="17-1-2-集群数据结构"><a href="#17-1-2-集群数据结构" class="headerlink" title="17.1.2 集群数据结构"></a>17.1.2 集群数据结构</h4><p>clusterNode 结构保存了一个节点当前的状态,同时也会为集群中所有的其他节点都创建一个相应的clusterNode结构.</p><h4 id="17-1-3-握手命令的实现"><a href="#17-1-3-握手命令的实现" class="headerlink" title="17.1.3 握手命令的实现"></a>17.1.3 握手命令的实现</h4><p><img src="https://s1.ax1x.com/2020/11/05/BRNh2q.png" alt="握手实现"></p><h3 id="17-2-槽指派"><a href="#17-2-槽指派" class="headerlink" title="17.2 槽指派"></a>17.2 槽指派</h3><p>Redis集群通过分片的方式保存数据库中的键值对:<br>整个数据库被分为16384个槽(slot),每个键都属于一个槽.<br>当数据库中的所有槽全部都有节点在处理时,集群处于上线状态.  </p><p>clusterNode结构的slots和numslot属性记录了节点负责处理哪些槽.<br>集群中的每个节点都会知道这16384个槽分别是由哪些节点在负责的.  </p><h3 id="17-3-在集群中执行命令"><a href="#17-3-在集群中执行命令" class="headerlink" title="17.3 在集群中执行命令"></a>17.3 在集群中执行命令</h3><p>当客户端向节点发送与数据库键有关的命令时,接受命令的节点会计算出槽,并指引客户端转向到正确的节点.  </p><p>注意保存键的时候也要计算槽,并且保存在跳跃表中slots_to_keys</p><h3 id="17-4-重新分片"><a href="#17-4-重新分片" class="headerlink" title="17.4 重新分片"></a>17.4 重新分片</h3><p>这个过程比较复杂,涉及到一致性哈希的问题,这里直接引用<br><img src="https://s1.ax1x.com/2020/11/05/BR6oEq.png" alt="重新分片的原理"></p><h3 id="17-6-复制与故障转移"><a href="#17-6-复制与故障转移" class="headerlink" title="17.6 复制与故障转移"></a>17.6 复制与故障转移</h3><h4 id="17-6-1-设置从节点"><a href="#17-6-1-设置从节点" class="headerlink" title="17.6.1 设置从节点"></a>17.6.1 设置从节点</h4><p>可以使用</p><pre><code>CLUSTER REPLICATE &lt;node_id&gt;</code></pre><p>来让接收命令的节点成为node_id节点的从节点,并开始对主节点进行复制,具体步骤如下图:<br><img src="https://s3.ax1x.com/2020/11/18/Dm0QVs.png" alt="从节点设置"></p><h4 id="17-6-2-故障检测"><a href="#17-6-2-故障检测" class="headerlink" title="17.6.2 故障检测"></a>17.6.2 故障检测</h4><p>集群中的每个节点都会定期向集群中其他节点发送PING消息,如果没有在规定时间内收到PONG消息回应,原始节点就会标记该回应节点为疑似下线(PFail).<br>当主节点通过消息得知主节点B认为C进入了疑似下线状态,主节点A会在自己的clusterState.nodes字典中找到C对应的clusterNode结构并且把B的下线报告添加进去.<br>如果在一个集群里半数以上负责处理槽的主节点都将某个主节点X报告为疑似下线,那么这个X将被标记为已下线(Fail),标记X为fail的节点将会向集群广播一条关于主节点X已经下线的消息,所有收到这个消息的节点都会把X标记为已经下线.  </p><h4 id="17-6-3-故障转移"><a href="#17-6-3-故障转移" class="headerlink" title="17.6.3 故障转移"></a>17.6.3 故障转移</h4><p>当一个从节点发现自己正在复制的主节点进入了已下线状态时,从节点将开始对下线节点进行故障转移:<br>1) 所有从节点中选中一个从节点.<br>2) 被选中节点执行slave of no one 命令,成为新的主节点.<br>3) 新的主节点会撤销所有对已下线节点的槽指派,并且将这些槽全部指派给自己.<br>4) 向集群广播一条PONG消息,让集群中所有其他节点知道这个节点已经接管了其他所有剩余节点.<br>5) 新节点开始接收和自己负责处理槽相关的命令请求.  </p><h4 id="17-6-4-选举新的主节点"><a href="#17-6-4-选举新的主节点" class="headerlink" title="17.6.4 选举新的主节点"></a>17.6.4 选举新的主节点</h4><p>类似于16章.</p><h3 id="17-7-消息"><a href="#17-7-消息" class="headerlink" title="17.7 消息"></a>17.7 消息</h3><p>消息主要有五种,meet,ping,pong,fail,publish.<br>具体实现略.</p><h1 id="第四部分-独立功能的实现"><a href="#第四部分-独立功能的实现" class="headerlink" title="第四部分: 独立功能的实现"></a>第四部分: 独立功能的实现</h1><h2 id="18-发布与订阅"><a href="#18-发布与订阅" class="headerlink" title="18. 发布与订阅"></a>18. 发布与订阅</h2><p>通过subcribe命令执行对某个频道的订阅,每当有其他客户端向被订阅的频道发送消息时,所有订阅者都会收到这个消息.<br>可以通过<code>publish &lt;channel&gt; &lt;message&gt;</code> 来发送一个消息.<br>除了直接订阅该频道,还可以模式匹配,比如这个例子:</p><p><img src="https://s3.ax1x.com/2020/11/25/DU2KqP.png" alt="模式匹配"></p><h3 id="18-1-频道的订阅与退订"><a href="#18-1-频道的订阅与退订" class="headerlink" title="18.1 频道的订阅与退订"></a>18.1 频道的订阅与退订</h3><p>Redis把所有频道的订阅关系都保存在服务器状态的pubsub_channels字典里面,这个字典的键是某个被订阅的频道,键的值则是一个链表,链表里面记录了所有订阅这个频道的客户端.  </p><p>订阅频道的操作就是把这个客户端加到链表的末尾,取消订阅就是对应的把这个节点从链表中删除.  </p><h3 id="18-2-模式的订阅与退订"><a href="#18-2-模式的订阅与退订" class="headerlink" title="18.2 模式的订阅与退订"></a>18.2 模式的订阅与退订</h3><p>所有的模式都保存在pubsub_patterns这个属性里,这个属性是一个链表,链表中的每个节点都包含一个pubsubPattern结构,这个结构的pattern属性记录了被订阅的模式,client属性记录了被订阅模式的客户端.<br>当新增模式订阅的时候,就会新增一个pubsubPattern结构然后追加到链表末尾,如下图:</p><p><img src="https://s3.ax1x.com/2020/11/25/DUo13T.png" alt="订阅模式"></p><p>退订时直接遍历链表,查找并删除对应的节点.  </p><h3 id="18-3-发送消息"><a href="#18-3-发送消息" class="headerlink" title="18.3 发送消息"></a>18.3 发送消息</h3><h4 id="18-3-1-将消息发送给频道订阅者"><a href="#18-3-1-将消息发送给频道订阅者" class="headerlink" title="18.3.1 将消息发送给频道订阅者"></a>18.3.1 将消息发送给频道订阅者</h4><p>在pubsub_channels字典里找到频道的订阅者名单(一个链表),然后将消息发送给名单上的所有客户端,需要一次遍历.  </p><h4 id="18-3-2-将消息发送给模式订阅者"><a href="#18-3-2-将消息发送给模式订阅者" class="headerlink" title="18.3.2 将消息发送给模式订阅者"></a>18.3.2 将消息发送给模式订阅者</h4><p>遍历pubsub_patterns,找到所有和频道匹配的模式,把消息发送给订阅了这些模式的客户端.  </p><h3 id="18-4-查看订阅信息"><a href="#18-4-查看订阅信息" class="headerlink" title="18.4 查看订阅信息"></a>18.4 查看订阅信息</h3><p>PUBSUB CHANNELS <code>[pattern]</code> 可以查看所有频道,pattern是可选参数,可以指定符合模式的所有频道;<br>这个命令是通过遍历pubsub_channels字典的所有键来实现.  </p><p>PUBSUB NUMSUB <code>[channel-1, channel-2]</code> 可以返回每个频道的订阅者数量,通过返回某个链表的长度来实现.  </p><p>PUBSUB NUMPAT 可以返回服务器当前被订阅模式的数量. 这个命令是通过返回pubsub_patterns链表的长度来实现.</p><h2 id="19-事务"><a href="#19-事务" class="headerlink" title="19. 事务"></a>19. 事务</h2><p>事务的定义:在事务被提交后会被Redis执行,执行过程中不会中断事务而去执行其他客户端的命令请求.<br>通过MULTI,EXEC,WATCH等命令来实现.  </p><p><img src="https://s3.ax1x.com/2020/12/02/DItMWR.png" alt="事务示例"></p><h3 id="19-1-事务实现"><a href="#19-1-事务实现" class="headerlink" title="19.1 事务实现"></a>19.1 事务实现</h3><p>multi命令标志着事务的开始,这一命令实际上是把客户端状态的flags属性中的REDIS_MUTLI标志位打开.<br>当一个客户端处于事务状态时,客户端发送的EXEC,DISCARD,WATCH,MULTI命令会被服务器立刻执行,其余的命令会被放入一个事务队列中.<br>每个客户端都有一个事务状态,这个状态包含一个事务队列和一个事务队列的长度,事务队列是一个multiCmd数组,每个结构都保存了一个已入队命令的信息,包括指向命令实现函数的指针,命令的参数和参数的数量.<br>如果服务器收到EXEC命令,会立刻执行队列中保存的所有命令,然后将所有执行结果全部返回给客户端.<br>实现如下:</p><p><img src="https://s3.ax1x.com/2020/12/02/DINv5Q.png" alt="EXEC的实现"></p><h3 id="19-2-WATCH命令的实现"><a href="#19-2-WATCH命令的实现" class="headerlink" title="19.2 WATCH命令的实现"></a>19.2 WATCH命令的实现</h3><p>watch命令是一个乐观锁,可以在exec命令执行之前,监视任意数量的数据库键,并在exec命令执行时检查被监视的键是否至少有一个已经被修改了,如果是的话服务器将拒绝执行事务,并向客户端返回代表事务执行失败的回复.</p><h4 id="19-2-1-WATCH命令的实现"><a href="#19-2-1-WATCH命令的实现" class="headerlink" title="19.2.1 WATCH命令的实现"></a>19.2.1 WATCH命令的实现</h4><p>每个Redis数据库都保存着一个watched_keys字典,这个字典的键是被WATCH命令监视的数据库键,字典的值则是一个链表,记录了所有监视数据库相应键的客户端.  </p><p>所有对数据库进行修改的命令,在执行完毕后都会对该字典进行检查,查看是否有客户端正在监视刚刚被修改过的数据库键,如果有,该客户端的事务安全性会被破坏,REDIS_DIRTY_CAS标识被打开.</p><p>当服务器接到一个客户端发来的EXEC命令时,服务器会根据这个客户端是否打开了上述标识来判断是否执行事务.  </p><h3 id="19-3-事务的ACID性质"><a href="#19-3-事务的ACID性质" class="headerlink" title="19.3 事务的ACID性质"></a>19.3 事务的ACID性质</h3><p>Redis和传统数据库事务的最大区别就在于不支持回滚,即使事务列表中某个命令在执行期间出现了错误也会继续执行下去,所以一定具有原子性.</p><p>而由于redis使用单线程来执行事务,所以一定是串行的,具有隔离性.</p><h2 id="20-Lua脚本"><a href="#20-Lua脚本" class="headerlink" title="20 Lua脚本"></a>20 Lua脚本</h2><p>略,生产环境中不常用.  </p><h2 id="21-排序"><a href="#21-排序" class="headerlink" title="21 排序"></a>21 排序</h2><p>具体实现并没有太多技巧,直接放一个重点回顾:</p><ul><li>sort命令通过将被排序键包含的元素载入到数组里面,然后对数组进行排序来完成对键进行排序的工作.  </li><li>在默认情况下,都按照键是数字来进行排序;如果使用alpha选项,都按照字符串的方式来进行排序.  </li><li>排序使用快速排序来实现</li><li>当使用by选项时,使用其他键的值作为权重来进行排序操作.  </li><li>当sort命令使用By选项时,命令使用其他键的值作为权重来进行排序操作.  </li><li>当sort命令同时使用多个选项时,命令先执行排序操作,然后执行limit选项,然后执行get选项,最后执行store选项.  </li><li>除了get选项,调整选项的拜访位置不会影响sort命令的结果. </li></ul><h2 id="22-二进制位数组"><a href="#22-二进制位数组" class="headerlink" title="22 二进制位数组"></a>22 二进制位数组</h2><p>略,生产环境中直接用字符串存储.  </p><h2 id="23-慢查询日志"><a href="#23-慢查询日志" class="headerlink" title="23 慢查询日志"></a>23 慢查询日志</h2><p>Redis的慢查询日志功能用于记录执行时间超过给定时长的命令请求.<br>slowlog-log-slower-than选项决定执行时间超过多少微妙的命令会被记录.<br>slowlog-max-len记录服务器最多保存多少条慢查询日志.  </p><p>慢查询日志保存在slowlog链表结构中.</p><h2 id="23-2-慢查询日志的阅览和删除"><a href="#23-2-慢查询日志的阅览和删除" class="headerlink" title="23.2 慢查询日志的阅览和删除"></a>23.2 慢查询日志的阅览和删除</h2><p>使用SLOWLOG_GET命令可以获取所有日志.  </p><h2 id="24-监视器"><a href="#24-监视器" class="headerlink" title="24 监视器"></a>24 监视器</h2><p>通过执行MONITOR命令,客户端可以把自己变为一个监视器,监视服务器当前处理的命令请求相关的信息.<br>该命令的实质是打开客户端的监视器标志,然后把客户端加到服务器的监视器链表末尾.</p><p>当服务器执行任何命令的时候,都会遍历监视器链表,把命令复制一份发过去.  </p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis设计与实现(二)</title>
      <link href="/2020/10/14/redis-she-ji-yu-shi-xian-er/"/>
      <url>/2020/10/14/redis-she-ji-yu-shi-xian-er/</url>
      
        <content type="html"><![CDATA[<p>本文是Redis设计与实现,第二版的读书笔记,来了解一下当下最流行的中间件到底是如何实现的,有哪些值得学习的设计思想.  </p><h1 id="第二部分-单机数据库的实现"><a href="#第二部分-单机数据库的实现" class="headerlink" title="第二部分: 单机数据库的实现"></a>第二部分: 单机数据库的实现</h1><h2 id="9-数据库"><a href="#9-数据库" class="headerlink" title="9 数据库"></a>9 数据库</h2><h3 id="9-1-服务器中的数据库"><a href="#9-1-服务器中的数据库" class="headerlink" title="9.1 服务器中的数据库"></a>9.1 服务器中的数据库</h3><p>Redis服务器将所有数据库都保存在db数组中,每个项都是一个redisDb结构,每个结构代表一个数据库.<br>初始化的时候默认是创建16个数据库.  </p><h3 id="9-2-切换数据库"><a href="#9-2-切换数据库" class="headerlink" title="9.2 切换数据库"></a>9.2 切换数据库</h3><p>客户端可以通过select命令来切换不同的数据库,默认是0号.  </p><h3 id="9-3-数据库键空间"><a href="#9-3-数据库键空间" class="headerlink" title="9.3 数据库键空间"></a>9.3 数据库键空间</h3><p>redisDb结构的dict字典保存了数据库中的所有键值对,所有的操作本质上都是对这个字典进行操作.<br>可以为键值对设定过期时间,redisDb结构的expires字典保存了数据库中所有键的过期时间.也可以被移除过期时间.  </p><h3 id="9-5-过期键删除策略"><a href="#9-5-过期键删除策略" class="headerlink" title="9.5 过期键删除策略"></a>9.5 过期键删除策略</h3><p>首先我们要明确一点,无论什么策略,对于CPU和内存无法做到全部友好,这就类似于空间换时间的理论一样,都是trade off.</p><h4 id="9-5-1-定时删除"><a href="#9-5-1-定时删除" class="headerlink" title="9.5.1 定时删除"></a>9.5.1 定时删除</h4><p>定时删除: 给每一个键加一个定时器,保证过期的键会在最短时间内被删除,并且释放其对应的内存.<br>优点是这种方案对内存是最友好的,缺点是这种方案对CPU时间是最不好的,CPU会被频繁中断来处理这一行为,因为现在CPU并不能高效的处理大量时间事件.</p><h4 id="9-5-2-惰性删除"><a href="#9-5-2-惰性删除" class="headerlink" title="9.5.2 惰性删除"></a>9.5.2 惰性删除</h4><p>惰性删除: 程序只会在取出键的时候才会对键进行过期检查.<br>优点是解放CPU,缺点是对内存非常不友好,甚至可以看做是一种内存泄漏,大量无用垃圾数据占用了大量的内存.</p><h4 id="9-5-3-定期删除"><a href="#9-5-3-定期删除" class="headerlink" title="9.5.3 定期删除"></a>9.5.3 定期删除</h4><p>上述两种方法的综合:<br>每隔一段时间执行一次删除过期键的操作,并且限制删除操作执行的时长和频率.<br>解决了过期键不删除导致的内存泄漏问题.<br>需要合理设定删除操作的执行时长和执行频率.  </p><h3 id="9-6-Redis的删除策略"><a href="#9-6-Redis的删除策略" class="headerlink" title="9.6 Redis的删除策略"></a>9.6 Redis的删除策略</h3><p>主要使用惰性+定期的结合.</p><h4 id="9-6-1-惰性删除的实现"><a href="#9-6-1-惰性删除的实现" class="headerlink" title="9.6.1 惰性删除的实现"></a>9.6.1 惰性删除的实现</h4><p>主要是通过expireIfNeeded函数对输入键进行检查,如果输入键已经过期就把输入键删除.  </p><h4 id="9-6-2-定期删除的实现"><a href="#9-6-2-定期删除的实现" class="headerlink" title="9.6.2 定期删除的实现"></a>9.6.2 定期删除的实现</h4><p>每当Redis的服务器周期性操作会调用activeExpireCycle函数,它在规定时间内分多次遍历服务器中各个数据库,从expire字典中随机检查一部分键的过期时间,并删除.</p><h3 id="9-7-AOF-RDB和复制功能对过期键的处理"><a href="#9-7-AOF-RDB和复制功能对过期键的处理" class="headerlink" title="9.7 AOF, RDB和复制功能对过期键的处理"></a>9.7 AOF, RDB和复制功能对过期键的处理</h3><p>在生成RDB文件的时候会自动把过期键过滤掉.<br>在AOF持久化模式运行过程中,如果发现过期会显式的向AOF文件中追加一条DEL命令.<br>当然在AOF重写的时候也会自动清理过期的键.  </p><p>如果是处于主从模式,且运行在复制模式下的时候,从服务器的过期键删除动作由主服务器控制:</p><ul><li>主服务器在删除一个过期键之后会给所有从服务器发送一个DEL命令.</li><li>从服务器在执行客户端发送的读命令时,即使遇到了过期键也不会删除.</li><li>从服务器只有接到del命令时才会删除.<br>这样可以保证主从服务器的数据一致性.  </li></ul><p>在Redis 2.8版本中,添加了数据库通知的功能,这个功能可以让客户端通过订阅的频道来获知数据库中键的变化,以及数据库中命令的执行情况.  </p><h3 id="9-8-发送通知的机制"><a href="#9-8-发送通知的机制" class="headerlink" title="9.8 发送通知的机制"></a>9.8 发送通知的机制</h3><p>这个功能是通过notify.c/notifyKeyspaceEvent函数实现的.<br><img src="https://s1.ax1x.com/2020/10/24/BZjWOx.png" alt="通知发送机制.png"><br>SADD 和DEL命令都会调用这个函数.  </p><h2 id="10-RDB持久化"><a href="#10-RDB持久化" class="headerlink" title="10 RDB持久化"></a>10 RDB持久化</h2><p>产生原因: Redis是内存数据库,它将自己的数据库状态存储在内存里,所以如果不持久化,一旦掉电就会丢失,因此我们需要产生RDB文件,RDB是一个压缩的二进制文件,包含了所有的键值对.  </p><h3 id="10-1-RDB文件的创建与载入"><a href="#10-1-RDB文件的创建与载入" class="headerlink" title="10.1 RDB文件的创建与载入"></a>10.1 RDB文件的创建与载入</h3><p>SAVE和BGSAVE可以生成RDB文件.<br>SAVE命令会阻塞Redis服务器进程.,直到RDB文件创建完毕为止;<br>BGSAVE命令会派生出一个子进程,然后由子进程负责创建RDB文件.<br>注意Redis是在启动时检测到RDB文件存在,它就会自动载入RDB文件.  </p><p>注意因为AOF文件的更新频率通常比RDB更新频率要高,所以:</p><ul><li>如果开启了AOF持久化功能,服务器会优先使用AOF文件来还愿数据库状态.  </li><li>只有AOF关闭的时候才会使用RDB文件来还原.  </li></ul><p>注意操作是不可重复执行的,会被服务器拒绝.<br>载入RDB文件期间,一样会始终处于阻塞状态.  </p><h3 id="10-2-自动间隔性保存"><a href="#10-2-自动间隔性保存" class="headerlink" title="10.2 自动间隔性保存"></a>10.2 自动间隔性保存</h3><p>通过设置save选项,每隔一段时间就会自动执行一次BGSAVE命令.<br>格式是 </p><pre><code>save 时间 修改次数</code></pre><p>可以有多条条件,只要有一个满足就会执行BGSAVE命令.  </p><p>Redis的服务器周期性操作函数serverCron默认每隔100毫秒就执行一次,其中一项工作就是检查save选项所保存的条件是否满足.  </p><h3 id="10-3-分析RDB文件"><a href="#10-3-分析RDB文件" class="headerlink" title="10.3 分析RDB文件"></a>10.3 分析RDB文件</h3><p>因为Redis本身带有RDB文件检查工具redis-check-dump, 网上也有很多处理RDB文件的工具,人工分析并无太大意义.这里只放一个书附带的总结图:<br><a href="https://imgchr.com/i/BmsyD0" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/25/BmsyD0.png" alt="BmsyD0.png"></a></p><h2 id="11-AOF持久化"><a href="#11-AOF持久化" class="headerlink" title="11 AOF持久化"></a>11 AOF持久化</h2><p>AOF(Append Only File) 和RDB的区别在于AOF是保存执行的写命令来记录数据库状态的.<br>本方法优先于RDB.</p><h3 id="11-1-AOF持久化的实现"><a href="#11-1-AOF持久化的实现" class="headerlink" title="11.1 AOF持久化的实现"></a>11.1 AOF持久化的实现</h3><p>命令追加: 服务器在执行完一个命令后会把这条命令追加到服务器状态的aof_buf缓冲区的末尾.  </p><p>写入与同步:<br>Redis的服务器进程就是一个事件循环,这个过程可以用以下伪代码表示:<br> <a href="https://imgchr.com/i/Bmg8JS" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/25/Bmg8JS.png" alt="Bmg8JS.png"></a></p><p> 注意现代的操作系统对文件的写入不是同步的,实际上是写入到一个缓冲区,当缓冲区满的时候才会执行同步.也可以通过fsync和fdatasync两个同步函数强制要求操作系统立刻将缓冲区的内存写入到磁盘.  </p><h3 id="11-2-AOF文件的载入和数据还原"><a href="#11-2-AOF文件的载入和数据还原" class="headerlink" title="11.2 AOF文件的载入和数据还原"></a>11.2 AOF文件的载入和数据还原</h3><p> 还原数据库的详细步骤:<br> 1) 创建一个不带网络连接的伪客户端.<br> 2) 循环进行读出一条命令,然后执行,直到所有的命令都被执行完毕.  </p><h3 id="11-3-AOF重写"><a href="#11-3-AOF重写" class="headerlink" title="11.3 AOF重写"></a>11.3 AOF重写</h3><p>AOF是记录命令的,所以AOF文件会越来越大,此时就需要重写.<br>实际上AOF文件”重写” 并不需要对现有的AOF文件进行任何的读取,分析或者写入,这个功能时通过读取服务器当前的数据库状态来实现的.<br>比如想要保存一个list,abcd,最简单的办法是从当前数据库中读取list内容,然后一次性push.<br>这样就节省了过程的时间,只关心结果即可.这就是AOF重写的原理.  </p><p>但是由于这个操作会有大量的写入操作,而Redis使用单个线程来处理命令请求,所以Redis会创建一个子进程来进行重写操作.这样有两个优点:</p><ul><li>子进程在进行AOF重写期间,父进程可以继续处理命令请求.  </li><li>子进程带有服务器进程的数据副本,所以无需使用锁就可以保证数据的安全性.  </li></ul><p>但是这样会出现数据不一致问题,所以Redis设置了一个AOF重写缓冲区,当Redis服务器执行完一个写命令之后,会同时发送给AOF缓冲区和AOF重写缓冲区.<br>之后缓冲区的内容会定期写入和同步到AOF文件.<br>当子进程完成之后,会触发一个信号处理函数(阻塞父进程),此时会将缓冲区文件全部写入新AOF文件,然后原子的替换老文件.  </p><h2 id="12-事件"><a href="#12-事件" class="headerlink" title="12 事件"></a>12 事件</h2><p>Redis是一个事件驱动程序, 有以下两类事件:<br><img src="https://s1.ax1x.com/2020/11/01/B0f61I.png" alt="Redis事件"></p><h3 id="12-1-文件事件"><a href="#12-1-文件事件" class="headerlink" title="12.1 文件事件"></a>12.1 文件事件</h3><ul><li>文件事件处理器使用I/O多路复用程序来同时监听多个套接字,并且根据套接字目前的任务来关联不同的事件处理器.  </li><li>当套接字准备好的时候,文件事件就会产生,处理器就会开始运行.  </li></ul><h4 id="12-1-1-文件事件处理器的构成"><a href="#12-1-1-文件事件处理器的构成" class="headerlink" title="12.1.1 文件事件处理器的构成"></a>12.1.1 文件事件处理器的构成</h4><p>尽管多个文件事件可能会并发的出现,单I/O多路复用程序会将所有产生的事件放到一个队列里,然后有序同步每次一个套接字的方式向文件事件分派器传送套接字. 当上一个套接字产生的事件被处理完之后多路复用程序才会向事件分派器传送下一个套接字.  </p><h4 id="12-1-2-I-O多路复用程序的实现"><a href="#12-1-2-I-O多路复用程序的实现" class="headerlink" title="12.1.2 I/O多路复用程序的实现"></a>12.1.2 I/O多路复用程序的实现</h4><p>Redis的I/O多路复用程序的功能都是通过包装select,epoll,evport和kqueue这些复用函数库来实现的.<br>(这里复习一下epoll,O(1),谁有事件就发个信号;select,O(n),只知道有事件,但是要全问一遍才知道到底是谁出问题了)</p><h4 id="12-1-3-一次标准的客户端和服务器的通信"><a href="#12-1-3-一次标准的客户端和服务器的通信" class="headerlink" title="12.1.3 一次标准的客户端和服务器的通信"></a>12.1.3 一次标准的客户端和服务器的通信</h4><p><img src="https://s1.ax1x.com/2020/11/02/B0T4EV.png" alt="通信过程"></p><h3 id="12-2-时间事件"><a href="#12-2-时间事件" class="headerlink" title="12.2 时间事件"></a>12.2 时间事件</h3><p>Redis的时间事件分为以下两类:</p><ul><li>定时事件, 一段程序在指定时间后执行一次,该事件在达到一次之后就会被删除</li><li>周期性事件, 一段程序每隔一段时间就执行一次,具体实现方式是更新when,从而不断被到达.<br>当前版本Redis只使用周期性事件,没有使用定时事件.  </li></ul><h4 id="12-2-1-实现"><a href="#12-2-1-实现" class="headerlink" title="12.2.1 实现"></a>12.2.1 实现</h4><p>服务器将所有的时间事件都放在一个无序链表中,每当时间事件执行器运行时,它就遍历整个链表,查找已经到达的时间事件.<br>注意链表是按照事件创造的时间进行排序的,并不是按照when的时间,所以每次都需要遍历链表,从而确保已经到达的事件都被执行.  </p><h4 id="12-2-3-serverCron函数"><a href="#12-2-3-serverCron函数" class="headerlink" title="12.2.3 serverCron函数"></a>12.2.3 serverCron函数</h4><p>Redis需要定期对自身的资源和状态进行检查和调整,以下操作都包含在serverCron这个函数里:</p><ul><li>更新服务器的各类统计信息,比如时间,内存占用,数据库占用情况.</li><li>清理数据库中的过期键值对</li><li>关闭和清理连接失效的客户端</li><li>尝试进行持久化操作</li><li>对从服务器进行定期同步</li><li>对集群进行连接测试和定期同步</li></ul><p>serverCron函数会定期被Redis服务器调用,其参数值可以修改.  </p><h3 id="12-3-事件的调度与执行"><a href="#12-3-事件的调度与执行" class="headerlink" title="12.3 事件的调度与执行"></a>12.3 事件的调度与执行</h3><p>这里放一个书上的Redis服务器的主程序流程图:</p><p><img src="https://s1.ax1x.com/2020/11/04/BcHiDO.png" alt="Redis主函数流程图"></p><p>实际就是一个循环中包含着事件调度函数,aeProcessEvents,该函数的伪代码如下所示:</p><p><img src="https://s1.ax1x.com/2020/11/04/BcHdMV.png" alt="事件调度函数"></p><p>这里要强调的是对文件事件和时间事件的处理都是同步,有序,原子地执行的,服务器不会中断事件处理,也不会对事件进行抢占,而且在有需要的时候主动让出执行权,确保不存在事件饥饿的问题.<br>缺点是由于时间事件在文件事件执行之后执行,所以时间事件的实际处理时间,会比设定的到达时间稍微晚一些.  </p><h2 id="13-客户端"><a href="#13-客户端" class="headerlink" title="13 客户端"></a>13 客户端</h2><h3 id="13-1-客户端属性"><a href="#13-1-客户端属性" class="headerlink" title="13.1 客户端属性"></a>13.1 客户端属性</h3><p>套接字fd: 判断当前客户端是真实客户端还是lua脚本或者AOF文件.<br>名字name: 默认为空,也可以自定义使得客户端更加清晰.<br>标志flags: 标志客户端当前的一些状态,如以下</p><p><img src="https://s1.ax1x.com/2020/11/04/Bg3Zu9.png" alt="客户端状态举例"></p><p>输入缓冲区querybuf: 保存客户端发送的命令请求.<br>命令argv与命令参数argc: 将命令进行解析之后进行分开保存.<br>命令的实现函数: 对不同的命令类型,比如”get””set”寻找对应的实现函数.<br>输出缓冲区: 执行命令得到的回复会被保存在这里.<br>身份验证authenticated: 记录客户端是否通过了身份验证.<br>时间time: 创建客户端的时间,和服务器连接的时间等等.  </p><h3 id="13-2-客户端的创建与关闭"><a href="#13-2-客户端的创建与关闭" class="headerlink" title="13.2 客户端的创建与关闭"></a>13.2 客户端的创建与关闭</h3><p>如果客户端是通过网络连接与服务器进行连接,那么在调用connect的时候,服务器会调用连接事件处理器,为客户端创建相应的客户端状态,并且添加到clients链表的末尾.  </p><p>如果是一个执行Lua脚本的伪客户端,那么服务器会关联在lua_client属性中,这个客户端只有在服务器被关闭时才会被关闭.<br>如果是AOF文件,服务器会在载入AOF文件的时候创建,并在载入完成时关闭这个伪客户端.  </p><h2 id="14-服务器"><a href="#14-服务器" class="headerlink" title="14 服务器"></a>14 服务器</h2><h3 id="14-1-服务器接受命令流程"><a href="#14-1-服务器接受命令流程" class="headerlink" title="14.1 服务器接受命令流程"></a>14.1 服务器接受命令流程</h3><p>略,只是基础业务流程,需要时可查询本书.</p><h3 id="14-2-服务器周期函数执行内容"><a href="#14-2-服务器周期函数执行内容" class="headerlink" title="14.2 服务器周期函数执行内容"></a>14.2 服务器周期函数执行内容</h3><p>略,更新各种资源,需要时可查询本书.</p><h3 id="14-3-初始化服务器"><a href="#14-3-初始化服务器" class="headerlink" title="14.3 初始化服务器"></a>14.3 初始化服务器</h3><h4 id="14-3-1-初始化服务器状态结构"><a href="#14-3-1-初始化服务器状态结构" class="headerlink" title="14.3.1 初始化服务器状态结构"></a>14.3.1 初始化服务器状态结构</h4><p>第一步是创建一个实例变量,为结构内的各个属性设置默认值,主要是通过initServerConfig()设置各种属性:</p><ul><li>服务器运行id</li><li>默认运行频率</li><li>默认配置文件路径</li><li>运行架构</li><li>默认端口号</li><li>RDB和AOF的持久化条件</li><li>LRU时钟</li><li>创建命令表</li></ul><h4 id="14-3-2-载入配置选项"><a href="#14-3-2-载入配置选项" class="headerlink" title="14.3.2 载入配置选项"></a>14.3.2 载入配置选项</h4><p>可以在启动时传入各种参数,这样就可以修改上一步设定的各种默认参数</p><h4 id="14-3-3-初始化服务器数据结构"><a href="#14-3-3-初始化服务器数据结构" class="headerlink" title="14.3.3 初始化服务器数据结构"></a>14.3.3 初始化服务器数据结构</h4><p><img src="https://s1.ax1x.com/2020/11/04/Bg6a9g.png" alt="服务器数据结构"></p><h4 id="14-3-4-还原数据库状态"><a href="#14-3-4-还原数据库状态" class="headerlink" title="14.3.4 还原数据库状态"></a>14.3.4 还原数据库状态</h4><p>使用RDB或者AOF进行还原数据库状态</p><h4 id="14-3-5-开始执行事件循环"><a href="#14-3-5-开始执行事件循环" class="headerlink" title="14.3.5 开始执行事件循环"></a>14.3.5 开始执行事件循环</h4><p>主要是时间事件和文件事件,如13章所述.  </p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis设计与实现(一)</title>
      <link href="/2020/10/03/redis-she-ji-yu-shi-xian-yi/"/>
      <url>/2020/10/03/redis-she-ji-yu-shi-xian-yi/</url>
      
        <content type="html"><![CDATA[<p>本文是Redis设计与实现,第二版的读书笔记,来了解一下当下最流行的中间件到底是如何实现的,有哪些值得学习的设计思想.  </p><h1 id="第一部分-数据结构与对象"><a href="#第一部分-数据结构与对象" class="headerlink" title="第一部分: 数据结构与对象"></a>第一部分: 数据结构与对象</h1><h2 id="2-简单动态字符串"><a href="#2-简单动态字符串" class="headerlink" title="2 简单动态字符串"></a>2 简单动态字符串</h2><p>C字符串: C语言传统表示的字符串,以空字符结尾.<br>Redis并没有使用这种方法,而是自己构建了一种SDS字符串(Simple Dynamic String),并作为默认字符串.<br>SDS除了保存数据库的字符串值之外,还用作缓冲区.  </p><h3 id="SDS的定义"><a href="#SDS的定义" class="headerlink" title="SDS的定义"></a>SDS的定义</h3><p>分为三部分,len free buf[]<br>len代表字符串长度,free代表未使用字节的数量,buf保存实际的数据.  </p><h3 id="SDS的优势"><a href="#SDS的优势" class="headerlink" title="SDS的优势"></a>SDS的优势</h3><p>1, 常数时间获取字符串长度.<br>2, 杜绝缓存区溢出,因为会先检查,然后完成空间分配的过程.<br>3, 减少修改字符串带来的内存重分配的次数.  具体是通过空间预分配和惰性空间释放来完成的.<br>空间预分配: 如果小于1M,就直接多分配一倍;如果大于1M,就多分配1M.<br>惰性空间释放: 释放的空间保存在free上,如果真正需要释放,再释放free.<br>4, 二进制安全,Redis不是用数组来保存字符,而是直接存储一系列二进制数据,这也是依赖于sds使用len来判断数据是否结束.<br>5,可以重用一部分二进制代码.</p><p>总结:<br><img src="https://s1.ax1x.com/2020/10/04/0JJauD.png" alt="SDS的优势.png"></p><h2 id="3-链表"><a href="#3-链表" class="headerlink" title="3 链表"></a>3 链表</h2><p>每个节点有前置节点,后置节点,节点的值.<br>当然Redis里还有一个list结构,构成如下:<br><img src="https://s1.ax1x.com/2020/10/06/0NQZQS.png" alt="list结构.png"><br>list结构提供了表头指针,表尾指针,链表长度,以及可以保存不同类型的值.  </p><h2 id="4-字典"><a href="#4-字典" class="headerlink" title="4 字典"></a>4 字典</h2><p>Redis使用MurmurHash2算法来计算键的哈希值,这种算法的优势是即使输入的键是有规律的,算法依旧会给出一个比较好的随机分部性,而且计算速度快.<br>其余部分类似java7中实现的hashmap底层结构.<br>注意Redis的rehash是渐进式的,集中式的会导致宕机.<br>在rehash的执行期间,任何的操作都会在新旧两表同时进行,但是添加只涉及新表,从而保证旧表一定会完成迁移.  </p><h2 id="5-跳跃表"><a href="#5-跳跃表" class="headerlink" title="5 跳跃表"></a>5 跳跃表</h2><p>只在有序集合键和集群节点中用作内部数据结构,在其他部分并没有用到过.  </p><h3 id="跳跃表的实现"><a href="#跳跃表的实现" class="headerlink" title="跳跃表的实现"></a>跳跃表的实现</h3><p>zskiplist结构:<br><img src="https://s1.ax1x.com/2020/10/06/0NDp3F.png" alt="跳跃表示例.png"></p><p>zskiplistNode结构:</p><ul><li>层: 代表当前是第几次,每个层带有两个属性: 前进指针和跨度.前进指针指向下个节点,跨度代表和下一个节点和当前节点之间的距离.  </li><li>后退指针: 指向上一个节点.  </li><li>分值: 节点按照所保存的分值,从小到大排列.  </li><li>成员对象.</li></ul><p>跳表的搜索方式:从高层往底层找,如果当前层没有,就从第一个比target小的节点的下一层开始继续寻找.  </p><h2 id="6-整数集合"><a href="#6-整数集合" class="headerlink" title="6 整数集合"></a>6 整数集合</h2><p>这个结构包含两个属性,集合包含的元素数量, 保存元素的数组.<br>各个项在数组中按照值的大小从小到大有序排列,并且数组中不包含任何的重复项.<br>注意集合的插入复杂度是O(N),因为有可能会引起升级,一旦升级,集合中所有的现有元素都必须升级到更长的级别.  </p><h2 id="7-压缩列表"><a href="#7-压缩列表" class="headerlink" title="7 压缩列表"></a>7 压缩列表</h2><p>略</p><h2 id="8-对象"><a href="#8-对象" class="headerlink" title="8 对象"></a>8 对象</h2><h3 id="对象的类型和编码"><a href="#对象的类型和编码" class="headerlink" title="对象的类型和编码"></a>对象的类型和编码</h3><p>set命令创建了俩对象,一个是键对象,一个是值对象.<br>Redis中的每个对象都由一个redisObject结构表示,包含三个属性:type类型,encoding编码,ptr指向底层实现数据结构的指针.<br>对于Redis数据库保存的键值对来说,键总是一个字符串,而值对象有以下5种:<br><img src="https://s1.ax1x.com/2020/10/06/0U3tDU.png" alt="值类型.png"></p><p>对应的,每种对象都对应着最少两种编码方式:<br><img src="https://s1.ax1x.com/2020/10/06/0U3f5d.png" alt="编码类型.png"></p><h3 id="字符串对象"><a href="#字符串对象" class="headerlink" title="字符串对象"></a>字符串对象</h3><p>如下图:<br><img src="https://s1.ax1x.com/2020/10/06/0U8lZD.png" alt="字符串对象编码.png"><br>简单总结就是整数型用int,短字符串用embstr,长字符串用raw.  </p><p>字符串对象常用命令和实现:<br><img src="https://s1.ax1x.com/2020/10/06/0UfXG9.png" alt="字符串命令实现.png"></p><h3 id="列表对象"><a href="#列表对象" class="headerlink" title="列表对象"></a>列表对象</h3><p>列表对象的底层可以选择使用ziplist或者linkedlist.<br>当满足以下两个条件时,列表对象使用ziplist编码:<br>1, 列表对象保存的所有字符串元素都小于64字节.<br>2, 列表对象保存的元素数量小于512个.  </p><p>相对应的也有类似的命令,不再重复了.  </p><h3 id="哈希对象"><a href="#哈希对象" class="headerlink" title="哈希对象"></a>哈希对象</h3><p>两种实现方式,ziplist或者hashtable.<br>当字符串长度增加的时候将会自动转换为hashtable.  </p><h3 id="集合对象"><a href="#集合对象" class="headerlink" title="集合对象"></a>集合对象</h3><p>集合对象的编码可以是intset或者hashtable.<br>当集合对象保存的所有元素都是整数值,或者集合对象保存的元素数量不超过512.<br>当集合长度变大就需要使用hashtable编码.  </p><h3 id="有序集合对象"><a href="#有序集合对象" class="headerlink" title="有序集合对象"></a>有序集合对象</h3><p>编码可以是ziplist或者skiplist.<br>skiplist编码的有序集合对象使用zset结构作为底层实现,zset包含一个字典和一个跳跃表.<br>通过字典可以在O(1)时间内根据索引找到对应的元素,基于跳跃表可以在O(logn)时间内查找上下界.  </p><h3 id="类型检查与命令多态"><a href="#类型检查与命令多态" class="headerlink" title="类型检查与命令多态"></a>类型检查与命令多态</h3><p>类型特定命令所进行的类型检查是通过redisObject结构的type属性来实现的.<br>多态命令的实现: 根据键的不同来进行同一命令的不同实现.  </p><h3 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h3><p>构建了一个引用技术实现的内存回收机制.</p><h3 id="对象共享"><a href="#对象共享" class="headerlink" title="对象共享"></a>对象共享</h3><p>主要是为了节约内存,比如AB都指向整数100,这个时候不会创建两个键值对,而是把整数100的被引用次数加一.<br>目前来说,Redis会在初始化服务器的时候创建一万个字符串对象包含0~9999的整数值,当服务器需要用到这些数字的时候就会使用这些共享对象.<br>注意Redis只对包含整数值的字符串对象进行共享.  </p><h3 id="对象的空转时长"><a href="#对象的空转时长" class="headerlink" title="对象的空转时长"></a>对象的空转时长</h3><p>redisObject结构包含的lru属性记录了对象最后一次被命令程序访问的时间.<br>当服务器打开了maxmemory选项,且服务器用于回收内存的算法为volatile-lru或者allkeys-lru的时候,空转时间较长的对象会优先被服务器释放.</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>golang入坑笔记</title>
      <link href="/2020/09/27/go-ru-keng-bi-ji/"/>
      <url>/2020/09/27/go-ru-keng-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="Golang学习笔记"><a href="#Golang学习笔记" class="headerlink" title="Golang学习笔记"></a>Golang学习笔记</h1><h2 id="课前声明"><a href="#课前声明" class="headerlink" title="课前声明"></a>课前声明</h2><p>本教程适用于已经学过Java,有Go学习需求的同学参照,不适合于初学者.<br>语言只是形式,所以一些非Go特有的细节我会略过.  </p><h2 id="为什么要学习Go"><a href="#为什么要学习Go" class="headerlink" title="为什么要学习Go"></a>为什么要学习Go</h2><p>1,go对于并发和线程的支持更加简单.<br>2,字节等很多大公司在增加go的使用.<br>3,方便部署和开发,go编译出来的文件直接就是exe,可以在服务器上直接运行.  </p><h2 id="课程视频"><a href="#课程视频" class="headerlink" title="课程视频:"></a>课程视频:</h2><p>综合比较了几个视频的评价,感觉b站上的这个视频是最好的,包含视频和博客:<br>视频地址:<br><a href="https://www.bilibili.com/video/BV14C4y147y8/?spm_id_from=333.788.videocard.0" target="_blank" rel="noopener">https://www.bilibili.com/video/BV14C4y147y8/?spm_id_from=333.788.videocard.0</a><br>博客地址:<br><a href="https://www.liwenzhou.com/" target="_blank" rel="noopener">https://www.liwenzhou.com/</a></p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置:"></a>环境配置:</h2><p><em>学习golang必须要使用VPN!</em><br>虽然课程中使用的是vscode,但是我亲测发现使用idea是更好的,配置更加便捷.<br>具体的步骤百度idea配置golang即可,非常简单.  </p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><ul><li>在*.go对应的目录下使用go build命令会在当前目录生成可执行文件,本质是会扫描当前的目录下的所有.go文件.  </li><li>如果在别的路径下运行go build &lt;路径&gt;,那么会在该目录下生成可执行文件.  </li><li>可以使用go build -o &lt;名字&gt;来指定编译出来的二进制文件的名字.  </li></ul><h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><p>go run, 直接运行文件.<br>go install, 先执行go build,然后再copy exe文件到bin目录去, 结果就是在任何地方都可以直接使用按照exe的名字运行文件.  </p><h2 id="跨平台编译"><a href="#跨平台编译" class="headerlink" title="跨平台编译"></a>跨平台编译</h2><p>首先要set 指定运行平台的环境,比如:</p><pre><code>SET CGO_ENABLED=0  // 禁用CGOSET GOOS=linux  // 目标平台是linuxSET GOARCH=amd64  // 目标处理器架构是amd64</code></pre><p>Mac 下编译 Linux 和 Windows平台 64位 可执行程序：</p><pre><code>CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go buildCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build</code></pre><p>更多的可以参考原博客,不用记住,用到的时候查一下就好了,或者写成.sh文件方便调用. </p><h2 id="变量和基础声明"><a href="#变量和基础声明" class="headerlink" title="变量和基础声明"></a>变量和基础声明</h2><p>package: 声明当前包,每个包有一个main作为程序的入口.<br>函数外的每个语句都必须以关键字开始,const,func,var等等.  </p><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>变量需要先声明后使用,且不支持重复声明,而且声明了非全局变量必须使用.<br>使用var来声明变量,声明的时候必须指明类型,静态类型语言.<br>命名使用驼峰式.  </p><pre><code>比如:  var s1 string如果是多个,注意批量声明是使用圆括号,而且不用逗号.注意声明的值是默认空值.  var (    s1 string    s2 int    s3 bool)如果是赋值的话,存在一个类型推导机制.比如:  var s1 = &quot;happy&quot;就不需要加类型.在函数内还可以使用简短变量声明:s3 :=&quot;happy&quot;这一句也是可以的.  _可以用来代表匿名变量,充当占位值,不分配内存空间.  </code></pre><h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><p>const关键字引出,常量在定义的时候必须赋值,而且不能修改.<br>也可以批量赋值,默认如果不赋值的常量就和上面一行是一样的.  </p><p>这里补充一个关键字,iota,这是go语言的常量计数器,只能在常量的表达式中使用.<br>iota在const出现的时候被置为0,每新增一行常量就加一.</p><pre><code>const (    a1 = iota    a2 // 1    a3 // 2)</code></pre><h2 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h2><p>使用fmt这个包的print,分为三种:<br>print是直接打印,printf是格式化输出,使用占位符;println是自动添加一个换行符.  </p><h2 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h2><p>包含int8,int16,int32,int64,对应的还有uint的.<br>八进制是用0开头,16进制使用0x开头.  </p><h2 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h2><p>最大的浮点数: math.MaxFloat32,注意是一个常量,整型之类的也类似.<br>默认go语言的小数都是float64.  </p><h2 id="复数"><a href="#复数" class="headerlink" title="复数"></a>复数</h2><p>complex64,1+2i</p><h2 id="布尔值"><a href="#布尔值" class="headerlink" title="布尔值"></a>布尔值</h2><p>默认是false,不允许将整数转换为bool.<br>无法参与数值运算,也不能参与类型转换.  </p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><p>字符串只能用双引号.<br>转义使用反斜线\,比如单斜线\应该变为\\,双引号应该变为\”\”<br>多行字符串:<br><code>xxxxxxxxxxx</code><br>不用加字符串的双引号.<br>字符串常用操作:<br>len(str),求长度;<br>‘+’, 代表字符串拼接;<br>strings.Split(str,”分隔符”),代表字符串切割<br>strings.contains(str,”查询的”),字符串包含<br>strings.HasPrefix(str, “前缀”)/strings.HasSuffix,查询前缀后缀.<br>strings.Index()查询子串的位置.<br>strings.Joins()拼接字符串数组;  </p><h3 id="字符串修改"><a href="#字符串修改" class="headerlink" title="字符串修改"></a>字符串修改</h3><p>字符串是不可修改的,如果要修改的话只能先变成[]rune(str)切片类型.<br>然后再使用string(s3)来重新变成字符.  </p><h2 id="if-else语句和for循环"><a href="#if-else语句和for循环" class="headerlink" title="if-else语句和for循环"></a>if-else语句和for循环</h2><p>1,不需要把条件括起来,使用空格即可.<br>2,使用大括号代表执行体.  </p><pre><code>if a&gt;1 {}for i:=0;i&lt;1;i++ {}</code></pre><p>还可以for range遍历</p><pre><code>for i,v := range s{}这里是s可以是数组等可以遍历的结构体.</code></pre><p>break跳出,continue继续下一次.  </p><h2 id="switch和goto"><a href="#switch和goto" class="headerlink" title="switch和goto"></a>switch和goto</h2><p>不鼓励使用,层次不分明.</p><pre><code>switch n{    case 1,3,4,5,7:        xxxx      case 2:          xxxx    default:        xxxx}也可以switch后面不加,到具体的case再判断.</code></pre><p>goto语句可以跳到任意的标签处</p><pre><code>go breakTagbreakTag:    xxxx</code></pre><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><p>++, – 单独的语句,不能用来赋值.<br>&amp;&amp;,||,!都和java一致.</p><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>声明:<br>var a1 [3]bool<br>如果不初始化,默认都是零值.<br>var a1 [3]bool{1,1,1},固定长度.<br>a1 := […]int{一堆数字},代表可变长度.<br>或者使用冒号来代表遍历,<br>a10 :=[5]int{0:1, 4:2}<br>可以使用类似的方法进行初始化.<br>一般不用数组,使用可变数组slices. </p><p>多维数组:<br>var all [3][2]int</p><p>注意数组是值类型,改变副本的值不会改变本身的值,赋值和传参会复制整个数组. </p><h3 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h3><p>可变长度的数组.<br>var s []int;实际上就是不写长度.<br>也可以用数组得到,左闭右开.  [0:4]类似这样.<br>切片是个引用类型,实际的数据存在数组中.<br>如果两个切片共享底层数组,修改一个会影响另一个.<br>可以使用append方法给切片添加元素,格式是: s1 = append(s1,”xxx”)<br>可以使用copy函数复制切片,相当于深拷贝.<br>go里面没有删除函数,只能自己手动切分.<br>cap函数可以返回分配的内存空间的大小.<br>底层数组都是占用一块连续的内存.  </p><h2 id="指针操作"><a href="#指针操作" class="headerlink" title="指针操作"></a>指针操作</h2><p>go语言的指针操作只包含两个内容:<br>&amp;n代表取地址, *代表取值.  </p><h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><pre><code>map[KeyType]ValueType</code></pre><p>变量的默认初始值nil, 需要使用make()函数分配内存.</p><pre><code>make(map[KeyType]ValueType, [cap]),cap代表容量</code></pre><p>使用方式基本类比python,[]代表索引.</p><pre><code>scoreMap[&quot;小明&quot;] = 100userInfo := map[string]string{        &quot;username&quot;: &quot;沙河小王子&quot;,        &quot;password&quot;: &quot;123456&quot;,    }</code></pre><p>可以使用特殊写法来检测键是否存在,</p><pre><code>value, ok := map[key]本质是索引这个用法会返回俩参数,一个是值,另一个是成功与否</code></pre><p>遍历的时候可以采用range,类似python写法.<br>可以使用delete(map,key)的写法来删除一对键和值.  </p><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><pre><code>使用func关键字定义:func 函数名(参数)(返回值){    函数体}注意go的类型是定义在参数名后面的</code></pre><p>函数的参数中如果相邻变量的类型相同,可以省略类型.<br>固定参数搭配可变参数使用时,可变参数要放在固定参数的后面.<br>在多返回的时候,注意必须要用()把所有的返回值包裹起来.<br>也可以在定义的时候给返回值命名,并在函数体中直接使用这些变量,最后通过return关键字返回.  </p><h3 id="定义函数类型"><a href="#定义函数类型" class="headerlink" title="定义函数类型"></a>定义函数类型</h3><pre><code>type calculation func(int, int) int用于自定义函数类型之后就可以自定义函数变量var c calculation之后我们就可以把事先定义好的函数赋值给c,从而实现函数传入.</code></pre><p>函数可以作为参数传入,也可以作为返回值.  </p><h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><p>匿名函数的定义方式:</p><pre><code>func main() {    // 将匿名函数保存到变量    add := func(x, y int) {        fmt.Println(x + y)    }    add(10, 20) // 通过变量调用匿名函数    //自执行函数：匿名函数定义完加()直接执行    func(x, y int) {        fmt.Println(x + y)    }(10, 20)}</code></pre><p>注意匿名函数必须保存到某个变量,或者作为立即执行函数.  </p><p>闭包=函数+引用环境.  </p><h3 id="defer语句"><a href="#defer语句" class="headerlink" title="defer语句"></a>defer语句</h3><p>defer语句后面跟随的语句会延后处理,并且逆序执行.<br>看一个例子:</p><pre><code>func main() {    fmt.Println(&quot;start&quot;)    defer fmt.Println(1)    defer fmt.Println(2)    defer fmt.Println(3)    fmt.Println(&quot;end&quot;)}输出结果:startend321</code></pre><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><p><img src="https://s1.ax1x.com/2020/09/30/0ufyVO.png" alt="内置函数.png"></p><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><p>go语言中没有类的概念,也没有继承等<br>使用type和struct关键字定义结构体,如下:</p><pre><code>type 类型名 struct {    字段名 字段类型    字段名 字段类型    …}比如:type person struct {    name string    city string    age  int8}可以使用var关键字来实例化, var p1 person这样就实例化了一个p1实例,类型是person当然也可以用var p2 = new(person)</code></pre><h3 id="结构体初始化"><a href="#结构体初始化" class="headerlink" title="结构体初始化"></a>结构体初始化</h3><p>可以使用键值对进行初始化:</p><pre><code>p5 := person{    name: &quot;小王子&quot;,    city: &quot;北京&quot;,    age:  18,}fmt.Printf(&quot;p5=%#v\n&quot;, p5) //p5=main.person{name:&quot;小王子&quot;, city:&quot;北京&quot;, age:18}甚至可以不写键直接按顺序初始化,但是这样就必须初始化所有字段,而且按照声明顺序,同时不能和前面的混用.  p8 := &amp;person{    &quot;沙河娜扎&quot;,    &quot;北京&quot;,    28,}fmt.Printf(&quot;p8=%#v\n&quot;, p8) //p8=&amp;main.person{name:&quot;沙河娜扎&quot;, city:&quot;北京&quot;, age:28}</code></pre><h3 id="方法和接受者"><a href="#方法和接受者" class="headerlink" title="方法和接受者"></a>方法和接受者</h3><p>方法的定义格式:</p><pre><code>func (接收者变量 接收者类型) 方法名(参数列表) (返回参数) {    函数体}接收者变量：接收者中的参数变量名在命名时，官方建议使用接收者类型名称首字母的小写，而不是self、this之类的命名。例如，Person类型的接收者变量应该命名为 p，Connector类型的接收者变量应该命名为c等.//Person 结构体type Person struct {    name string    age  int8}//NewPerson 构造函数func NewPerson(name string, age int8) *Person {    return &amp;Person{        name: name,        age:  age,    }}//Dream Person做梦的方法func (p Person) Dream() {    fmt.Printf(&quot;%s的梦想是学好Go语言！\n&quot;, p.name)}func main() {    p1 := NewPerson(&quot;小王子&quot;, 25)    p1.Dream()}注意值类型和引用类型的接收者,值类型的接收者只针对副本,无法修改变量本身.当需要修改变量本身时,要用指针类型的接收者.</code></pre><h3 id="任意类型添加方法"><a href="#任意类型添加方法" class="headerlink" title="任意类型添加方法"></a>任意类型添加方法</h3><p>可以使用type给基本类型包装一下,然后再使用方法进行添加.<br>注意只能给当前包添加方法,也就是本地类型.  </p><pre><code>//MyInt 将int定义为自定义MyInt类型type MyInt int//SayHello 为MyInt添加一个SayHello的方法func (m MyInt) SayHello() {    fmt.Println(&quot;Hello, 我是一个int。&quot;)}func main() {    var m1 MyInt    m1.SayHello() //Hello, 我是一个int。    m1 = 100    fmt.Printf(&quot;%#v  %T\n&quot;, m1, m1) //100  main.MyInt}</code></pre><h3 id="结构体实现继承"><a href="#结构体实现继承" class="headerlink" title="结构体实现继承"></a>结构体实现继承</h3><p>实际上是运用类似于组合的方法来实现的,嵌套匿名结构体<br>看一个例子:  </p><pre><code>//Animal 动物type Animal struct {    name string}func (a *Animal) move() {    fmt.Printf(&quot;%s会动！\n&quot;, a.name)}//Dog 狗type Dog struct {    Feet    int8    *Animal //通过嵌套匿名结构体实现继承}func (d *Dog) wang() {    fmt.Printf(&quot;%s会汪汪汪~\n&quot;, d.name)}func main() {    d1 := &amp;Dog{        Feet: 4,        Animal: &amp;Animal{ //注意嵌套的是结构体指针            name: &quot;乐乐&quot;,        },    }    d1.wang() //乐乐会汪汪汪~    d1.move() //乐乐会动！}</code></pre><p>注意结构体字段大写开头表示公开,小写表示私有.  </p><h2 id="包"><a href="#包" class="headerlink" title="包"></a>包</h2><p>包是存放.go文件的文件夹,该目录下所有文件都必须在代码第一行添加</p><pre><code>package 包名</code></pre><p>名为main的包编译之后会得到一个可执行文件作为程序的入口,其他包不会.<br>想在一个包中引用另外一个包的标识符,该标识符必须是对外可见的,在Go语言中只需要首字母大写即可.  </p><p>import导入语句通常放在文件开头包声明语句的下面。<br>导入的包名需要使用双引号包裹起来。<br>包名是从$GOPATH/src/后开始计算的，使用/进行路径分隔。<br>Go语言中禁止循环导入包。</p><h3 id="init-初始化函数"><a href="#init-初始化函数" class="headerlink" title="init()初始化函数"></a>init()初始化函数</h3><p>在Go语言程序执行时导入包语句会自动触发包内部init()函数的调用。需要注意的是： init()函数没有参数也没有返回值。 init()函数在程序运行时自动被调用执行，不能在代码中主动调用它。<br><img src="https://s1.ax1x.com/2020/09/30/0Ki8UO.png" alt="init函数.png"></p><h3 id="fmt包的讲解"><a href="#fmt包的讲解" class="headerlink" title="fmt包的讲解"></a>fmt包的讲解</h3><p>占位符<br>T, 代表类型;<br>v, 代表值;<br>b, 二进制;<br>d, 十进制;<br>o, 八进制;<br>x, 十六进制;<br>s, 字符串;  </p><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>Go提倡面向接口编程.  </p><pre><code>type 接口类型名 interface{    方法名1( 参数列表1 ) 返回值列表1    方法名2( 参数列表2 ) 返回值列表2    …}type writer interface{    Write([]byte) error}</code></pre><p>接口一般是用er结尾,且参数可以省略名字只写类型.<br>注意go中不需要显式实现接口,只需要实现接口的所有方法即可.  </p><p>接口的主要用法是,接口可以存储所有实现了该接口的实例,比如下面这个例子:</p><pre><code>func main() {    var x Sayer // 声明一个Sayer类型的变量x    a := cat{}  // 实例化一个cat    b := dog{}  // 实例化一个dog    x = a       // 可以把cat实例直接赋值给x    x.say()     // 喵喵喵    x = b       // 可以把dog实例直接赋值给x    x.say()     // 汪汪汪}</code></pre><p>一个类型可以实现多个接口,一个接口也可以被多个类型实现.<br>接口之间也可以嵌套.  </p><p>空接口是指没有任何方法的接口,所以任何类型都实现了空接口,而空接口类型的变量可以存储任何类型的变量.<br>空接口可以用作函数的参数,从而实现可以接受任何类型的函数参数;或者作为map的值从而定义一个保存任意值的字典.  </p><h3 id="接口值"><a href="#接口值" class="headerlink" title="接口值"></a>接口值</h3><p>一个接口值=具体类型+具体值.<br>看一个例子:</p><pre><code>func main() {    var x interface{}    x = &quot;Hello 沙河&quot;    v, ok := x.(string)    if ok {        fmt.Println(v)    } else {        fmt.Println(&quot;类型断言失败&quot;)    }}</code></pre><p>其中</p><pre><code>x.(T)</code></pre><p>该语法返回两个参数，第一个参数是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败。</p><h2 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h2><p>在Go语言中,使用reflect.TypeOf()函数可以获取任意值的类型对象,从而可以访问任意值的类型信息;<br>还可以用reflect.ValueOf()来获取任意值的值对象.  </p><p>Go语言中的类型分为kind和type,kind是底层定义好的类型.kind主要有以下几种:</p><pre><code>type Kind uintconst (    Invalid Kind = iota  // 非法类型    Bool                 // 布尔型    Int                  // 有符号整型    Int8                 // 有符号8位整型    Int16                // 有符号16位整型    Int32                // 有符号32位整型    Int64                // 有符号64位整型    Uint                 // 无符号整型    Uint8                // 无符号8位整型    Uint16               // 无符号16位整型    Uint32               // 无符号32位整型    Uint64               // 无符号64位整型    Uintptr              // 指针    Float32              // 单精度浮点数    Float64              // 双精度浮点数    Complex64            // 64位复数类型    Complex128           // 128位复数类型    Array                // 数组    Chan                 // 通道    Func                 // 函数    Interface            // 接口    Map                  // 映射    Ptr                  // 指针    Slice                // 切片    String               // 字符串    Struct               // 结构体    UnsafePointer        // 底层指针)</code></pre><h3 id="通过反射获取和设置变量的值"><a href="#通过反射获取和设置变量的值" class="headerlink" title="通过反射获取和设置变量的值"></a>通过反射获取和设置变量的值</h3><pre><code>获取func reflectValue(x interface{}) {    v := reflect.ValueOf(x)    k := v.Kind()    switch k {    case reflect.Int64:        // v.Int()从反射中获取整型的原始值，然后通过int64()强制类型转换        fmt.Printf(&quot;type is int64, value is %d\n&quot;, int64(v.Int()))    case reflect.Float32:        // v.Float()从反射中获取浮点型的原始值，然后通过float32()强制类型转换        fmt.Printf(&quot;type is float32, value is %f\n&quot;, float32(v.Float()))    case reflect.Float64:        // v.Float()从反射中获取浮点型的原始值，然后通过float64()强制类型转换        fmt.Printf(&quot;type is float64, value is %f\n&quot;, float64(v.Float()))    }}func main() {    var a float32 = 3.14    var b int64 = 100    reflectValue(a) // type is float32, value is 3.140000    reflectValue(b) // type is int64, value is 100    // 将int类型的原始值转换为reflect.Value类型    c := reflect.ValueOf(10)    fmt.Printf(&quot;type c :%T\n&quot;, c) // type c :reflect.Value}设置,注意函数参数传递的是值拷贝,要传递地址变量才能修改变量值,在反射中使用专有的Elem()来获取指针对应的值.  package mainimport (    &quot;fmt&quot;    &quot;reflect&quot;)func reflectSetValue1(x interface{}) {    v := reflect.ValueOf(x)    if v.Kind() == reflect.Int64 {        v.SetInt(200) //修改的是副本，reflect包会引发panic    }}func reflectSetValue2(x interface{}) {    v := reflect.ValueOf(x)    // 反射中使用 Elem()方法获取指针对应的值    if v.Elem().Kind() == reflect.Int64 {        v.Elem().SetInt(200)    }}func main() {    var a int64 = 100    // reflectSetValue1(a) //panic: reflect: reflect.Value.SetInt using unaddressable value    reflectSetValue2(&amp;a)    fmt.Println(a)}</code></pre><h3 id="检测值"><a href="#检测值" class="headerlink" title="检测值"></a>检测值</h3><p>IsNil()报告v持有的值是否为nil。v持有的值的分类必须是通道、函数、接口、映射、指针、切片之一；否则IsNil函数会导致panic;<br>IsValid()返回v是否持有一个值。如果v是Value零值会返回假，此时v除了IsValid、String、Kind之外的方法都会导致panic。<br>看一个例子:</p><pre><code>func main() {    // *int类型空指针    var a *int    fmt.Println(&quot;var a *int IsNil:&quot;, reflect.ValueOf(a).IsNil())    // nil值    fmt.Println(&quot;nil IsValid:&quot;, reflect.ValueOf(nil).IsValid())    // 实例化一个匿名结构体    b := struct{}{}    // 尝试从结构体中查找&quot;abc&quot;字段    fmt.Println(&quot;不存在的结构体成员:&quot;, reflect.ValueOf(b).FieldByName(&quot;abc&quot;).IsValid())    // 尝试从结构体中查找&quot;abc&quot;方法    fmt.Println(&quot;不存在的结构体方法:&quot;, reflect.ValueOf(b).MethodByName(&quot;abc&quot;).IsValid())    // map    c := map[string]int{}    // 尝试从map中查找一个不存在的键    fmt.Println(&quot;map中不存在的键：&quot;, reflect.ValueOf(c).MapIndex(reflect.ValueOf(&quot;娜扎&quot;)).IsValid())}</code></pre><h3 id="结构体反射"><a href="#结构体反射" class="headerlink" title="结构体反射"></a>结构体反射</h3><p>对于任何结构体对象,可以通过reflect.Type的NumField() 和 Field()方法获得结构体成员的详细信息.<br><img src="https://s1.ax1x.com/2020/10/02/0l2PDx.png" alt="结构体反射.png"></p><p>还可以用StructField类型来描述结构体中一个字段的信息.  </p><pre><code>type StructField struct {    // Name是字段的名字。PkgPath是非导出字段的包路径，对导出字段该字段为&quot;&quot;。    // 参见http://golang.org/ref/spec#Uniqueness_of_identifiers    Name    string    PkgPath string    Type      Type      // 字段的类型    Tag       StructTag // 字段的标签    Offset    uintptr   // 字段在结构体中的字节偏移量    Index     []int     // 用于Type.FieldByIndex时的索引切片    Anonymous bool      // 是否匿名字段}</code></pre><h3 id="结构体反射示例"><a href="#结构体反射示例" class="headerlink" title="结构体反射示例"></a>结构体反射示例</h3><p>type student struct {<br>    Name  string <code>json:&quot;name&quot;</code><br>    Score int    <code>json:&quot;score&quot;</code><br>}</p><p>func main() {<br>    stu1 := student{<br>        Name:  “小王子”,<br>        Score: 90,<br>    }</p><pre><code>t := reflect.TypeOf(stu1)fmt.Println(t.Name(), t.Kind()) // student struct// 通过for循环遍历结构体的所有字段信息for i := 0; i &lt; t.NumField(); i++ {    field := t.Field(i)    fmt.Printf(&quot;name:%s index:%d type:%v json tag:%v\n&quot;, field.Name, field.Index, field.Type, field.Tag.Get(&quot;json&quot;))}// 通过字段名获取指定结构体字段信息if scoreField, ok := t.FieldByName(&quot;Score&quot;); ok {    fmt.Printf(&quot;name:%s index:%d type:%v json tag:%v\n&quot;, scoreField.Name, scoreField.Index, scoreField.Type, scoreField.Tag.Get(&quot;json&quot;))}</code></pre><p>}</p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>Go语言的最大优势,可以说Go正是因此而流行.<br>Go的并发是使用goroutine和channel进行实现.<br>在Go中不需要自己去写线程等,当需要让某个任务并发执行的时候只需要把任务包装成一个函数,然后开启一个goroutine去执行这个函数.  </p><p>启动goroutine的方式非常简单,只需要在调用的函数前面加一个 go 关键字即可.</p><p>对比看几个例子:</p><pre><code>func hello() {    fmt.Println(&quot;1&quot;)}func main() {    hello()    fmt.Println(&quot;2&quot;)}</code></pre><p>这段程序是顺序执行的,输出<br>1<br>2</p><p>我们修改一下:</p><pre><code>func hello() {    fmt.Println(&quot;1&quot;)}func main() {    go hello()    fmt.Println(&quot;2&quot;)}</code></pre><p>这段程序只输出一个2,没有1;原因是main所在的goroutine结束了,所有在这个main函数中启动的goroutine会一起结束,而此时我们开启的这个线程还没来得及输出1.<br>所以我们只要加上time.sleep就可以输出21了,注意在开启新的线程的同时,主线程是非阻塞的继续往下运行的.  </p><h3 id="线程的调度"><a href="#线程的调度" class="headerlink" title="线程的调度"></a>线程的调度</h3><p>GPM是Go语言自己实现的一套调度系统,这一段的讲解最好还是看李老师的讲解比较清楚.<br>放个截图:<br><img src="https://s1.ax1x.com/2020/10/02/01PBge.png" alt="GPM讲解.png"><br>运行GO时的调度器使用GOMAXPROCS来确定需要使用多少个OS线程来执行Go代码,默认是机器核心数.  </p><h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><p>单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。  </p><p>虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。  </p><p>Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。  </p><p>直观理解的话相当于是一个消息队列,总是遵循先入先出原则,声明channel的时候需要为其指定元素类型.  </p><p>声明格式:</p><pre><code>var 变量 chan 元素类型例子:var ch1 chan int   // 声明一个传递整型的通道var ch2 chan bool  // 声明一个传递布尔型的通道var ch3 chan []int // 声明一个传递int切片的通道</code></pre><p>初始化:</p><pre><code>make(chan 元素类型, [缓冲大小])ch4 := make(chan int)ch5 := make(chan bool)ch6 := make(chan []int)</code></pre><p>channel有3个操作:send,receive,close.<br>发送和接收都使用&lt;-符号。<br>示例代码:</p><pre><code>ch := make(chan int)ch &lt;- 10 // 把10发送到ch中x := &lt;- ch // 从ch中接收值并赋值给变量x&lt;-ch       // 从ch中接收值，忽略结果close(ch)//通道是会被垃圾回收机制自动回收的,关闭只是为了通知接收方线程所有的数据都发送完毕.  </code></pre><p>对一个关闭的通道再发送值就会导致panic。<br>对一个关闭的通道进行接收会一直获取值直到通道为空。<br>对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。<br>关闭一个已经关闭的通道会导致panic。</p><h3 id="无缓冲的通道"><a href="#无缓冲的通道" class="headerlink" title="无缓冲的通道"></a>无缓冲的通道</h3><p>无缓冲的通道是阻塞的,必须有人接收才能发送.<br>看一个例子:</p><pre><code>func recv(c chan int) {    ret := &lt;-c    fmt.Println(&quot;接收成功&quot;, ret)}func main() {    ch := make(chan int)    go recv(ch) // 启用goroutine从通道接收值    ch &lt;- 10    fmt.Println(&quot;发送成功&quot;)}</code></pre><p>无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这时值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。</p><p>使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。</p><h3 id="判断通道关闭"><a href="#判断通道关闭" class="headerlink" title="判断通道关闭"></a>判断通道关闭</h3><pre><code>// channel 练习func main() {    ch1 := make(chan int)    ch2 := make(chan int)    // 开启goroutine将0~100的数发送到ch1中    go func() {        for i := 0; i &lt; 100; i++ {            ch1 &lt;- i        }        close(ch1)    }()    // 开启goroutine从ch1中接收值，并将该值的平方发送到ch2中    go func() {        for {            i, ok := &lt;-ch1 // 通道关闭后再取值ok=false            if !ok {                break            }            ch2 &lt;- i * i        }        close(ch2)    }()    // 在主goroutine中从ch2中接收值打印    for i := range ch2 { // 通道关闭后会退出for range循环        fmt.Println(i)    }}</code></pre><p>从上面的例子中我们看到有两种方式在接收值的时候判断该通道是否被关闭，不过我们通常使用的是for range的方式。使用for range遍历通道，当通道被关闭的时候就会退出for range。</p><h3 id="单向通道"><a href="#单向通道" class="headerlink" title="单向通道"></a>单向通道</h3><pre><code>func counter(out chan&lt;- int) {    for i := 0; i &lt; 100; i++ {        out &lt;- i    }    close(out)}func squarer(out chan&lt;- int, in &lt;-chan int) {    for i := range in {        out &lt;- i * i    }    close(out)}func printer(in &lt;-chan int) {    for i := range in {        fmt.Println(i)    }}func main() {    ch1 := make(chan int)    ch2 := make(chan int)    go counter(ch1)    go squarer(ch2, ch1)    printer(ch2)}</code></pre><ul><li>chan&lt;- int是一个只写单向通道（只能对其写入int类型值），可以对其执行发送操作但是不能执行接收操作；</li><li>&lt;-chan int是一个只读单向通道（只能从其读取int类型值），可以对其执行接收操作但是不能执行发送操作。</li></ul><p>在函数传参及任何赋值操作中可以将双向通道转换为单向通道，但反过来是不可以的。</p><p>更多关于并发的内容请参考博客:<br><a href="https://www.liwenzhou.com/posts/Go/14_concurrence/" target="_blank" rel="noopener">https://www.liwenzhou.com/posts/Go/14_concurrence/</a></p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-序列化</title>
      <link href="/2020/09/11/java-kai-fa-jin-jie-bi-ji-xu-lie-hua/"/>
      <url>/2020/09/11/java-kai-fa-jin-jie-bi-ji-xu-lie-hua/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第十二章-序列化"><a href="#第十二章-序列化" class="headerlink" title="第十二章: 序列化"></a>第十二章: 序列化</h1><h2 id="85-其他方法优先于Java序列化"><a href="#85-其他方法优先于Java序列化" class="headerlink" title="85. 其他方法优先于Java序列化"></a>85. 其他方法优先于Java序列化</h2><p>尽可能的避免在任何地方使用反序列化.<br>而是使用跨平台的结构化数据表示法,比如JSON,这种实际上是使用键值对来存储的结构.<br>JSON本质就是一个数据表示法.  </p><h2 id="86-谨慎的实现Serializable接口"><a href="#86-谨慎的实现Serializable接口" class="headerlink" title="86. 谨慎的实现Serializable接口"></a>86. 谨慎的实现Serializable接口</h2><ul><li>一旦一个类被发布,就大大降低了”改变这个类的实现”的灵活性,因为这种序列化方式必须被永远兼容.  </li><li>增加了出现bug和安全漏洞的可能性.</li><li>随着类发行新的版本,相关的测试负担也会增加.</li></ul><p>内部类不应该实现Serializazable接口,因为没有默认的序列化形式.  </p><h2 id="87-考虑使用自定义的序列化形式"><a href="#87-考虑使用自定义的序列化形式" class="headerlink" title="87. 考虑使用自定义的序列化形式"></a>87. 考虑使用自定义的序列化形式</h2><p>如果事先没有认真考虑默认的序列化形式是否合适,不要贸然接受.一般来说只有自行设计的自定义序列化形式和默认的序列化形式基本相同时,才能接受默认的序列化形式.  </p><h2 id="88-89-90"><a href="#88-89-90" class="headerlink" title="88,89,90"></a>88,89,90</h2><p>TODO,感觉序列化是一个已经被废弃的部分,用的太少,需要的时候再来回顾一下.</p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 序列化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-并发</title>
      <link href="/2020/09/08/java-kai-fa-jin-jie-bi-ji-bing-fa/"/>
      <url>/2020/09/08/java-kai-fa-jin-jie-bi-ji-bing-fa/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第十一章-并发"><a href="#第十一章-并发" class="headerlink" title="第十一章: 并发"></a>第十一章: 并发</h1><h2 id="78-同步访问共享的可变数据"><a href="#78-同步访问共享的可变数据" class="headerlink" title="78. 同步访问共享的可变数据"></a>78. 同步访问共享的可变数据</h2><p>同步有两个效果:<br>1, 阻止一个线程看到对象处于不一样的状态<br>2, 保证进入同步方法的线程都能看到由同一个锁保护的之前所有修改效果.<br>注意写和读都是要同步的,只同步一个功能可能会造成不可预知的后果.<br>保证可见性最有效的方法是使用volatile变量,但是千万要注意这个变量是不保证原子性的.<br>更加好的办法是用AtomicLong类,保证原子性.  </p><h2 id="79-避免过度同步"><a href="#79-避免过度同步" class="headerlink" title="79. 避免过度同步"></a>79. 避免过度同步</h2><p>在一个被同步的区域内,不要调用设计成要被覆盖的方法,或者是被客户端以函数形式提供的方法.<br>比如使用CopyOnWriteArrayList来进行同步,每次写操作都是拷贝整个数组,所以迭代不需要锁定.<br>当不确定的时候,不要使用同步类,而是应该建立文档,注明它不是线程安全的.  </p><h2 id="80-executor-task和stream优先于线程"><a href="#80-executor-task和stream优先于线程" class="headerlink" title="80. executor,task和stream优先于线程"></a>80. executor,task和stream优先于线程</h2><p>尽可能不要自己手动创建和管理线程,而是使用线程池来集中管理.  </p><h2 id="81-并发工具优先于wait和notify"><a href="#81-并发工具优先于wait和notify" class="headerlink" title="81. 并发工具优先于wait和notify"></a>81. 并发工具优先于wait和notify</h2><p>并发集合中不可能排除并发活动;将它锁定没有什么作用,只会使程序的速度变慢.<br>同步器也成为信号器,能使得线程等待另一个线程的对象,比如Semaphore或者Countdown Latch,后者是一个带有int的参数,所有在等待的线程被调用之前必须在锁存器上调用countDown方法.  </p><p>注意始终使用wait循环模式来调用wait方法,永远不要在循环之外调用wait方法.<br>除非必要,应该始终使用notifyAll方法,而不是notify方法.</p><h2 id="82-线程安全的文档化"><a href="#82-线程安全的文档化" class="headerlink" title="82. 线程安全的文档化"></a>82. 线程安全的文档化</h2><p>线程安全是分为几个级别的:<br><img src="https://s1.ax1x.com/2020/09/12/wd6Gs1.png" alt="线程安全的等级.png"></p><h2 id="83-慎用延迟初始化"><a href="#83-慎用延迟初始化" class="headerlink" title="83. 慎用延迟初始化"></a>83. 慎用延迟初始化</h2><p>除非绝对要,否则就不要使用延迟初始化. 尤其是在线程同步的时候,如果多个线程共享一个延迟初始化的域,采用某种形式的同步是非常必要的.<br>如果出于性能的考虑而需要对静态域使用延迟初始化,就使用lazy initialization holder class模式,保证类要在被用到的时候才会被初始化.<br>如果是实例域,就使用双重校验模式. 如果是一个可以接受重复初始化的,就使用volatile修饰下的单重检查模式也可.  </p><h2 id="84-不要依赖于线程调度器"><a href="#84-不要依赖于线程调度器" class="headerlink" title="84. 不要依赖于线程调度器"></a>84. 不要依赖于线程调度器</h2><p>依赖于线程调度器来达到正确性或者性能要求的程序,很可能都是不可移植的.<br>如果线程没有在做有意义的工作,就不应该运行.<br>线程不应该一直处于忙等的状态.<br>线程优先级是最不可移植的特征.  </p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-异常</title>
      <link href="/2020/09/06/java-kai-fa-jin-jie-bi-ji-yi-chang/"/>
      <url>/2020/09/06/java-kai-fa-jin-jie-bi-ji-yi-chang/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第十章-异常"><a href="#第十章-异常" class="headerlink" title="第十章: 异常"></a>第十章: 异常</h1><h2 id="69-只针对异常的情况才使用异常"><a href="#69-只针对异常的情况才使用异常" class="headerlink" title="69. 只针对异常的情况才使用异常"></a>69. 只针对异常的情况才使用异常</h2><p>在正常工作的时候程序是不应该使用异常的,异常永远不应该被使用于正常的控制流.  </p><h2 id="70-对可恢复的情况使用受检异常-对编程错误使用运行时异常"><a href="#70-对可恢复的情况使用受检异常-对编程错误使用运行时异常" class="headerlink" title="70. 对可恢复的情况使用受检异常,对编程错误使用运行时异常"></a>70. 对可恢复的情况使用受检异常,对编程错误使用运行时异常</h2><p>如果期望调用者能够适当的恢复,对于这种情况应该使用受检异常.也就是用catch语句来捕捉并处理.<br>运行时异常和错误是不应该被捕获的,往往也不属于可恢复的情况,应该直接抛出并出现适当的错误消息.<br>实现的所有未受检的抛出结构应该都是RuntimeException的子类.  </p><h2 id="71-避免不必要的使用受检异常"><a href="#71-避免不必要的使用受检异常" class="headerlink" title="71. 避免不必要的使用受检异常"></a>71. 避免不必要的使用受检异常</h2><p>TODO</p><h2 id="72-优先使用标准的异常"><a href="#72-优先使用标准的异常" class="headerlink" title="72. 优先使用标准的异常"></a>72. 优先使用标准的异常</h2><p>代码的复用性是衡量程序员的一个有效方式.<br>不要直接使用重用Exception,RuntimeException,Throwable或者Error.对待这些要和对待抽象类一样.<br>比较常见的可重用异常如下表:<br><img src="https://s1.ax1x.com/2020/09/08/wl6qfO.png" alt="可重用异常.png"></p><h2 id="73-抛出与抽象对应的异常"><a href="#73-抛出与抽象对应的异常" class="headerlink" title="73. 抛出与抽象对应的异常"></a>73. 抛出与抽象对应的异常</h2><p>异常转译: 更高层的实现应该捕获低层的异常,同时抛出可以按照高层抽象解释的异常.<br>这样可以使得更高层的用户知道到底是哪一步抛出了异常.  </p><h2 id="74-每个方法抛出的所有异常都要建立文档"><a href="#74-每个方法抛出的所有异常都要建立文档" class="headerlink" title="74. 每个方法抛出的所有异常都要建立文档"></a>74. 每个方法抛出的所有异常都要建立文档</h2><p>始终要单独的声明受检异常,并且利用Javadoc的@throw标签,记录下抛出每个异常的条件.  </p><h2 id="75-在细节消息中包含失败-捕获信息"><a href="#75-在细节消息中包含失败-捕获信息" class="headerlink" title="75. 在细节消息中包含失败-捕获信息"></a>75. 在细节消息中包含失败-捕获信息</h2><p>千万不要在细节消息中包含密码和密钥,因为安全信息很多时候是外部可见的.<br>异常和错误消息,一个是给程序员看的,一个是给用户看的.  </p><h2 id="76-努力使得失败保持原子性"><a href="#76-努力使得失败保持原子性" class="headerlink" title="76. 努力使得失败保持原子性"></a>76. 努力使得失败保持原子性</h2><p>失败方法的调用应该让对象保持在失败之前的状态.<br>常见的有三种实现方法:</p><ul><li>在执行操作之前检验参数的有效性.</li><li>调整计算处理过程的顺序,使得任何可能会失败的计算部分都在对象状态被修改之前发生.</li><li>在对象的一份临时拷贝上进行操作.</li><li>编写一段恢复代码.</li></ul><h2 id="77-不要忽略异常"><a href="#77-不要忽略异常" class="headerlink" title="77. 不要忽略异常"></a>77. 不要忽略异常</h2><p>如果选择忽略异常,catch中应该包含一条注释,说明为什么可以这么做,并且变量应该命名为ignored.  </p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 异常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-通用编程规范</title>
      <link href="/2020/09/04/java-kai-fa-jin-jie-bi-ji-tong-yong-bian-cheng-gui-fan/"/>
      <url>/2020/09/04/java-kai-fa-jin-jie-bi-ji-tong-yong-bian-cheng-gui-fan/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第九章-通用编程"><a href="#第九章-通用编程" class="headerlink" title="第九章: 通用编程"></a>第九章: 通用编程</h1><h2 id="57-将局部变量的作用域最小化"><a href="#57-将局部变量的作用域最小化" class="headerlink" title="57. 将局部变量的作用域最小化"></a>57. 将局部变量的作用域最小化</h2><p>在变量声明的时候应该初始化,否则应该推迟这个变量的声明.<br>如果在循环终止之后不再需要循环变量的内容,for循环就优于while循环.  </p><h2 id="58-for-each循环优先于传统的for循环"><a href="#58-for-each循环优先于传统的for循环" class="headerlink" title="58. for-each循环优先于传统的for循环"></a>58. for-each循环优先于传统的for循环</h2><p>大部分不需要索引的情况下优先使用for-each循环,但是有三种情况是不能使用的:<br><img src="https://s1.ax1x.com/2020/09/07/wKANFI.png" alt="foreach不适用的时候.png"></p><h2 id="59-了解和使用类库"><a href="#59-了解和使用类库" class="headerlink" title="59. 了解和使用类库"></a>59. 了解和使用类库</h2><p>使用标准类库可以充分利用这些编写标准类库的专家的知识,以及之前的人使用的经验.<br>随机数生成器应该使用ThreadLocalRandom而不是Random类库.<br>先搜索java本身是否提供了类库,如果没有,就去找是否有开源的第三方类库,比如Guava等等.  </p><h2 id="60-如果需要精确答案-避免使用float和double"><a href="#60-如果需要精确答案-避免使用float和double" class="headerlink" title="60. 如果需要精确答案,避免使用float和double"></a>60. 如果需要精确答案,避免使用float和double</h2><p>如果想让系统来处理十进制小数点,并且不介意因为不使用基本类型而带来的不便,使用BigDecimal;<br>如果性能很关键,使用int来手动处理小数点.  </p><h2 id="61-基本类型优先于装箱基本类型"><a href="#61-基本类型优先于装箱基本类型" class="headerlink" title="61. 基本类型优先于装箱基本类型"></a>61. 基本类型优先于装箱基本类型</h2><p>装箱类型不要使用==,基本是错误的.</p><h2 id="62-尽量避免使用字符串"><a href="#62-尽量避免使用字符串" class="headerlink" title="62. 尽量避免使用字符串"></a>62. 尽量避免使用字符串</h2><p>1,如果字符串的类型是确定的,请直接转换,比如12345转换为int<br>2,字符串不适合代替枚举类型<br>3,字符串不适合代替聚合类型,最好单独写一个类.  </p><h2 id="63-了解字符串连接的性能"><a href="#63-了解字符串连接的性能" class="headerlink" title="63. 了解字符串连接的性能"></a>63. 了解字符串连接的性能</h2><p>为连接n个字符使用+号,需要n的平方级的时间.因为当两个字符串被连接在一起的时候,他们的内容都要被拷贝.应该使用StringBuilder来完成操作.</p><h2 id="64-通过接口引用对象"><a href="#64-通过接口引用对象" class="headerlink" title="64. 通过接口引用对象"></a>64. 通过接口引用对象</h2><p>比如创建一个hashMap:</p><pre><code>Map&lt;&gt; hashMap = new HashMap&lt;&gt;();</code></pre><p>这样在需要更改的时候,比如使用别的map类型的时候,只需要改变构造器即可.<br>但是注意,如果周围的代码需要这个实现的特有功能,那么新的功能也应该包含这个功能.</p><h2 id="65-接口优先于反射机制"><a href="#65-接口优先于反射机制" class="headerlink" title="65. 接口优先于反射机制"></a>65. 接口优先于反射机制</h2><p>反射机制的好处是,允许一个类使用另一个类,即使前者被编译时后者还压根不存在.<br>但是反射机制也存在一些问题:</p><p><img src="https://s1.ax1x.com/2020/09/07/wKuh5Q.png" alt="反射的性能损失.png"></p><h2 id="66-谨慎的使用本地方法"><a href="#66-谨慎的使用本地方法" class="headerlink" title="66. 谨慎的使用本地方法"></a>66. 谨慎的使用本地方法</h2><p>使用本地方法的应用程序不再是可以移植的,一定程度上破坏了java的跨平台性.<br>而且垃圾回收也不再是自动的,所以要坚决慎用.  </p><h2 id="67-谨慎的进行优化"><a href="#67-谨慎的进行优化" class="headerlink" title="67. 谨慎的进行优化"></a>67. 谨慎的进行优化</h2><p>有三条关于优化的名言:</p><p><img src="https://s1.ax1x.com/2020/09/07/wK1NkT.png" alt="优化的准则.png"></p><p>注意要努力编写好的程序,而不是快的程序;<br>但是在设计系统的时候,尤其是设计API,交互层协议和永久数据结构的时候,要考虑性能的因素.  </p><h2 id="68-遵守普遍接受的命名惯例"><a href="#68-遵守普遍接受的命名惯例" class="headerlink" title="68. 遵守普遍接受的命名惯例"></a>68. 遵守普遍接受的命名惯例</h2><p>这里给出一些例子,日常工作中应当自觉遵守这些惯例.  </p><p><img src="https://s1.ax1x.com/2020/09/07/wKtut0.png" alt="命名规则.png"></p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 通用编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-函数</title>
      <link href="/2020/08/30/java-kai-fa-jin-jie-bi-ji-han-shu/"/>
      <url>/2020/08/30/java-kai-fa-jin-jie-bi-ji-han-shu/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第八章-函数"><a href="#第八章-函数" class="headerlink" title="第八章: 函数"></a>第八章: 函数</h1><h2 id="49-检查参数的有效性"><a href="#49-检查参数的有效性" class="headerlink" title="49. 检查参数的有效性"></a>49. 检查参数的有效性</h2><p>在设计方法或者构造器的时候,应该考虑参数有哪些限制,并且把对应的限制写入到文档中.并且在方法的开头处通过显式的检查来实现这些限制.</p><h2 id="50-必要时进行保护性拷贝"><a href="#50-必要时进行保护性拷贝" class="headerlink" title="50. 必要时进行保护性拷贝"></a>50. 必要时进行保护性拷贝</h2><p>为了维护程序的稳定性,最好把外部对象进行拷贝之后再进行直接使用,避免外部对象发生不可预测的变化从而影响整个程序的性能.</p><h2 id="51-谨慎设计方法签名"><a href="#51-谨慎设计方法签名" class="headerlink" title="51. 谨慎设计方法签名"></a>51. 谨慎设计方法签名</h2><p>设计方法的名称时一定要能直接读出来这个方法是干啥的,从而提高可读性.<br>当参数列表过长时,可以采用设计一个输入类的形式,传入一个input对象来完成设计.<br>参数类型优先使用对应的接口,提高系统的可扩展性.</p><h2 id="52-慎用重载"><a href="#52-慎用重载" class="headerlink" title="52. 慎用重载"></a>52. 慎用重载</h2><p>永远不要导出两个具有相同参数数目的重载方法<br>最好是把允许使用的参数写到方法签名上,这种命名的好处是可以提供对应名称的读方法<br>重载时一定要避免: 同一组参数只要经过类型转换就可以传递给不同的重载方法.  </p><h2 id="53-慎用可变参数"><a href="#53-慎用可变参数" class="headerlink" title="53. 慎用可变参数"></a>53. 慎用可变参数</h2><p>在可变参数的个数少于3个时,最好设计几个不同参数个数的构造器,使用重载;<br>在大于3个时再使用可变参数.</p><h2 id="54-返回零长度的数组或者集合-而不是null"><a href="#54-返回零长度的数组或者集合-而不是null" class="headerlink" title="54. 返回零长度的数组或者集合,而不是null"></a>54. 返回零长度的数组或者集合,而不是null</h2><p>为了维护返回值类型的一致性,返回null的话很多size之类的函数就无法使用了.  </p><h2 id="55-谨慎返回optinal"><a href="#55-谨慎返回optinal" class="headerlink" title="55. 谨慎返回optinal"></a>55. 谨慎返回optinal</h2><p>TODO</p><h2 id="56-为所有导出的API元素编写文档注释"><a href="#56-为所有导出的API元素编写文档注释" class="headerlink" title="56. 为所有导出的API元素编写文档注释"></a>56. 为所有导出的API元素编写文档注释</h2><p>使用JavaDoc可以自动导出文档.<br>为了正确的编写API,必须在每个被导出的类,接口,构造器,方法和域声明之前增加一个文档注释<br>如果是可序列化的,也要对序列化形式编写文档<br>方法的文档注释应该清楚的写明白它和客户端之间的约定,也就是这个方法做了什么,而不是他怎么做的;还应该注明前置条件和后置条件,以及这个API的副作用,比如开了后台线程;<br>类的线程安全性和可序列化性需要在文档中进行特别说明.  </p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 函数与方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-Lambda和Stream</title>
      <link href="/2020/08/28/java-kai-fa-jin-jie-bi-ji-lambda-he-stream/"/>
      <url>/2020/08/28/java-kai-fa-jin-jie-bi-ji-lambda-he-stream/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第七章-Lambda和Stream"><a href="#第七章-Lambda和Stream" class="headerlink" title="第七章: Lambda和Stream"></a>第七章: Lambda和Stream</h1><h2 id="42-Lambda优先于匿名类"><a href="#42-Lambda优先于匿名类" class="headerlink" title="42. Lambda优先于匿名类"></a>42. Lambda优先于匿名类</h2><p>首先,默认删除所有出现在lambda表达式中的参数类型,除非编译器通知无法推导出类型.</p><p>注意lambda表达式一样是可以实现接口的,在java.util.function中给函数接口定义了很多可供选择的,这样lambda表达式就可以作为一个参数传进去了.</p><p>lambda表达式不能超过3行</p><p>lambda表达式无法获取对自身的引用,this指的是外围实例,但是匿名类中this指的是当前匿名类实例<br>,如果需要从函数对象的主体内部访问它,就必须使用匿名类</p><h2 id="43-方法引用优先于Lambda"><a href="#43-方法引用优先于Lambda" class="headerlink" title="43. 方法引用优先于Lambda"></a>43. 方法引用优先于Lambda</h2><p>方法引用能够完成的事情,lambda几乎一定可以完成.<br>但是方法引用更加简洁,build in函数总是优先于自己写的函数  </p><h2 id="44-坚持使用标准的函数接口"><a href="#44-坚持使用标准的函数接口" class="headerlink" title="44. 坚持使用标准的函数接口"></a>44. 坚持使用标准的函数接口</h2><p>只要标准的函数接口能够满足需求,应该尽可能的减少自定义的接口,便于维护一致性和可读性.<br>关键是要记住6个基础接口:<br>Operator接口代表其结果与参数类型一致的函数<br>Predicate接口代表带有一个参数并返回一个boolean的函数<br>Function接口代表其参数与返回的类型不一致的函数<br>Supplier接口代表没有参数并且返回一个值的函数<br>Consumer代表的是带有一个函数但是不返回任何值的函数</p><p>对于不同的类型在前缀部分加上对应的即可变为变体.</p><p>尤其是当标准接口已经很明确的表现了功能时,比如Comparator<t>这个接口,或者已经有很多默认的缺省接口的时候.</t></p><h2 id="45-谨慎使用Stream"><a href="#45-谨慎使用Stream" class="headerlink" title="45. 谨慎使用Stream"></a>45. 谨慎使用Stream</h2><p>注意变量的命名,对于理解其中的元素的结构或者意义至关重要.<br>避免使用stream来处理char值<br>一些只能使用代码块完成的东西:<br>1,代码块中可以修改局部变量.<br>2,代码块可以抛出受检异常,但是Lambda是做不到的.</p><p>应该使用Stream完成的任务:</p><ul><li>统一转换元素的序列</li><li>过滤元素的序列</li><li>利用单个操作合并元素的顺序</li><li>根据某些公共属性进行分组</li><li>搜索满足某些条件的元素的序列</li></ul><h2 id="46-优先选择Stream中无副作用的函数"><a href="#46-优先选择Stream中无副作用的函数" class="headerlink" title="46. 优先选择Stream中无副作用的函数"></a>46. 优先选择Stream中无副作用的函数</h2><p>注意java8给map集合添加了一个新方法merge,如果键对应的值不存在就直接赋值,如果存在就调用第三个参数对应的函数.</p><p>比较常用的收集器工厂是: toList,toSet,toMap,groupingBy和joining</p><h2 id="47-Stream要优先用Collection作为返回类型"><a href="#47-Stream要优先用Collection作为返回类型" class="headerlink" title="47. Stream要优先用Collection作为返回类型"></a>47. Stream要优先用Collection作为返回类型</h2><p>Collection接口时Iterable的一个子类型,有个stream的方法,所以提供了迭代和stream访问  </p><h2 id="48-谨慎使用Stream并行"><a href="#48-谨慎使用Stream并行" class="headerlink" title="48. 谨慎使用Stream并行"></a>48. 谨慎使用Stream并行</h2><p>使用Stream的并行指令必须满足: 数据结构可以被精确的划分为任意大小的子范围,并且交予不同的线程去完成. 因为Stream中执行这个任务的抽象是分割迭代器.<br>同时还需要满足在进行顺序处理时,需要保证引用局部性: 序列化的元素引用一起保存在内存中.</p><p>并行最好当且仅当适用于机器学习的时候,但是在那种场景下使用python或者spark会更好.</p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> Lambda和Stream </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-枚举和注解</title>
      <link href="/2020/08/26/java-kai-fa-jin-jie-bi-ji-mei-ju-he-zhu-jie/"/>
      <url>/2020/08/26/java-kai-fa-jin-jie-bi-ji-mei-ju-he-zhu-jie/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第六章-枚举和注解"><a href="#第六章-枚举和注解" class="headerlink" title="第六章: 枚举和注解"></a>第六章: 枚举和注解</h1><h2 id="34-用enum代替int常量"><a href="#34-用enum代替int常量" class="headerlink" title="34. 用enum代替int常量"></a>34. 用enum代替int常量</h2><p>java的枚举本质上是int值<br>枚举类型没有可以访问的构造器,因此是真正的final类. 而且客户端不能创建枚举类型的实例,也不能对其进行扩展,因此是存在声明过的枚举常量,所以枚举类型是完全实例受控的.</p><p>枚举在定义的时候已经提供了所有的实例,并且定义的时候已经完成了初始化.<br>而且可以用.values方法来访问所有的实例,注意是按照声明的顺序返回的.<br>toString方法会返回实例的名称,this方法也会返回实例的名称.</p><p>一个比较好的方法来实现对于每个实例都不同的方法是如何定义的:<br><img src="https://s1.ax1x.com/2020/09/03/wC7LBF.png" alt="枚举的重载.png"></p><p>实现原理是枚举类型的抽象方法必须被它所有的常量中的具体方法所覆盖,要注意此时定义的内部方法使用的是{}而不是(),()是用于调用构造函数传入参数使用的.</p><p>比如下面这个例子:<br><img src="https://s1.ax1x.com/2020/09/03/wCbi2q.png" alt="枚举的特定方法.png"></p><p>在枚举类中慎重使用switch方法,因为要注意可扩展性,可以考虑使用嵌套枚举.</p><p>使用枚举的时机:<br>当需要一组固定常量,并且在编译时就知道其成员的时候,使用枚举.</p><h2 id="35-用实例域代替序数"><a href="#35-用实例域代替序数" class="headerlink" title="35. 用实例域代替序数"></a>35. 用实例域代替序数</h2><p>每个实例都有一个默认分配的序数,可以使用ordinal方法调用,但是要尽量避免,最好自己定义一个order号来保存,方便扩展和维护.</p><h2 id="36-用EnumSet代替位域"><a href="#36-用EnumSet代替位域" class="headerlink" title="36. 用EnumSet代替位域"></a>36. 用EnumSet代替位域</h2><p>TODO<br>看不太懂.</p><h2 id="37-用EnumMap代替序数索引"><a href="#37-用EnumMap代替序数索引" class="headerlink" title="37. 用EnumMap代替序数索引"></a>37. 用EnumMap代替序数索引</h2><p>TODO<br>看不太懂.</p><h2 id="38-用接口模拟可拓展的枚举"><a href="#38-用接口模拟可拓展的枚举" class="headerlink" title="38. 用接口模拟可拓展的枚举"></a>38. 用接口模拟可拓展的枚举</h2><p>简而言之,虽然枚举类型是不可拓展的,但是可以通过枚举类实现接口,并且在调用接口的地方使用拓展类进行模拟拓展.</p><h2 id="39-注解优先于命名模式"><a href="#39-注解优先于命名模式" class="headerlink" title="39. 注解优先于命名模式"></a>39. 注解优先于命名模式</h2><p>简而言之就是使用专门定义的注解来避免使用命名模式这种自动化的读取策略来标志一个测试类.</p><h2 id="40-坚持使用Override注解"><a href="#40-坚持使用Override注解" class="headerlink" title="40. 坚持使用Override注解"></a>40. 坚持使用Override注解</h2><p>Override注解用于避免,初衷是覆盖,实际上由于参数设计原因变成了重载,这个问题.<br>所以注意要在你想覆盖超类方法的时候对每个方法都加上这个注解,手动添加.<br>或者在用于确保只覆盖原有方法而不添加新方法的地方.</p><h2 id="41-用标记接口定义类型"><a href="#41-用标记接口定义类型" class="headerlink" title="41. 用标记接口定义类型"></a>41. 用标记接口定义类型</h2><p>标记接口时不包含方法声明的接口,只是用于标记一下这个类实现了这个接口,<br>比如Serializable接口<br>这样可以在编译器就发现使用标记注解在运行期才能发现的错误.<br>标记接口只适用于类,标记注解适用于元素.  </p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 枚举和注解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-泛型</title>
      <link href="/2020/08/20/java-kai-fa-jin-jie-bi-ji-fan-xing/"/>
      <url>/2020/08/20/java-kai-fa-jin-jie-bi-ji-fan-xing/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第五章-泛型"><a href="#第五章-泛型" class="headerlink" title="第五章: 泛型"></a>第五章: 泛型</h1><h2 id="26-不要使用原生态类型"><a href="#26-不要使用原生态类型" class="headerlink" title="26.不要使用原生态类型"></a>26.不要使用原生态类型</h2><p>原生态类型指的是不带泛型的集合类,比如Set,List,不加泛型是为了和之前的代码兼容,在类型转换的时候要注意加上泛型.平常使用的时候尽可能的不要使用原生态类型.</p><h2 id="27-消除非受检的警告"><a href="#27-消除非受检的警告" class="headerlink" title="27.消除非受检的警告"></a>27.消除非受检的警告</h2><p>尽可能的把警告都消除掉,少用关闭警告的注解.</p><h2 id="28-列表优于数组"><a href="#28-列表优于数组" class="headerlink" title="28.列表优于数组"></a>28.列表优于数组</h2><p>1,数组是在运行时才发现错误,泛型在编译期就发现错误了<br>2,数组是具体化的,而泛型只在编译期进行使用,在运行时就擦除他们的元素类型信息了,这样也提高了泛型与没有使用泛型的代码的互用型.</p><p>不可具体化: 运行期包含的信息比编译期要少</p><p>因此数组和列表一般不可混用,最好在能使用List的部分都使用List</p><h2 id="29-优先考虑泛型"><a href="#29-优先考虑泛型" class="headerlink" title="29.优先考虑泛型"></a>29.优先考虑泛型</h2><p>只要时间允许,就把现有类型都泛型化.</p><h2 id="30-优先考虑泛型方法"><a href="#30-优先考虑泛型方法" class="headerlink" title="30.优先考虑泛型方法"></a>30.优先考虑泛型方法</h2><p>泛型方法比要求客户端转换输入参数并返回值的方法来的更加安全.</p><h2 id="31-使用有限通配符来提升API灵活性"><a href="#31-使用有限通配符来提升API灵活性" class="headerlink" title="31.使用有限通配符来提升API灵活性"></a>31.使用有限通配符来提升API灵活性</h2><p>主要是由于多态,在编写时要考虑使用&lt;? extends/super E&gt;的方式来保证子类也可以成立.<br>原则上是生产者是用extends,消费者用super,以及所有的comparable 和comparator都是消费者.</p><h2 id="32-谨慎并用泛型和可变参数"><a href="#32-谨慎并用泛型和可变参数" class="headerlink" title="32.谨慎并用泛型和可变参数"></a>32.谨慎并用泛型和可变参数</h2><p>可变参数实际上是基于数组的,我们在上面也说到了泛型和数组尽可能不要同时使用.</p><h2 id="33-优先考虑类型安全的异构容器"><a href="#33-优先考虑类型安全的异构容器" class="headerlink" title="33. 优先考虑类型安全的异构容器"></a>33. 优先考虑类型安全的异构容器</h2><p>如何实现一个集合中存在不同类型的实例,实现的方法就是使用Class<t>也就是Class对象来作为key,使用Object来作为对象.这样的问题就在于,键和值的类型并不一致,也就是一个Class.String<br>对应的值很有可能是个Integer,因此在存放的时候就要注意这一点.<br>但是实际上在取出的时候会使用cast方法强制转换成对应的键的类型,所以也不需要特别关注这一点.</t></p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 泛型 </tag>
            
            <tag> Effective Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法之美(一)</title>
      <link href="/2020/08/20/shu-ju-jie-gou-yu-suan-fa-zhi-mei-yi/"/>
      <url>/2020/08/20/shu-ju-jie-gou-yu-suan-fa-zhi-mei-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><ul><li><p>数组和链表的区别?<br>注意不能只回答插入和删除的时间复杂度,正确回答是:</p><pre><code>数组支持随机访问，根据下标随机访问的时间复杂度为O(1)</code></pre></li><li><p>何时使用容器类?何时使用数组?<br>对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发， 比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选</p></li><li><p>为什么大多数编程语言中数组编号是从0开始?<br>因为下标的最准确的定义应该是’偏移’,所以如果是从1开始,那么计算a[k]的内存地址就要比0开始多减一次.对于数组这种CPU级别的基础数据结构,优化是要压缩到极致的.</p></li></ul><h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><ul><li><p>双向链表在哪些情况下更加高效?<br>查找时,如果数据有序,就可以有两个方向,所以每次可以从上次的数据开始找.<br>删除时实际上需要前一个节点的指针,双向链表有这个功能.<br>同理,在某个节点前插入节点,双向链表也比较方便.</p></li><li><p>如何利用哨兵简化插入<br>在链表的前端添加一个哨兵节点,不存储对象只是指向head,这样就可以统一把插入到头部,或者中间或者尾部的代码用同一方法编写.</p></li></ul><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><ul><li><p>栈在求值表达式中的应用<br>一个保存操作数的栈,一个保存运算符的栈,当遇到数字就压入操作数栈,遇到运算符就和运算符栈的栈顶元素进行比较,如果比运算符栈顶元素的优先级高,就把当前的运算符压入栈,如果遇到优先级低的,就从运算符栈顶取出一个,从操作数栈顶取出两个,进行计算,计算完把结果压入操作数栈,继续比较.</p></li><li><p>栈在括号匹配中的应用<br>如果遇到更高级括号就压入,遇到右括号就匹配,如果不符合就报错.</p></li><li><p>实现浏览器的前进后退<br>还是两个栈实现,刚开始先把网页都压入栈1,如果就后退就出栈1压栈2,这样就可以实现前进功能了.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法之美 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-类和接口</title>
      <link href="/2020/08/14/java-kai-fa-jin-jie-bi-ji-lei-he-jie-kou/"/>
      <url>/2020/08/14/java-kai-fa-jin-jie-bi-ji-lei-he-jie-kou/</url>
      
        <content type="html"><![CDATA[<p>本文是Java 四大教科书之一的Effective Java的中文第三版的笔记整理</p><h1 id="第四章-类和接口"><a href="#第四章-类和接口" class="headerlink" title="第四章: 类和接口"></a>第四章: 类和接口</h1><h2 id="15-使类和成员的可访问性最小化"><a href="#15-使类和成员的可访问性最小化" class="headerlink" title="15.使类和成员的可访问性最小化"></a>15.使类和成员的可访问性最小化</h2><p>一个组件设计的好不好,很重要的一点就是他的内部数据和其他实现细节是否隐藏.<br>一个模块无需知道其他模块是怎么实现的,从而使得这些组件可以独立的开发,测试,优化,使用,理解和修改,支持并行开发.</p><p>尽可能多的使用private级别.</p><p>注意如果静态域中存在常量,需要大写全部字母同时使用下划线分割字符</p><p>数组永远是可以被修改的,所以final 数组域是没有意义的.<br>一个巧妙的实现方法是把数组变为私有的,并且添加一个公有方法来返回数组的一个拷贝.</p><h2 id="16-要在公有类而非公有域中使用访问方法"><a href="#16-要在公有类而非公有域中使用访问方法" class="headerlink" title="16.要在公有类而非公有域中使用访问方法"></a>16.要在公有类而非公有域中使用访问方法</h2><p>公有域尽可能少的暴露可变内部数据,多使用get/set方法</p><h2 id="17-使可变性最小化"><a href="#17-使可变性最小化" class="headerlink" title="17.使可变性最小化"></a>17.使可变性最小化</h2><p>对于一些不希望被改变的类,要遵循以下一些原则来实现不可变性:</p><ul><li>不要提供任何设值方法</li><li>保证类不会被扩展,声明这个类成为final</li><li>声明所有的域都是final</li><li>声明所有域都为私有</li></ul><p>不可变类大部分时候都是返回一个新的实例,而非修改原有实例.</p><p>不可变类的一个优势就是他是完全线程安全的,所以可以被自由的共享,永远也不需要进行保护性拷贝.</p><h2 id="18-复合优先于继承"><a href="#18-复合优先于继承" class="headerlink" title="18.复合优先于继承"></a>18.复合优先于继承</h2><p>对普通的类进行跨域包边界的继承是非常危险的,因为子类的实现实际上依托于超类的实现,当超类在后续更新中获取新方法或者发生变动的时候,子类将无法预知这种变化,即使他的代码完全没有发生任何变动.因此我们需要使用复合.</p><p>增加一个私有域,引用现有类的一个实例,这样的新类被称为包装类,也就是修饰者模式的一个实现.</p><p>什么时候使用继承?<br>只有当子类真正是超类的子类型的时候才适用,也就是确实存在is-a关系,B才应该扩展类A</p><h2 id="19-要么设计继承并且提供文档说明-要么禁止继承"><a href="#19-要么设计继承并且提供文档说明-要么禁止继承" class="headerlink" title="19.要么设计继承并且提供文档说明,要么禁止继承"></a>19.要么设计继承并且提供文档说明,要么禁止继承</h2><p>首先,该类必须有文档说明它可覆盖的方法的自用型,也就是精确描述覆盖每个方法所带来的影响.<br>以及必须在发布类之前先编写子类对类进行测试.<br>以及构造器决不能调用可被覆盖的方法,只能调用private,final和静态的方法,clone和serializable方法也是一样.</p><h2 id="20-接口优于抽象类"><a href="#20-接口优于抽象类" class="headerlink" title="20.接口优于抽象类"></a>20.接口优于抽象类</h2><p>接口可以对接不同的类型,而且易于拓展和实现,还可以使用骨架接口来定义结构,非常的清晰.</p><h2 id="21-为后代设计接口"><a href="#21-为后代设计接口" class="headerlink" title="21.为后代设计接口"></a>21.为后代设计接口</h2><p>缺省方法主要就是为了给接口添加方法</p><p>程序员应该以不少于3种方法实现一个接口,最起码不少于3种实现.</p><h2 id="22-接口只用于定义类型"><a href="#22-接口只用于定义类型" class="headerlink" title="22.接口只用于定义类型"></a>22.接口只用于定义类型</h2><p>当类实现接口时,接口就充当可以引用这个类的实例的类型,接口不应该用于导出常量.</p><h2 id="23-类层次优先于标签类"><a href="#23-类层次优先于标签类" class="headerlink" title="23. 类层次优先于标签类"></a>23. 类层次优先于标签类</h2><p>当程序员想要编写一个包含显式标签域的类时,应该考虑一下这个标签是否可以被取消或者修改为类层次来替代.</p><h2 id="24-静态成员类优先于非静态成员类"><a href="#24-静态成员类优先于非静态成员类" class="headerlink" title="24. 静态成员类优先于非静态成员类"></a>24. 静态成员类优先于非静态成员类</h2><p>嵌套类是指定义在另一个类内部的类,内部类存在的意义应该是只为他的外围类提供服务.<br>如果嵌套类可能被其他类进行调用,那它就应该被定义为顶层类.<br>一共有四种嵌套类.</p><h3 id="静态成员类"><a href="#静态成员类" class="headerlink" title="静态成员类:"></a>静态成员类:</h3><p>静态成员类是外围类的一个静态成员,可以访问外围类的所有成员,包括被声明为私有的.<br>只是一个辅助的方法,可以用于实现多重继承.<br>如果嵌套类的实例可以在它的外围类的实例之外独立存在,这个类就必须是静态成员类.</p><h3 id="非静态成员类"><a href="#非静态成员类" class="headerlink" title="非静态成员类"></a>非静态成员类</h3><p>一个常见用法是定义一个Adapter,允许外部类的实例被看作是另一个不相关类的实例,Map接口的实现往往使用非静态成员类来实现他的集合视图.或者实现迭代器.<br>匿名类最好少于10行,或者使用lambda表达式来进行代替,否则会影响可读性.</p><h2 id="25-限制源文件只包含单个顶级类"><a href="#25-限制源文件只包含单个顶级类" class="headerlink" title="25.限制源文件只包含单个顶级类."></a>25.限制源文件只包含单个顶级类.</h2><p>如此可以确保编译时一个类只会有一个定义,从而避免错误引用.</p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
            <tag> 类和接口 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-对于所有对象都通用的方法</title>
      <link href="/2020/08/07/java-kai-fa-jin-jie-bi-ji-dui-yu-suo-you-dui-xiang-du-tong-yong-de-fang-fa/"/>
      <url>/2020/08/07/java-kai-fa-jin-jie-bi-ji-dui-yu-suo-you-dui-xiang-du-tong-yong-de-fang-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章-对于所有对象都通用的方法"><a href="#第三章-对于所有对象都通用的方法" class="headerlink" title="第三章: 对于所有对象都通用的方法"></a>第三章: 对于所有对象都通用的方法</h1><h2 id="10-覆盖equals时请遵守通用约定"><a href="#10-覆盖equals时请遵守通用约定" class="headerlink" title="10.覆盖equals时请遵守通用约定"></a>10.覆盖equals时请遵守通用约定</h2><p>无需覆盖的情况:</p><ul><li>类的每个实例本质上都是唯一的, Object提供的equals对于这种需求是无需覆盖的</li><li>类没有必要提供逻辑相等的测试功能</li><li>类是私有的的时候需要确保他的equals方法永远不会被调用,可以采用类似单例的方法,直接覆盖然后抛出异常</li></ul><p>需要覆盖的时候:</p><ul><li>类具有自己的特有逻辑相等的概念,比如值相同,不关心是否指向同一个对象</li></ul><p>equals方法必须具备的等价关系:<br>自反性: 任何引用的equals方法必须为true<br>对称性: 任何两个引用的equals必须一致<br>传递性: x=y,y=z,则x=z<br>一致性: 多次调用需要返回相同的值<br>任何非null的引用调用equals方法必须返回false</p><p>如何实现在扩展值组件的同时保持equals的有效性?<br>遵循第18条复合优先于继承的原则,构造一个新的方法,调用原有的方法同时&amp;&amp;新的域的判定</p><p>覆盖equals总要覆盖hashCode<br>不要企图让equals过于智能<br>不要把equals声明中的Object对象替换为其他类型.(使其可以重载父类的equals方法)</p><h2 id="11-覆盖equals时总要覆盖hashCode"><a href="#11-覆盖equals时总要覆盖hashCode" class="headerlink" title="11. 覆盖equals时总要覆盖hashCode"></a>11. 覆盖equals时总要覆盖hashCode</h2><p>1,只要equals方法用到的信息没有被修改,那么hashCode方法都必须返回同一个值,即使多次调用<br>2,两个对象是equal的hashCode必须相同.<br>3,不同的两个对象的hashCode可能是相同的,但是要尽量避免这个问题<br>(使用AutoValue来生成是最优解)</p><h2 id="12-始终要覆盖toString"><a href="#12-始终要覆盖toString" class="headerlink" title="12. 始终要覆盖toString"></a>12. 始终要覆盖toString</h2><p>toString方法应该返回对象中所有值得关注的信息,或者一个摘要信息</p><h2 id="13-谨慎覆盖clone方法"><a href="#13-谨慎覆盖clone方法" class="headerlink" title="13. 谨慎覆盖clone方法"></a>13. 谨慎覆盖clone方法</h2><p>本质是不调用构造器从而实现创建新对象.</p><h2 id="14-实现Comparable接口"><a href="#14-实现Comparable接口" class="headerlink" title="14. 实现Comparable接口"></a>14. 实现Comparable接口</h2><p>对于一个已经实现的对象进行数组排序非常简单:<br>Arrays.sort(a);<br>对于值类型或者方排序的类型,实现该接口非常有必要.</p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring源码解析</title>
      <link href="/2020/08/01/spring-yuan-ma-jie-xi/"/>
      <url>/2020/08/01/spring-yuan-ma-jie-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="Spring源码分析"><a href="#Spring源码分析" class="headerlink" title="Spring源码分析"></a>Spring源码分析</h1><p>参考博客为: <a href="https://www.cnblogs.com/chenyanbin/p/11756034.html" target="_blank" rel="noopener">https://www.cnblogs.com/chenyanbin/p/11756034.html</a></p><h2 id="框架启动"><a href="#框架启动" class="headerlink" title="框架启动"></a>框架启动</h2><p>使用@SpringBootApplication注解来完成启动</p><p>分为两步,<br>第一步是初始化SpringApplication对象<br>第二步是调用run方法.</p><h3 id="框架初始化"><a href="#框架初始化" class="headerlink" title="框架初始化"></a>框架初始化</h3><p>1,配置资源加载器<br>2,配置primarySources<br>3,应用环境检测<br>4,配置系统初始化器<br>5,配置应用监听器<br>6,配置main方法所在类</p><h3 id="框架自动化装配步骤"><a href="#框架自动化装配步骤" class="headerlink" title="框架自动化装配步骤"></a>框架自动化装配步骤</h3><p>1,收集配置文件中的配置工厂类<br>2,加载组件工厂<br>3,注册组件内的bean</p><h2 id="Spring核心概念"><a href="#Spring核心概念" class="headerlink" title="Spring核心概念"></a>Spring核心概念</h2><p>IoC:对象创建的权力由程序反转给Spring框架<br>Aop:在不修改目标对象的源代码的情况下,增强IoC容器中Bean的功能<br>DI:依赖注入,在Spring框架负责创建Bean对象时,动态的将依赖对象注入到Bean组件中</p><p>IOC容器:<br>Spring中Bean工厂里面的Map存储结构,存储了Bean的实例</p><h2 id="Spring中的工厂"><a href="#Spring中的工厂" class="headerlink" title="Spring中的工厂"></a>Spring中的工厂</h2><p>ApplicationContext接口()</p><ul><li>实现了BeanFactory接口</li><li>实现ApplicationContext接口的工厂，可以获取到容器中具体的Bean对象</li><li>实现BeanFactory接口的工厂也可以获取到Bean对象<br>最终的底层BeanFactory都是DefaultListableBeanFactory<br>这两个接口的区别在于,BeanFactory采取延迟加载,第一次getBean的时候才会初始化Bean<br>ApplicationContext是加载完applicationContext.xml时,就创建具体的Bean对象的实例,除非描述为单例时才进行饿汉加载.</li></ul><h2 id="创建Web环境中的IoC容器"><a href="#创建Web环境中的IoC容器" class="headerlink" title="创建Web环境中的IoC容器"></a>创建Web环境中的IoC容器</h2><p>ApplicationContext接口常用实现类:</p><ul><li>ClassPathXmlApplicationContext: 类的根路径下加载配置文件</li><li>FileSystemXmlApplicationContext：它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。</li><li>AnnotationConfigApplicationContext：当我们使用注解配置容器对象时，需要使用此类来创建Spring容器。它用来读取注解。</li></ul><p>配置方法主要有两种:<br>Java应用中创建IoC容器：ApplicationContext context=new ClassPathXmlApplicationContext(xml路径);</p><p>Web应用中创建IoC容器：web.xml中配置ContextLoaderListener接口，并配置ContextConfigLocation参数,web容器启动之后加载web.xml，此时加载ContextLoaderListener监听器, ContextLoaderListener监听器会在web容器启动的时候，调用ContextInitialized()方法,调用initWebApplicationContext()方法，该方法负责创建Spring容器(DefaultListableBeanFactory)</p><h2 id="Web中的三类八种监听器"><a href="#Web中的三类八种监听器" class="headerlink" title="Web中的三类八种监听器"></a>Web中的三类八种监听器</h2><p>监听域对象的生命周期<br>ServletContextListener：</p><ul><li>创建：服务器启动</li><li>销毁：服务器正常关闭</li><li>spring ContextLoaderListener(服务器启动时负责加载spring配置文件)</li></ul><p>HttpSessionListener</p><ul><li>创建：第一次访问request.getHttpSession()</li><li>销毁：调用invalidate()；非法关闭；过期</li></ul><p>ServletRequestListener</p><ul><li>创建：每一次访问</li><li>销毁：相应结束</li></ul><p>监听域对象的属性：(添加、删除、替换)<br>ServletContextAttributeListener<br>HttpSessionAttributeListener<br>ServletRequestAttributeListener</p><p>监听HttpSession中JavaBean的改变：<br>HttpSessionBindingListener(HttpSession和JavaBean对象的绑定和解绑)<br>HttpSessionActivationListener(HttpSession的序列化，活化，纯化)</p><h2 id="具体加载过程"><a href="#具体加载过程" class="headerlink" title="具体加载过程"></a>具体加载过程</h2><p>1.web服务器(tomcat)启动会加载web.xml(启动ContextLoaderListener监听器)<br>2.创建web环境中的Spring容器<br>3.ContextLoader类中创建Spring容器并初始化容器中的Bean实例<br>4.configureAndRefreshWebApplicationContext方法中调用初始化Bean的refresh方法</p><h2 id="容器具体创建过程"><a href="#容器具体创建过程" class="headerlink" title="容器具体创建过程:"></a>容器具体创建过程:</h2><p><img src="https://s1.ax1x.com/2020/08/17/dZkw40.png" alt="dZkw40.png"></p><h2 id="Bean对象创建过程"><a href="#Bean对象创建过程" class="headerlink" title="Bean对象创建过程"></a>Bean对象创建过程</h2><p><img src="https://s1.ax1x.com/2020/08/17/dZkD3T.png" alt="dZkD3T.png"></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java-创建和销毁对象</title>
      <link href="/2020/07/26/java-kai-fa-jin-jie-bi-ji-chuang-jian-he-xiao-hui-dui-xiang/"/>
      <url>/2020/07/26/java-kai-fa-jin-jie-bi-ji-chuang-jian-he-xiao-hui-dui-xiang/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章-创建和销毁对象"><a href="#第二章-创建和销毁对象" class="headerlink" title="第二章:创建和销毁对象"></a>第二章:创建和销毁对象</h1><h2 id="1-用静态方法类替代构造器"><a href="#1-用静态方法类替代构造器" class="headerlink" title="1,用静态方法类替代构造器"></a>1,用静态方法类替代构造器</h2><p>为什么要使用静态方法而不是public构造器:<br>优点:<br>1,静态方法是有名字的,构造器只能根据参数来决定返回实例的类型.但是通过静态工厂方法就可以避开这个过程.<br>2,可以复用对象,不用每次都创建一个新的实例,而这个实例可以是提前构造好的,从而实现实例受控类.<br>3,返回原返回类型的任何子类的对象.<br>4,返回对象的类可以随着每次调用而发生变化,取决于参数值.<br>5,方法返回的对象的所属类,在编写包含该静态工厂方法的类时可以不存在</p><p>缺点:<br>1,类如果不包含公有的或者protected的构造器,就不能被子类化.<br>2,程序员可能无法发现他们</p><h2 id="2-遇到多个构造器参数时要考虑使用构造器"><a href="#2-遇到多个构造器参数时要考虑使用构造器" class="headerlink" title="2.遇到多个构造器参数时要考虑使用构造器"></a>2.遇到多个构造器参数时要考虑使用构造器</h2><p>因为静态工厂和构造器都有个共同的局限性,不能扩展到大量的可选参数.<br>一个替代的方法是用的javaBeans模式,先调用一个无参构造器来构造对象,然后使用setter方法来设置必要的参数.<br>但是这个办法也会有线程安全的问题,如果强行冻结的话就很笨拙.</p><p>实际生产过程中是用的建造者模式来处理,使用lombok的builder方法,先使得客户端利用所有必要的参数调用构造器,得到一个builder对象,再在builder对象上调用build方法来生成不可变的对象.<br>builder一般是它构建的类的静态成员类.<br>优点是流式编程,而且模拟了具名的可选参数.</p><p>一个大优点是便于扩展参数,对于之前的代码,可以保持原有的builder不变.</p><h2 id="3-用私有构造器或者枚举类型强化Singleton属性"><a href="#3-用私有构造器或者枚举类型强化Singleton属性" class="headerlink" title="3.用私有构造器或者枚举类型强化Singleton属性"></a>3.用私有构造器或者枚举类型强化Singleton属性</h2><p>首先要注意私有方法还是可以被反射给调用,所以要在构造器中添加二次创建就报异常的机制.<br>有两种常见方法:<br>1.public静态成员,final域<br><img src="https://s1.ax1x.com/2020/07/27/aPEKMQ.png" alt="aPEKMQ.png"></p><p>2,public获取方法,final成员<br><img src="https://s1.ax1x.com/2020/07/27/aPEMrj.png" alt="aPEMrj.png"></p><p>方法2有3个好处:<br>1,便于修改,保持api不变.<br>2,简单,可以返回一个泛型Singleton工厂<br>3,可以通过方法引用来提供实例.</p><p>注意还要声明所有实例域都是transient的,并且提供一个readResolve方法.</p><p>3,声明一个包含单个元素的枚举类型<br><img src="https://s1.ax1x.com/2020/07/27/aPEeG8.png" alt="aPEeG8.png"><br>这是最好的方法.</p><h2 id="4-通过私有构造器强化不可实例化的能力"><a href="#4-通过私有构造器强化不可实例化的能力" class="headerlink" title="4.通过私有构造器强化不可实例化的能力"></a>4.通过私有构造器强化不可实例化的能力</h2><p>对于一些只包含静态方法的类,实例化是毫无意义的,但是如果不包含构造器,系统会提供一个默认的无参构造器.所以需要给一个私有的构造器,这样就可以完全避免被实例化了.<br>私有构造器可以直接抛出一个异常,以防在内部被错误调用.<br>这样的一个问题就是该类不可被子类化,因为无法调用超类的构造器.</p><h2 id="5-优先考虑使用依赖注入来引用资源"><a href="#5-优先考虑使用依赖注入来引用资源" class="headerlink" title="5.优先考虑使用依赖注入来引用资源"></a>5.优先考虑使用依赖注入来引用资源</h2><p>比如使用spring这种方法,定义依赖并且把依赖注入,从而进行使用.</p><h2 id="6-避免创建不必要的对象"><a href="#6-避免创建不必要的对象" class="headerlink" title="6.避免创建不必要的对象"></a>6.避免创建不必要的对象</h2><p>多使用静态工厂方法避免使用构造器<br>比如创建string的时候,避免调用构造器,而是直接赋值.<br>以及使用基本变量类型的时候,尽可能避免自动装箱.<br>或者使用正则表达式的时候,先显式定义再进行调用.</p><h2 id="7-消除过期的对象引用"><a href="#7-消除过期的对象引用" class="headerlink" title="7.消除过期的对象引用"></a>7.消除过期的对象引用</h2><p>过期引用: 永远不会再被解除的引用<br>往往发生在自己管理内存的类上</p><h2 id="8-避免使用终结方法和清除方法"><a href="#8-避免使用终结方法和清除方法" class="headerlink" title="8.避免使用终结方法和清除方法"></a>8.避免使用终结方法和清除方法</h2><p>能不用就不用.<br>记得每次使用完资源都close一下;</p><h2 id="9-try-with-resources-优先于try-finally"><a href="#9-try-with-resources-优先于try-finally" class="headerlink" title="9.try-with-resources 优先于try-finally"></a>9.try-with-resources 优先于try-finally</h2><p>实际使用就是在try的括号里打开资源,并且不需要使用finally这个方法来关闭资源了,从而避免异常覆盖.</p><p><img src="https://s1.ax1x.com/2020/07/27/aPEQqs.png" alt="aPEQqs.png"></p>]]></content>
      
      
      <categories>
          
          <category> Effective Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Effective Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络</title>
      <link href="/2020/07/03/ji-suan-ji-wang-luo/"/>
      <url>/2020/07/03/ji-suan-ji-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h1><h2 id="1-http属于哪一层？OSI和5层模型里都在第几层？说下TCP和UDP？在什么层？介绍一下TCP和UDP-三次握手四次挥手"><a href="#1-http属于哪一层？OSI和5层模型里都在第几层？说下TCP和UDP？在什么层？介绍一下TCP和UDP-三次握手四次挥手" class="headerlink" title="1.http属于哪一层？OSI和5层模型里都在第几层？说下TCP和UDP？在什么层？介绍一下TCP和UDP,三次握手四次挥手?"></a>1.http属于哪一层？OSI和5层模型里都在第几层？说下TCP和UDP？在什么层？介绍一下TCP和UDP,三次握手四次挥手?</h2><p>Http属于应用层</p><p>TCP和UDP属于传输层.</p><p>TCP（Transmission Control Protocol，传输控制协议）是面向连接的协议，也就是说，在收发数据前，必须和对方建立可靠的连接。 一个TCP连接必须要经过三次“对话”才能建立起来，其中的过程非常复杂， 只简单的描述下这三次对话的简单过程：</p><p>1）主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；</p><p>2）主机B向主机A发送同意连接和要求同步 （同步就是两台主机一个在发送，一个在接收，协调工作）的数据包 ：“可以，你什么时候发？”，这是第二次对话；</p><p>3）主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”， 这是第三次对话。</p><p>三次“对话”的目的是使数据包的发送和接收同步， 经过三次“对话”之后，主机A才向主机B正式发送数据。</p><p>具体过程:<br>第一次握手：主机A通过向主机B 发送一个含有同步序列号的标志位的数据段给主机B，向主机B 请求建立连接，通过这个数据段， 主机A告诉主机B 两件事：我想要和你通信；你可以用哪个序列号作为起始数据段来回应我。</p><p>第二次握手：主机B 收到主机A的请求后，用一个带有确认应答（ACK）和同步序列号（SYN）标志位的数据段响应主机A，也告诉主机A两件事：我已经收到你的请求了，你可以传输数据了；你要用那个序列号作为起始数据段来回应我</p><p>第三次握手：主机A收到这个数据段后，再发送一个确认应答，确认已收到主机B 的数据段：”我已收到回复，我现在要开始传输实际数据了，这样3次握手就完成了，主机A和主机B 就可以传输数据了。</p><p>为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤<br>如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认</p><p>四次挥手:<br>第一次： 当主机A完成数据传输后,将控制位FIN置1，提出停止TCP连接的请求 ；<br>第二次： 主机B收到FIN后对其作出响应，确认这一方向上的TCP连接将关闭,将ACK置1；<br>第三次： 由B 端再提出反方向的关闭请求,将FIN置1 ；<br>第四次： 主机A对主机B的请求进行确认，将ACK置1，双方向的关闭结束.。</p><h2 id="2-如果传输失败了怎么办"><a href="#2-如果传输失败了怎么办" class="headerlink" title="2.如果传输失败了怎么办?"></a>2.如果传输失败了怎么办?</h2><p>如果此时ACK在网络中丢失，过了超时计时器后，那么Server端会重新发送SYN+ACK包，重传次数根据/proc/sys/net/ipv4/tcp_synack_retries来指定，默认是5次。如果重传指定次数到了后，仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包响应，方能感知到Server的错误。</p><h2 id="3-延迟回应是什么"><a href="#3-延迟回应是什么" class="headerlink" title="3.延迟回应是什么"></a>3.延迟回应是什么</h2><p>TCP delayed ack<br>接收方在收到数据后，并不会立即回复ACK, 而是延迟一定时间 或者 达到2x最大段数据长度为止 (不同操作系统实现并不一样)<br>这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。<br>如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。</p><h2 id="4-http网络请求了解吗"><a href="#4-http网络请求了解吗" class="headerlink" title="4.http网络请求了解吗?"></a>4.http网络请求了解吗?</h2><p>影响一个 HTTP 网络请求的因素主要有两个：带宽和延迟。</p><p>带宽：如果说我们还停留在拨号上网的阶段，带宽可能会成为一个比较严重影响请求的问题，但是现在网络基础建设已经使得带宽得到极大的提升，我们不再会担心由带宽而影响网速，那么就只剩下延迟了。</p><p>延迟：<br>浏览器阻塞（HOL blocking）：浏览器会因为一些原因阻塞请求。浏览器对于同一个域名，同时只能有 4 个连接（这个根据浏览器内核不同可能会有所差异），超过浏览器最大连接数限制，后续请求就会被阻塞。</p><p>DNS 查询（DNS Lookup）：浏览器需要知道目标服务器的 IP 才能建立连接。将域名解析为 IP 的这个系统就是 DNS。这个通常可以利用DNS缓存结果来达到减少这个时间的目的。</p><p>建立连接（Initial connection）：HTTP 是基于 TCP 协议的，浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。</p><h2 id="5-http-1-0和1-1之间有什么主要的区别-和2-0呢"><a href="#5-http-1-0和1-1之间有什么主要的区别-和2-0呢" class="headerlink" title="5.http 1.0和1.1之间有什么主要的区别?和2.0呢"></a>5.http 1.0和1.1之间有什么主要的区别?和2.0呢</h2><p>和1.1的区别:<br>缓存处理: 在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。<br>带宽优化及网络连接的使用: HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。<br>错误通知的管理: 在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。<br>Host头处理: 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。<br>长连接: HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。</p><p>和2.0的区别:<br>新的二进制格式（Binary Format）:HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。<br>多路复用（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。<br>header压缩，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。<br>HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；</p><h2 id="6-http报文由哪几部分构成"><a href="#6-http报文由哪几部分构成" class="headerlink" title="6.http报文由哪几部分构成?"></a>6.http报文由哪几部分构成?</h2><p>首先分为请求报文和响应报文;<br>两种报文都由3部分构成:开始行,首部行,实体主体<br>请求报文的开始行: 方法、[空格]、URL、[空格]、HTTP版本<br>响应报文的开始行: HTTP 版本、[空格]、状态码<br>首部行:<br>HTTP首部字段分为4种：通用首部字段、请求首部字段、响应首部字段、实体首部字段<br><img src="https://s1.ax1x.com/2020/08/17/dZEqht.png" alt="dZEqht.png"></p><p>实体主体,也就是payload:一般是json文件</p><h2 id="7-里面有一个connect关键词-这个应该填什么"><a href="#7-里面有一个connect关键词-这个应该填什么" class="headerlink" title="7.里面有一个connect关键词,这个应该填什么?"></a>7.里面有一个connect关键词,这个应该填什么?</h2><p>keep-alive,建立长连接/或者close,关闭连接.<br>同时补充其他几个比较常见的:<br>请求首部字段:<br>User-Agent                         HTTP 客户端程序的信息<br>Host                               请求资源所在服务器<br>Accept                         用户代理可处理的媒体类型<br>Accept-Charset                  优先的字符集<br>Accept-Encoding               优先的内容编码<br>Accept-Language               优先的语言（自然语言）<br>Authorization                  Web认证信息,比如证书值</p><p>响应首部字段:<br>Location                        令客户端重定向至指定URI<br>Proxy-Authenticate      代理服务器对客户端的认证信息<br>Retry-After                   对再次发起请求的时机要求<br>Server HTTP                  服务器的安装信息</p><p>实体首部字段:<br>Allow                       资源可支持的HTTP方法<br>Content-Encoding            实体主体适用的编码方式<br>Content-Language            实体主体的自然语言<br>Content-Length              实体主体的大小（单位：字节）<br>Content-Location            替代对应资源的URI<br>Content-MD5                 实体主体的报文摘要<br>Content-Range               实体主体的位置范围<br>Content-Type                实体主体的媒体类型<br>Expires                     实体主体过期的日期时间<br>Last-Modified               资源的最后修改日期时间</p><p>还有一些比如cookie啊之类的非标准字段.</p><h2 id="8-网络拥堵了解吗-堵塞了解吗-流量控制是怎么一回事"><a href="#8-网络拥堵了解吗-堵塞了解吗-流量控制是怎么一回事" class="headerlink" title="8.网络拥堵了解吗?堵塞了解吗?流量控制是怎么一回事?"></a>8.网络拥堵了解吗?堵塞了解吗?流量控制是怎么一回事?</h2><p>流量控制:如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止分组丢失，它是构成TCP可靠性的一方面。</p><p>如何实现:由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。</p><p>流量控制中的死锁:<br>当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。<br>为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。</p><p>拥塞控制:<br>拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；<br>先假设:<br>1、数据是单方向传递，另一个窗口只发送确认；<br>2、接收方的缓存足够大，因此发送方的大小的大小由网络的拥塞程度来决定。<br>常用的方法就是：<br>（ 1 ）慢开始、拥塞避免<br>发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。<br>慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。<br>为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：当cwnd &lt; ssthresh时，使用慢开始算法。当cwnd&gt;ssthresh时，改用拥塞避免算法。当cwnd=ssthresh时，慢开始与拥塞避免算法任意.<br>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p><p>无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。<br>（ 2 ）快重传、快恢复。<br>快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期<br>当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法<br>考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。</p><h2 id="9-http和https"><a href="#9-http和https" class="headerlink" title="9.http和https"></a>9.http和https</h2><p>HTTPS和HTTP的区别主要如下：</p><p>　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。</p><p>　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。</p><p>　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。</p><p>　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全</p><p>客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。</p><p>　　（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。</p><p>　　（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。</p><p>　　（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。</p><p>　　（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。</p><p>　　（5）Web服务器利用自己的私钥解密出会话密钥。</p><p>　　（6）Web服务器利用会话密钥加密与客户端之间的通信。</p><h2 id="10-非对称加密的常见算法"><a href="#10-非对称加密的常见算法" class="headerlink" title="10.非对称加密的常见算法"></a>10.非对称加密的常见算法</h2><p>非对称加密,指需要两个密钥,一个公钥,一个私钥;如果用公钥加密,只有用私钥才能解密;反之亦然<br>这样就不需要像对称密码一样传输密钥了.https属于典型的非对称加密.</p><p>常见的签名加密算法:<br><a href="https://juejin.im/post/5b48b0d7e51d4519962ea383#heading-22" target="_blank" rel="noopener">https://juejin.im/post/5b48b0d7e51d4519962ea383#heading-22</a></p><h2 id="11-介绍JWT-JSON-Web-Token"><a href="#11-介绍JWT-JSON-Web-Token" class="headerlink" title="11.介绍JWT(JSON Web Token)"></a>11.介绍JWT(JSON Web Token)</h2><p>举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？</p><p>一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。</p><p>另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。</p><p>实现原理:<br>JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。</p><p>JWT的缺点:<br>JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。</p><h2 id="12-HTTP服务器的通信原理？NIO？Netty？"><a href="#12-HTTP服务器的通信原理？NIO？Netty？" class="headerlink" title="12.HTTP服务器的通信原理？NIO？Netty？"></a>12.HTTP服务器的通信原理？NIO？Netty？</h2><p>1、创建一个ServerSocket，监听并绑定一个端口<br>2、一系列客户端来请求这个端口<br>3、服务器使用Accept，获得一个来自客户端的Socket连接对象<br>4、启动一个新线程处理连接<br>    4.1、读Socket，得到字节流<br>    4.2、解码协议，得到Http请求对象<br>    4.3、处理Http请求，得到一个结果，封装成一个HttpResponse对象<br>    4.4、编码协议，将结果序列化字节流写Socket，将字节流发给客户端<br>5、继续循环步骤3HTTP服务器之所以称为HTTP服务器，是因为编码解码协议是HTTP协议，如果协议是Redis协议，那它就成了Redis服务器，如果协议是WebSocket，那它就成了WebSocket服务器，等等。<br>使用Netty你就可以定制编解码协议，实现自己的特定协议的服务器。</p><p>那么NIO是怎么做到非阻塞的呢。它用的是事件机制。它可以用一个线程把Accept，读写操作，请求处理的逻辑全干了。如果什么事都没得做，它也不会死循环，它会将线程休眠起来，直到下一个事件来了再继续干活，这样的一个线程称之为NIO线程。</p><p>有三种模式：N<br>1,单线程版本一个NIO线程+一个accept线程：<br><img src="https://s1.ax1x.com/2020/08/17/dZmCAH.png" alt="dZmCAH.png"></p><p>2,多线程模型<br><img src="https://s1.ax1x.com/2020/08/17/dZVEcT.png" alt="dZVEcT.png"></p><p>3,主从模型<br><img src="https://s1.ax1x.com/2020/08/17/dZmi4A.png" alt="dZmi4A.png"></p><p>Netty是建立在NIO基础之上，Netty在NIO之上又提供了更高层次的抽象。在Netty里面，Accept连接可以使用单独的线程池去处理，读写操作又是另外的线程池来处理。</p><h2 id="13-打开一个网站的全过程"><a href="#13-打开一个网站的全过程" class="headerlink" title="13.打开一个网站的全过程"></a>13.打开一个网站的全过程</h2><p>主要参考文章:<a href="https://www.cnblogs.com/dengzz/p/5544122.html" target="_blank" rel="noopener">https://www.cnblogs.com/dengzz/p/5544122.html</a><br>DNS解析过程:<br>浏览器首先搜索浏览器自身缓存的DNS记录,<br>如果浏览器缓存中没有找到需要的记录或记录已经过期，则搜索hosts文件和操作系统缓存。<br>如果在hosts文件和操作系统缓存中没有找到需要的记录或记录已经过期，则向域名解析服务器发送解析请求。<br>如果域名解析服务器也没有该域名的记录，则开始递归+迭代解析。<br>根域服务器-com域服务器-google.com域服务器</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> http </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ</title>
      <link href="/2020/06/13/rocketmq/"/>
      <url>/2020/06/13/rocketmq/</url>
      
        <content type="html"><![CDATA[<h1 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><h2 id="1-整体架构"><a href="#1-整体架构" class="headerlink" title="1. 整体架构"></a>1. 整体架构</h2><p>主要分为生产者,消费者,主题,消息,消息队列,标记,broker经纪人,名称服务器,offset.</p><p>生产者: 将消息发送到brokers中.RMQ提供了同步,异步,单向,三种消息发送模式.<br>生产组: 生产者的一个集合,原始生产者崩溃,另一个生产者替代<br>    如何选择消息队列?<br>    首先，要澄清一个误会。这里的选择消息队列发送消息，并不是真的往某个队列发送消息。RocketMQ的消息只存在一个叫CommitLog的逻辑文件中，对应于磁盘上的多个文件。消息队列的概念，仅仅是消息消费的时候才会用到。因为所有消息都是存放在一个CommitLog中的，这意味着不同的Topic的消息是先来后到的顺序插入到CommitLog中。如果Consumer要消费某个Topic下的消息，去CommitLog里面去一个个查询势必非常缓慢，是完全不可取的。为了解决某Topic下消息查询的问题（当然不仅仅是解决这一个问题，还包括消费进度等），RocketMQ在原有的CommitLog的基础之上，为每一个Topic新建了一个ConsumerQueue的文件（同样对应于磁盘上的多个文件，也就是我们口中的消息队列），它保存了某个topic下的消息在CommitLog里偏移位置。这样消费某个Topic的消息，就可以直接读取该ConsumerQueue文件，拿到消息在CommitLog中的偏移位置，然后去CommitLog里面寻找消息实体即可。</p><p>消费者: 从brokers中拉取消息,并且将消息传递给业务系统.<br>有两种消费者:</p><pre><code>拉取DefaultMQPullConsumer: 主动从brokers拉取消息.读取中的大部分功能由使用者自主控制.推送DefaultMQPushConsumer: 系统控制读取操作,收到消息后自动调用传入的处理方法.  需要传入三个参数,一是这个Consumer的GroupName，二是NameServer的地址和端口号，三是Topic的名称+要的tag。</code></pre><p>同时有两种消费模式:</p><pre><code>Clustering(集群模式):在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。  RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。  所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。  但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。Broadcasting广播模式:同一个ConsumerGroup里的每个Consumer都能消费到所订阅Topic的全部消息，也就是一个消息会被多次分发，被多个Consumer消费。在实现上，其中一个不同就是在consumer分配queue的时候，会所有consumer都分到所有的queue。</code></pre><p>消息类型:</p><pre><code>无序消息:生成和消费消息是顺序未知有序消息: 取决于topic到底有几个queue- 全局有序: 只设定一个queue,但是慢- 局部有序: 多个queue,按照orderid进行消息投递和消费.延时消息: 在msg中设定延时即可</code></pre><p>Topic: 是消息的逻辑分类,如下图可以展示topic,broker,queue三者之间的关系</p><p><img src="https://s1.ax1x.com/2020/08/17/dZEIne.png" alt="dZEIne.png"><br>实际上保存的消息不是真正的消息数据,而是指向commit log的消息索引.<br>Topic创建的时候可以用集群模式去创建（这样集群里面每个broker的queue的数量相同），也可以用单个broker模式去创建（这样每个broker的queue数量可以不一致）。<br>使用命令行创建topic, mqadmin通知broker创建topic和对应的queue信息,broker转发通知namesrv保存topic和broker的原信息，同时在本地持久化一份topic配置。<br>不同的topic，message queue都是写到相同的CommitLog 文件，也就是说CommitLog完全的顺序写</p><p>offset:RocketMQ在存储消息时会为每个Topic下的每个Queue生成一个消息的索引文件，每个Queue都对应一个Offset记录当前Queue中消息条数。</p><p>broker:真正存储消息的地方,有很多个queue.<br>每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。<br>由于消息分布在各个Broker上，一旦某个Broker宕机，则该Broker上的消息读写都会受到影响。<br>所以RocketMQ提供了Master/Slave的结构，Salve定时从Master同步数据，如果Master宕机，则Slave提供消费服务，但是不能写入消息，此过程对应用透明，由RocketMQ内部解决。<br>消费者得到Master宕机通知后，转向Slave消费，但是Slave不能保证Master的消息100%都同步过来了，因此会有少量的消息丢失。但是消息最终不会丢的，一旦Master恢复，未同步过去的消息会被消费掉。</p><ul><li>都有哪些组件?</li></ul><p>主要分为生产者,消费者,主题,消息,消息队列,标记,broker经纪人,名称服务器,offset.</p><ul><li><p>有哪几种消费者?<br>拉取,推送.</p></li><li><p>是怎么消费的?<br>拉取,推送,取决于自己的设定.</p></li><li><p>和Kafka最大的区别是什么?<br>存储形式: Kafka采用partition，每个topic的每个partition对应一个文件。顺序写入，定时刷盘。但一旦单个broker的partition过多，则顺序写将退化为随机写，Page Cache脏页过多，频繁触发缺页中断，性能大幅下降; RocketMQ采用CommitLog+ConsumeQueue，单个broker所有topic在CommitLog中顺序写，Page Cache只需保持最新的页面即可。同时每个topic下的每个queue都有一个对应的ConsumeQueue文件作为索引。ConsumeQueue占用Page Cache极少，刷盘影响较小。</p></li></ul><pre><code>介绍一下Kafka的刷盘策略首先我们先来了解一下kafka日志的结构：每个topic的partition对应一个broker上一个目录，目录中的文件以日志的大小（log.segment.bytes）和时间（log.roll.hours）来roll。我们看到的kafka v0.10.2的日志文件包括三个部分，分别是xxxxxxxxxxxxxxxxxxxx.index、xxxxxxxxxxxxxxxxxxxx.log和xxxxxxxxxxxxxxxxxxxx.timeindex，其中xxxxxxxxxxxxxxxxxxxx代表的是offset，20位，从0开始。Kafka没有采用uuid的形式，为每个message分配一个message.id，而是通过offset来标记message，offset并不是消息在文件中的物理编号，而是一个逻辑编号，通过追加方式，每次加1。那通过offset如何查找消息的呢？</code></pre><p>刷盘策略:<br>同步刷盘是在每条消息都确认落盘了之后才向发送者返回响应；而异步刷盘中，只要消息保存到Broker的内存就向发送者返回响应，Broker会有专门的线程对内存中的消息进行批量存储。</p><p>所以异步刷盘的策略下，当机器突然掉电时，Broker内存中的消息因无法刷到磁盘导致丢失;RMQ支持同步和异步刷盘,但是KAFKA只支持异步.</p><p>其次是支持的队列数: Kafka单机超过64个队列/分区，消息发送性能降低严重；RocketMQ 单机支持最高5万个队列，性能稳定</p><p>消息顺序性: Kafka 某些配置下，支持消息顺序，但是一台Broker宕机后，就会产生消息乱序；RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序；</p><p>消息查询机制: Kafka不支持消息查询,RocketMQ支持根据Message Id查询消息，也支持根据消息内容查询消息.<br>具体的原理是什么?</p><p>如何刷盘/存磁盘的?</p><ul><li>异步刷盘: Broker的一种持久化策略，消息写入pagecache后，直接返回。由异步线程负责将pagecache写入硬盘。</li><li>同步刷盘:Broker的一种持久化策略，消息写入pagecache后，由同步线程将pagecache写入硬盘后，再返回。</li></ul><p>是用在哪和哪之间通讯?</p><p>用于发送订单和处理订单,用于数据库和redis之间</p><h3 id="补充一个分布式事务"><a href="#补充一个分布式事务" class="headerlink" title="补充一个分布式事务"></a>补充一个分布式事务</h3><p>先介绍事务:<br>事务的ACID是通过InnoDB日志和锁来保证。事务的隔离性是通过数据库锁的机制实现的，持久性通过redo log（重做日志）来实现，原子性和一致性通过Undo log来实现。<br>UndoLog的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。<br>和Undo Log相反，RedoLog记录的是新数据的备份。在事务提交前，只要将RedoLog持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。</p><p>核心是记录log,不记录数据.</p><p>分布式事务意思就是多个服务同时管理事务,使用事务队列RocketMQ来进行管理.</p><p>在RocketMQ中实现了分布式事务，实际上其实是对本地消息表的一个封装，将本地消息表移动到了MQ内部，</p><p>基本流程如下:<br>第一阶段Prepared消息，会拿到消息的地址。<br>第二阶段执行本地事务。<br>第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。消息接受者就能使用这个消息。<br>如果确认消息失败，在RocketMq Broker中提供了定时扫描没有更新状态的消息，如果有消息没有得到确认，会向消息发送者发送消息，来判断是否提交，在rocketmq中是以listener的形式给发送者，用来处理。</p><p>如果消费超时，则需要一直重试，消息接收端需要保证幂等。如果消息消费失败，这个就需要人工进行处理，因为这个概率较低，如果为了这种小概率时间而设计这个复杂的流程反而得不偿失</p><h2 id="2-讲一下RocketMQ-Kafka的选型考虑"><a href="#2-讲一下RocketMQ-Kafka的选型考虑" class="headerlink" title="2. 讲一下RocketMQ/Kafka的选型考虑"></a>2. 讲一下RocketMQ/Kafka的选型考虑</h2><p>使用原因：异步，解藕，削峰。<br>RMQ是根据Kafak的架构原型设计出来的,有很多地方相似.但是RMQ的吞吐量是10wTPS,Kafka是百万.<br>K使用zookeeper作为nameserver，nameserver就是帮助producer和consumer路由到Broker</p><p>K是每个Partition一个文件,R是所有topic都存在一个文件.</p><p>消息写入:<br>1） 顺序写入<br>2） 利用OS提供的pageCache来实现mmap（内存映射文件），java中是通过NOI提供的MappedByteBuffer类具体实现的</p><p>消息读取:</p><p>两者都采用了一个技术叫做零拷贝，这样就不用先将磁盘内容从内核空间（磁盘的）拷贝到用户空间，再从用户空间拷贝到内核空间（socket的），而是直接从内核转到内核，java里面是通过NIO提供的FileChannel实现。</p><p>零拷贝:<br>磁盘数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer(socket buffer)，无需 CPU 拷贝,这一步叫send file.<br>正常拷贝需要拷贝4次:<br>1、第一次：将磁盘文件，读取到操作系统内核缓冲区；<br>2、第二次：将内核缓冲区的数据，copy到application应用程序的buffer；<br>3、第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)；<br>4、第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。</p><p><img src="https://pic2.zhimg.com/80/v2-07f829c7a070c3444b1d8c99d4afd1bb_1440w.jpg" alt></p><p>但是零拷贝就是把中间过程省略,变成共享内存的方式,减少拷贝次数.具体是使用mmap文件映射机制,Memory Mapped Files，<br>其作用就是：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。<br>在进程 的非堆内存开辟一块内存空间，和OS内核空间的一块内存进行映射，<br>kafka数据写入、是写入这块内存空间，但实际这块内存和OS内核内存有映射，也就是相当于写在内核内存空间了，且这块内核空间、内核直接能够访问到，直接落入磁盘。这里，我们需要清楚的是：内核缓冲区的数据，flush就能完成落盘。</p><p>Kafka为什么快:<br>1、partition顺序读写，充分利用磁盘特性，这是基础；<br>2、Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入；<br>3、Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。<br>4、kafka采用异步发送的机制，当发送一条消息时，消息并没有发送到broker而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送。<br>此时减少了网络io，从而提高了消息发送的性能，但是如果消息发送者宕机，会导致消息丢失，业务出错，所以理论上kafka利用此机制提高了io性能却降低了可靠性。  </p><p>Kafka的消息存储：<br><a href="https://www.jianshu.com/p/7da49ff4f565" target="_blank" rel="noopener">https://www.jianshu.com/p/7da49ff4f565</a></p><p>如何保证消息的顺序性：<br><a href="https://www.jianshu.com/p/8a5630e2c317" target="_blank" rel="noopener">https://www.jianshu.com/p/8a5630e2c317</a></p><p>Kafka的手段是：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL</title>
      <link href="/2020/05/19/mysql/"/>
      <url>/2020/05/19/mysql/</url>
      
        <content type="html"><![CDATA[<h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><h2 id="1-怎么加快检索-如果一个读操作慢了-怎么办-写操作慢了-怎么办-or-并发度较高的时候，数据库压力较大，怎么解决"><a href="#1-怎么加快检索-如果一个读操作慢了-怎么办-写操作慢了-怎么办-or-并发度较高的时候，数据库压力较大，怎么解决" class="headerlink" title="1.怎么加快检索?如果一个读操作慢了,怎么办?写操作慢了,怎么办? or 并发度较高的时候，数据库压力较大，怎么解决?"></a>1.怎么加快检索?如果一个读操作慢了,怎么办?写操作慢了,怎么办? or 并发度较高的时候，数据库压力较大，怎么解决?</h2><p>1,合理增加索引<br>表索引可以加快对表中数据的检索速度,但是会降低更新速度.如果是读多写少,可以适当加索引;最基础的手段.</p><p>2,对数据进行截转<br>对业务进行梳理,将当前时间间隔之外的数据进行截转,截转到历史数据库中;当需要历史数据时可以到历史数据库中查询<br>推荐的方法是根据业务量最小的时间自动截转</p><p>要注意外键,以及生产库和历史库的关系,以免历史库需要调用生产库.</p><p>3,加缓存<br>缓存的操作顺序很重要,一般是先删缓存,再使用队列保证更新和查询操作的顺序,以免破坏数据一致性.</p><p>4,生成大宽表<br>尽量避免多表联合查询,需要考虑是在业务流程中生成,或者异步化任务来生成.</p><p>5,NoSQL数据库<br>不强调表的关系,查询非常的快.</p><p>6,读写分离<br>将数据拆分为俩操作,写入到副本中,从主库中读取,主机和从机定期进行同步.<br>可以使用binlog进行操作监听和复制,复原.</p><p>7,数据库拆分<br>将具体的业务拆分成到不同的库中</p><p>8,表的水平拆分和垂直拆分<br>分库分表来进行优化查询,水平拆分就是比如a开头和b开头,垂直拆分就是按照经常被查询到的列进行拆分.</p><h2 id="2-InnoDB是基于什么算法进行检索的"><a href="#2-InnoDB是基于什么算法进行检索的" class="headerlink" title="2.InnoDB是基于什么算法进行检索的?"></a>2.InnoDB是基于什么算法进行检索的?</h2><p>B+树实现.</p><p>索引:<br>每个InnoDB的表都拥有一个索引，称之为聚簇索引，此索引中存储着行记录，一般来说，聚簇索引是根据主键生成的。为了能够获得高性能的查询、插入和其他数据库操作，理解InnoDB聚簇索引是很有必要的。</p><p>聚簇索引按照如下规则创建：</p><p>当定义了主键后，InnoDB会利用主键来生成其聚簇索引；<br>如果没有主键，InnoDB会选择一个非空的唯一索引来创建聚簇索引；<br>如果这也没有，InnoDB会隐式的创建一个自增的列来作为聚簇索引。</p><p>除了聚簇索引之外的索引都可以称之为辅助索引，与聚簇索引的区别在于辅助索引的叶子节点中存放的是主键的键值。一张表可以存在多个辅助索引，但是只能有一个聚簇索引，通过辅助索引来查找对应的行记录的话，需要进行两步，第一步通过辅助索引来确定对应的主键，第二步通过相应的主键值在聚簇索引中查询到对应的行记录，也就是进行两次B+树搜索。相反通过辅助索引来查询主键的话，遍历一次辅助索引就可以确定主键了，也就是所谓的索引覆盖，不用回表（查询聚簇索引）。</p><p>创建辅助索引，可以创建单列的索引，也就是用一个字段来创建索引，也可以用多个字段来创建副主索引称为联合索引，创建联合索引后，B+树的节点存储的键值数量不是1个，而是多个,如下:<br><img src="https://pic4.zhimg.com/80/v2-5257a9af1e46594f78629e2dd472703b_1440w.jpg" alt></p><p>联合索引的B+树和单键辅助索引的B+树是一样的，键值都是排序的，通过叶子节点可以逻辑顺序的读出所有的数据，比如上图所存储的数据时，按照(a,b)这种形式(1,1),(1,2),(2,1),(2,4),(3,1),(3,2)进行存放，这样有个好处存放的数据时排了序的，当进行order by对某个字段进行排序时，可以减少复杂度，加速进行查询；<br>当用select <em> from table where a=? and ?可以使用索引(a,b)来加速查询，但是在查询时有一个原则，sql的where条件的顺序必须和二级索引一致，而且还遵循索引最左原则，select </em> from table where b=?则无法利用(a,b)索引来加速查询。<br>辅助索引还有一个概念便是索引覆盖，索引覆盖的一个好处便是辅助索引不包含行记录，因此其大小远远小于聚簇索引，利用辅助索引进行查询可以减少大量的IO操作。</p><p>索引有如下有点：减少服务器扫描的数据量、避免排序和临时表、将随机I/O变为顺序I/O。<br>主键最好定义为整形,避免索引分裂.</p><h2 id="3-sql语句按照什么顺序执行"><a href="#3-sql语句按照什么顺序执行" class="headerlink" title="3.sql语句按照什么顺序执行"></a>3.sql语句按照什么顺序执行</h2><p>(1) from：对左表left-table和右表right-table执行笛卡尔积(a*b)，形成虚拟表VT1;</p><p>(2) on: 对虚拟表VT1进行on条件进行筛选，只有符合条件的记录才会插入到虚拟表VT2中;</p><p>(3) join: 指定out join会将未匹配行添加到VT2产生VT3,若有多张表，则会重复(1)~(3);</p><p>(4) where: 对VT3进行条件过滤，形成VT4, where条件是从左向右执行的;</p><p>(5) group by: 对VT4进行分组操作得到VT5;</p><p>(6) cube | rollup: 对VT5进行cube | rollup操作得到VT6;</p><p>(7) having: 对VT6进行过滤得到VT7;</p><p>(8) select: 执行选择操作得到VT8，本人看来VT7和VT8应该是一样的;</p><p>(9) distinct: 对VT8进行去重，得到VT9;</p><p>(10) order by: 对VT9进行排序，得到VT10;</p><p>(11) limit: 对记录进行截取，得到VT11返回给用户。</p><h2 id="4-mysql的执行过程"><a href="#4-mysql的执行过程" class="headerlink" title="4.mysql的执行过程"></a>4.mysql的执行过程</h2><p>客户端先发送一条查询给服务器；<br>服务器先检查查询缓存，如果命中了缓存，则立刻返回给存储在缓存中的结果，否则进入下一个阶段；<br>服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划；<br>MySQL 根据优化器生成的执行计划，调用存储引擎的API来执行查询；<br>将结果返回客户端。</p><h2 id="5-Mysql默认的隔离级别-解决了什么问题"><a href="#5-Mysql默认的隔离级别-解决了什么问题" class="headerlink" title="5.Mysql默认的隔离级别,解决了什么问题"></a>5.Mysql默认的隔离级别,解决了什么问题</h2><p>默认是可重复读的级别,解决了脏读和不可重复读的问题.<br>脏读是读出来的数据已经被修改,幻读是一个事务中连续读两次,结果不一样.<br>一个锁行,一个锁表.</p><h2 id="6-保证主从一致性的方法"><a href="#6-保证主从一致性的方法" class="headerlink" title="6.保证主从一致性的方法"></a>6.保证主从一致性的方法</h2><p>保证主从数据一致性主要有3种方法</p><h3 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a>半同步复制</h3><p>等到主从同步完成之后,主库上的写请求再返回.<br>缺点是很慢,要等</p><h3 id="数据库中间件"><a href="#数据库中间件" class="headerlink" title="数据库中间件"></a>数据库中间件</h3><p>请求先发给中间件,如果是CUD(创建更新删除)就发给主库,再同步到从库;<br>如果是Retrieve读取操作,就判断同步是否完成,决定从哪个地方读取</p><h3 id="缓存写key法"><a href="#缓存写key法" class="headerlink" title="缓存写key法"></a>缓存写key法</h3><p>将某个库上的某个key要发生写操作，记录在cache里，并设置“经验主从同步时间”的cache超时时间，例如500ms,再修改数据库<br>如果是读操作,先去cache看看有没有要写的,如果有,说明这个key上刚写过,去主库看看<br>如果没有,那就去从库直接获取即可.</p><h2 id="7-如果并发的全是写操作-如何解决"><a href="#7-如果并发的全是写操作-如何解决" class="headerlink" title="7.如果并发的全是写操作,如何解决"></a>7.如果并发的全是写操作,如何解决</h2><p>根据首字母进行分库分表.<br>或者使用消息队列进行插入,这样写操作就是可控的了</p><h2 id="8-如果并发数远远大于数据库性能的瓶颈，怎么操作"><a href="#8-如果并发数远远大于数据库性能的瓶颈，怎么操作" class="headerlink" title="8.如果并发数远远大于数据库性能的瓶颈，怎么操作"></a>8.如果并发数远远大于数据库性能的瓶颈，怎么操作</h2><p>同上.</p><h2 id="9-什么是数据库死锁"><a href="#9-什么是数据库死锁" class="headerlink" title="9.什么是数据库死锁"></a>9.什么是数据库死锁</h2><p>数据库中有两种锁,排他锁和共享锁.<br>共享锁是只读,不能修改;排他锁是读和修改都不能.<br>出现死锁的情况:</p><h3 id="1-事务之间对资源访问顺序的交替"><a href="#1-事务之间对资源访问顺序的交替" class="headerlink" title="1,事务之间对资源访问顺序的交替."></a>1,事务之间对资源访问顺序的交替.</h3><p>解决办法:程序之间的漏洞,最好保证操作两个表之间的顺序,比如所有用户都必须先操作A表再B表.</p><h3 id="2-并发修改同一记录"><a href="#2-并发修改同一记录" class="headerlink" title="2,并发修改同一记录"></a>2,并发修改同一记录</h3><p>用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。</p><p>解决办法:<br>1,乐观锁,基于数据版本记录机制实现,将提交数据的版本和当前版本比对,如果大于当前版本就更新,否则不处理.每次更新之后版本号加一.<br>主要是为了判断操作是否过时,每次操作的时候都假设别人是不会去改动的.提高效率,典型操作是CAS<br>2,悲观锁,长事务完全锁定,会严重影响并发效率</p><p>3, SqlServer可支持更新锁<br>为解决死锁，SqlServer引入更新锁,它有如下特征：<br>(1) 加锁的条件：当一个事务执行update语句时，数据库系统会先为事务分配一把更新锁。<br>(2) 解锁的条件：当读取数据完毕，执行更新操作时，会把更新锁升级为独占锁。<br>(3) 与其他锁的兼容性：更新锁与共享锁是兼容的，也就是说，一个资源可以同时放置更新锁和共享锁，但是最多放置一把更新锁。这样，当多个事务更新相同的数据时，只有一个事务能获得更新锁，然后再把更新锁升级为独占锁，其他事务必须等到前一个事务结束后，才能获取得更新锁，这就避免了死锁。</p><h3 id="索引不当导致全表扫描"><a href="#索引不当导致全表扫描" class="headerlink" title="索引不当导致全表扫描"></a>索引不当导致全表扫描</h3><p>使用多个表锁.</p><p>解决办法:对有全表扫描的SQL语句,建立索引进行优化</p><h2 id="10-如何解决脏读"><a href="#10-如何解决脏读" class="headerlink" title="10.如何解决脏读"></a>10.如何解决脏读</h2><p>一个事务中访问到了另一个事务中未提交的数据.</p><p>采用数据隔离级别,也就排他写锁.但是未提交的写事务将会禁止其他事务访问该行。</p><p>简单的说：<br>避免不可重复读锁行就行<br>避免幻读锁表就行</p><h2 id="11-Mysql和B-树"><a href="#11-Mysql和B-树" class="headerlink" title="11.Mysql和B+树"></a>11.Mysql和B+树</h2><p>B+树索引是什么？<br>为什么说B+树比B树更适合数据库索引？</p><p>众所周知，一颗传统的M阶B+树需要满足以下几个要求：<br><img src="https://user-gold-cdn.xitu.io/2019/1/13/16846ff5983b92fe?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt></p><p>从根节点到叶节点的所有路径都具有相同的长度<br>所有数据信息都存储在叶子节点，非叶子节点仅作为叶节点的索引存在<br>根节点至少拥有两个子树<br>每个树节点最多拥有M个子树<br>每个树节点(除了根节点)拥有至少M/2个子树</p><p>B+树是为了磁盘及其他存储辅助设备而设计的一种平衡查找树(不是二叉树)，在B+树中，所有记录的节点按大小顺序存放在同一层的叶节点中，各叶子节点用指针进行连接,而B+树索引本质上就是B+树在数据库中的实现，与纯粹的B+树数据结构还是有点区别。</p><p>B+树索引用于基于磁盘的数据库系统，即数据最后持久化存放在磁盘上，每个页的叶子节点一般包含较多的记录，因此具有较高的扇出。这意味着在数据库中B+树索引高度一般较小，在2~3层，其高度也决定了磁盘I/O搜索的次数<br>还有一点需要注意的是，实际上根据B+树索引并不能找到一个给定值的具体行，B+树索引能找到的只是查找数据行所在的页。然后数据库通过把数据页读入内存，再在内存中进行查找，最后得到查找的数据。</p><p><img src="https://user-gold-cdn.xitu.io/2019/1/13/16846ff5980f9693?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt><br>上图小红方块表示文件内容在硬盘中的存储位置。B树相比B+树的一个主要区别就在于B树的分支节点上存储着数据，而B+树的分支节点只是叶子节点的索引而已。</p><p>优点:</p><ol><li><p>B+树的磁盘读取代价低<br>B+-tree的内部节点并没有指向关键字具体信息的指针，换句话说，即分支节点没有存储数据，因此其内部节点相对B 树更小。如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。</p></li><li><p>B+树的查询效率更加稳定<br>在B+树中，由于分支节点并不是最终指向文件内容的节点，分支节点只是叶子节点的索引，所以对于任意关键字的查找都必须从根节点走到分支节点，所有关键字查询路径长度相同，每个数据查询效率相当。而对于B树而言，其分支节点上也保存有数据，对于每一个数据的查询所走的路径长度是不一样的，效率也不一样。</p></li><li><p>B+树便于执行扫库操作<br>由于B+树的数据都存储在叶子节点上，分支节点均为索引，方便扫库，只需扫一遍叶子即可。但是B树在分支节点上都保存着数据，要找到具体的顺序数据，需要执行一次中序遍历来查找。所以B+树更加适合范围查询的情况，在解决磁盘IO性能的同时解决了B树元素遍历效率低下的问题</p></li></ol><h2 id="12-Mysql底层实现事物机制"><a href="#12-Mysql底层实现事物机制" class="headerlink" title="12.Mysql底层实现事物机制"></a>12.Mysql底层实现事物机制</h2><p>首先我们要知道 mysql 的预写日志 wtite ahead log (WAL)机制，在mysql中redo日志相当于wal，即客户端操作命令先写入 redo 日志，然后再写入内存缓冲区，返回客户端， 最后再由操作系统写入硬盘。这样的好处是能保证事务。</p><p>undo日志（记录事物未执行之前数据库值）<br>将多个事物操作语句按顺序写入redo<br>biglog日志 （整个一次写入，所以当开启binlog时会对性能有点影响）<br>事物commit<br>返回用户</p><p>5.5之后加了半同步复制：<br>半同步复制，binlog写入后，会同步等待从库返回，从库返回后才返回给用户。</p><h2 id="13-数据库三范式"><a href="#13-数据库三范式" class="headerlink" title="13.数据库三范式"></a>13.数据库三范式</h2><p>第一范式：要求有主键，并且要求每一个字段原子性不可再分<br>不符合要求的实例:<br><img src="https://s1.ax1x.com/2020/08/19/dlwpRg.png" alt="dlwpRg.png"><br>第二范式：要求所有非主键字段完全依赖主键，不能产生部分依赖<br>不符合要求的实例:<br><img src="https://s1.ax1x.com/2020/08/19/dlw9zQ.png" alt="dlw9zQ.png"></p><p>第三范式：所有非主键字段和主键字段之间不能产生传递依赖<br><img src="https://s1.ax1x.com/2020/08/19/dlwSJS.png" alt="dlwSJS.png"></p><h2 id="14-SQl，如何构建索引，如何命中索引"><a href="#14-SQl，如何构建索引，如何命中索引" class="headerlink" title="14.SQl，如何构建索引，如何命中索引"></a>14.SQl，如何构建索引，如何命中索引</h2><p>可以使用Create index。或者使用alert index</p><pre><code>ALTER TABLE table_name ADD INDEX index_name (column_list)CREATE INDEX index_name ON table_name (column_list)</code></pre><p>联合索引:<br>create index 索引名 on 表名（字段名1，字段名2）</p><p>索引命中规则:<br>最左匹配:<br>1、先定位该sql的查询条件，有哪些，那些是等值的，那些是范围的条件。<br>2、等值的条件去命中索引最左边的一个字段，然后依次从左往右命中，范围的放在最后。</p><p>聚集索引: 叶子节点存放的是数据<br>非聚集索引: 叶子节点存放的是非聚集索引的key和主键值.</p><p>聚集索引的高度决定了根据主键取数据的理论IO次数。根据非聚集索引读取数据的理论IO次数还要加上访问聚集索引的IO次数总和。实际上可能要不了这么多IO。因为索引的分支节点所在的Page因为多次读取会在mysql内存里cache住。</p><h2 id="15-一条sql语句要执行完成需要经历什么过程"><a href="#15-一条sql语句要执行完成需要经历什么过程" class="headerlink" title="15.一条sql语句要执行完成需要经历什么过程"></a>15.一条sql语句要执行完成需要经历什么过程</h2><p>1、先在where解析这一步把当前的查询语句中的查询条件分解成每一个独立的条件单元<br>2、mysql会自动将sql拆分重组<br>3、然后where条件会在B-tree index这部分进行索引匹配，如果命中索引，就会定位到指定的table records位置。如果没有命中，则只能采用全部扫描的方式<br>4、根据当前查询字段返回对应的数据值</p><h2 id="16-Mybatis-‘-’-和-‘-’-的区别"><a href="#16-Mybatis-‘-’-和-‘-’-的区别" class="headerlink" title="16.Mybatis ‘#’ 和 ‘$’ 的区别"></a>16.Mybatis ‘#’ 和 ‘$’ 的区别</h2><p>使用”${}”方式传入的参数，mybatis不会对它进行特殊处理，而使用”#{}”传进来的参数，mybatis默认会将其当成字符串<br>所以对于传入分组(order)字段或者排序字段(order)，应使用’${}’,避免出现order  by “id” 等情况。</p><h2 id="17-数据库事务四大特性"><a href="#17-数据库事务四大特性" class="headerlink" title="17.数据库事务四大特性"></a>17.数据库事务四大特性</h2><p>事务具有四个特征：原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持久性（ Durability ）。这四个特性简称为 ACID 特性。<br>1 、原子性<br>事务是数据库的逻辑工作单位，不可分割，事务中包含的各操作要么都做，要么都不做<br>2 、一致性<br>事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。<br>3 、隔离性<br>一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。 事务的隔离级别有4级，可以查看这篇博客，关于MySQL的事务处理及隔离级别<br>4 、持续性<br>也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的，不能回滚。接下来的其它操作或故障不应该对其执行结果有任何影响。</p><h2 id="18-可重复读的底层实现原理"><a href="#18-可重复读的底层实现原理" class="headerlink" title="18.可重复读的底层实现原理"></a>18.可重复读的底层实现原理</h2><p>使用MVCC（多版本并发控制）。InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一。<br>在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号&lt;=当前版本号的数据，这时就算另一个事务插入一个数据，并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。<br>如果数据库并发控制引擎是单纯的封锁协议机制，则应该在读取数据的时候，判断数据项是不是其他事务更新过的。可是InnoDB没有这么做，而是通过如下方式，在RR隔离级别下为事务设置了一个“一致性读视图（即快照）”，之后读取数据，就是根据这个快照来获取，这样，就不能看到他晚于本事务的事务对已有记录的更新（更新生成新版本，必然不在旧的快照所限定的范围内）。</p><h2 id="19-聚集索引和非聚集索引"><a href="#19-聚集索引和非聚集索引" class="headerlink" title="19.聚集索引和非聚集索引"></a>19.聚集索引和非聚集索引</h2><p>聚集索引<br>　　一种索引，该索引中键值的逻辑顺序决定了表中相应行的物理顺序。<br>　　聚集索引确定表中数据的物理顺序。聚集索引类似于电话簿，后者按姓氏排列数据。由于聚集索引规定数据在表中的物理存储顺序，因此一个表只能包含一个聚集索引。但该索引可以包含多个列（组合索引），就像电话簿按姓氏和名字进行组织一样。<br>　　　　<br>　　　　 聚集索引对于那些经常要搜索范围值的列特别有效。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理相邻。例如，如果应用程序执行 的一个查询经常检索某一日期范围内的记录，则使用聚集索引可以迅速找到包含开始日期的行，然后检索表中所有相邻的行，直到到达结束日期。这样有助于提高此 类查询的性能。同样，如果对从表中检索的数据进行排序时经常要用到某一列，则可以将该表在该列上聚集（物理排序），避免每次查询该列时都进行排序，从而节 省成本。<br>　　　　 当索引值唯一时，使用聚集索引查找特定的行也很有效率。例如，使用唯一雇员 ID 列 emp_id 查找特定雇员的最快速的方法，是在 emp_id 列上创建聚集索引或 PRIMARY KEY 约束。<br>非聚集索引<br>　　一种索引，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。</p><p>每个表只能有一个聚集索引，因为目录只能按照一种方法进行排序。<br><img src="https://s1.ax1x.com/2020/07/27/aPEnxg.png" alt="aPEnxg.png"></p><p>底层实现:<br><a href="https://blog.csdn.net/q6627666/article/details/104405461" target="_blank" rel="noopener">https://blog.csdn.net/q6627666/article/details/104405461</a></p><h2 id="20-where-order-by-group-by对联合索引的使用情况"><a href="#20-where-order-by-group-by对联合索引的使用情况" class="headerlink" title="20.where,order by, group by对联合索引的使用情况"></a>20.where,order by, group by对联合索引的使用情况</h2><p>引用自:<a href="https://blog.csdn.net/q6627666/article/details/89607932?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">https://blog.csdn.net/q6627666/article/details/89607932?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase</a></p><p>1、只有where的情况，遵从最左原则，条件必须有左边的字段，才会用到索引，中间如果断开了，则都不会用到后面的索引，<br>例子： where c1 = ‘1’ and c2 = ‘1’ and c4 = ‘1’，这种情况因为c3没有在条件中，所以只会用到c1,c2索引。<br>特殊情况，使用范围条件的时候，也会使用到该处的索引，但后面的索引都不会用到<br>例子： where c1 = ‘1’ and c2 &gt; ‘1’ and c3 = ‘1’，这种情况从c2处已经断开，会使用到c1,c2索引，不会再使用到后面的c3,c4索引。<br>2、group by和order by 其实一样，也是遵从最左原则，可以看做继承where的条件顺序，但需要where作为基础铺垫，即没有where语句，单纯的group by | order by 也是不会使用任何索引的，并且需要和联合索引顺序一致才会使用索引。<br>例子：<br>group by c1 | order by c1，由于没有where的铺垫，不使用任何索引<br>where c1 = ‘1’ group | order by c2，使用c1,c2索引<br>where c1 = ‘1’ group | order by c3，只使用c1索引<br>where c1 &gt; ‘1’ group | order by c2，前面也说了，范围搜索会断掉连接，所以也只会使用c1索引<br>关于顺序：<br>where c1 = ‘1’ group | order by c2,c3，使用c1,c2,c3索引<br>where c1 = ‘1’ group | order by c3,c2，只使用c1索引</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis</title>
      <link href="/2020/04/02/redis/"/>
      <url>/2020/04/02/redis/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h2 id="1-Redis持久化问题"><a href="#1-Redis持久化问题" class="headerlink" title="1.Redis持久化问题"></a>1.Redis持久化问题</h2><p>有两种手段:<br>指定时间对数据进行快照存储,RDB<br>记录每次对服务器写的操作到日志中,AOF</p><p>从持久化恢复是优先找AOF文件,再找RDB文件.<br>一些优化经验:<br>如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其它途径补回；<br>自己制定策略定期检查Redis的情况，然后可以手动触发备份、重写数据；<br>单机如果部署多个实例，要防止多个机器同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变为串行；<br>可以加入主从机器，利用一台从机器进行备份处理，其它机器正常响应客户端的命令；<br>RDB持久化与AOF持久化可以同时存在，配合使用。</p><h2 id="2-Redis是单线程还是多线程"><a href="#2-Redis是单线程还是多线程" class="headerlink" title="2.Redis是单线程还是多线程"></a>2.Redis是单线程还是多线程</h2><p>Redis是单线程只是因为网络请求模块使用了一个线程,不用考虑并发安全性,其他模块是多线程</p><p>内部实现原理:多路io复用技术<br>内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间.epoll是事件回调,等io处理完了再回来处理.<br>通俗说法:老李去火车站买票，委托黄牛，黄牛买到后即通知老李去领，然后老李去火车站交钱领票。</p><h2 id="3-Redis的哨兵机制"><a href="#3-Redis的哨兵机制" class="headerlink" title="3.Redis的哨兵机制"></a>3.Redis的哨兵机制</h2><p>为了解决redis主从复制模式致命缺点，当主节点宕机，影响整个系统运行，引入哨兵机制Sentinel。<br>主要实现的功能:<br>监控，监控每个节点以及哨兵运行状态报警，当发现某个节点或哨兵出现问题，通知其他哨兵自动故障转化，当主节点宕机时，哨兵从原主节点下的所有可用从节点中选举出一个作为主节点，原主节点降为从节点，并将其他从节点的主节点配置改为指定新主节点配置中心，客户端初始化连接的是哨兵节点集合</p><p>具体实现:<br>哨兵是一个特殊的redis服务器，不同的是命令以及不会持久化，启动时，根据配置文件中master主节点ip和端口，创建两个连接，一为命令连接，获取服务器的运行状态（包括主节点、从节点的基本信息）；二为订阅连接，订阅服务器的_sentinel_:hello频道（获取哨兵集群的其他哨兵节点，配置中只需配置主节点信息）哨兵默认每隔十秒向节点发送info，获取主从服务器的信息，及时更新哨兵下的服务器实例；每隔一秒向节点发送ping命令，根据有效时间内（down-after-milliseconds参数配置）返回内容判断服务器是否在线，有效回复内容包括PONG、LOADING、MASTERDOWN，其他均为无效回复，将服务器设定为主观下线（在有效时间内未回复有效内容，将被哨兵主观下线）当主节点出现主观下线， 哨兵将询问其他哨兵主节点状态，当确认主节点状态为主观下线的哨兵数量达到配置数目（sentinel monitor mymaster 127.0.0.1 6379 2，2则表示数目）时，主节点被修改为客观下线当主节点被客观下线时，哨兵将选举出一位临时主哨兵（哨兵可以让其他哨兵选举自己，先到先得，选票高者当选），主哨兵根据原则（在线、slave-priority可设置从节点当选主节点服务器优先级，越小优先级越高）从节点中选出主节点，原主节点降为从节点并客观下线状态，并将其他从节点指向新主节点进行数据复制</p><h2 id="4-Redis支持什么类型的数据"><a href="#4-Redis支持什么类型的数据" class="headerlink" title="4.Redis支持什么类型的数据."></a>4.Redis支持什么类型的数据.</h2><p>Redis支持五中数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）及zset(sortedset：有序集合)<br>注意这些都是值的value的类型,key是不限制的<br>String的字符串大小限制512M</p><h2 id="5-Redis和数据库的数据一致性是怎么保证的"><a href="#5-Redis和数据库的数据一致性是怎么保证的" class="headerlink" title="5.Redis和数据库的数据一致性是怎么保证的?"></a>5.Redis和数据库的数据一致性是怎么保证的?</h2><p>两个办法:<br>1,先删缓存,再更新数据库数据,再更新缓存;同时给缓存设定过期时间<br>2,异步更新缓存,基于binlog的同步机制<br>这里说的是增量,指的是mysql的update、insert、delate变更数据,读取binlog后分析,利用消息队列,推送更新各台的redis缓存数据,这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><h2 id="6-解决缓存一致性问题"><a href="#6-解决缓存一致性问题" class="headerlink" title="6.解决缓存一致性问题"></a>6.解决缓存一致性问题</h2><p>如果要求强一致性,即任何时间必须保证绝对一致,只能:读请求和写请求串行化，串到一个内存队列里去。<br>但是这样会很慢</p><p>下面介绍个新的方法:<br>Cache Aside Pattern<br>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。<br>更新的时候，先删除缓存,然后更新数据库。</p><p>因为一般的时候缓存没必要随时更新,而是用到缓存的时候才去更新;这是一个lazy的思想.</p><p>新的问题:如果缓存被删除,数据库更新完尚未更新缓存,此时有一个读取请求进来读到旧数据怎么办;<br>解决:更新数据的操作进队列,读取数据的时候发送的重新读取+更新缓存也进队列,此时就先发送更新缓存的操作进队列即可.</p><p>优化:如果发现队列里对同一个数据有多个缓存更新请求,就直接等待前面的更新操作完成即可.<br>请求如果不断轮询发现可以取到值了,就直接返回即可.<br>如果超时了,就直接读取旧的值.</p><p>可以使用Kafka,或者RocketMQ来实现.</p><h2 id="7-如果要更新数据库-是怎么样的一个流程"><a href="#7-如果要更新数据库-是怎么样的一个流程" class="headerlink" title="7.如果要更新数据库,是怎么样的一个流程?"></a>7.如果要更新数据库,是怎么样的一个流程?</h2><p>先删缓存,再更新,然后更改binlog,缓存监听binlog进行异步更新.</p><h2 id="8-常用命令"><a href="#8-常用命令" class="headerlink" title="8.常用命令"></a>8.常用命令</h2><p>set,del,dump(序列化),exists,ttl(查看有效期),expire(设定有效期),persist(移除过期时间),keys(获取满足条件的所有key)</p><h2 id="9-如何解决超卖的问题"><a href="#9-如何解决超卖的问题" class="headerlink" title="9.如何解决超卖的问题"></a>9.如何解决超卖的问题</h2><p>1,使用redis的分布式锁,点击结算时,后端逻辑会查询库存并且锁定,只有一个线程能运行.<br>性能并不强</p><p>2,推荐使用redis原子操作+sql乐观锁<br>使用redis increment的原子操作,先查询库存信息,并且存入到缓存中.<br>以商品id为key,数量为value,设定一个合理定时时间.</p><p>比较下单的数量大小,如果足够就进行处理.<br>执行redis客户端的increment,参数为负数,redis是单线程处理.</p><p>使用乐观锁update,把库存字段减一.</p><p>sql的每条语句都是有事务的,所以也是乐观锁,分先后执行.</p><h2 id="10-讲讲Redis分布式锁"><a href="#10-讲讲Redis分布式锁" class="headerlink" title="10.讲讲Redis分布式锁"></a>10.讲讲Redis分布式锁</h2><h3 id="10-1出现原因"><a href="#10-1出现原因" class="headerlink" title="10.1出现原因"></a>10.1出现原因</h3><p>保证不同节点的线程同步执行</p><h3 id="10-2分布式锁的特点"><a href="#10-2分布式锁的特点" class="headerlink" title="10.2分布式锁的特点"></a>10.2分布式锁的特点</h3><p>同可重入锁，不过是多进程取锁。</p><h3 id="10-3实现方式"><a href="#10-3实现方式" class="headerlink" title="10.3实现方式"></a>10.3实现方式</h3><p>1，基于数据库<br>有三种实现方式：基于表记录、乐观锁和悲观锁。</p><h4 id="10-3-1基于表记录："><a href="#10-3-1基于表记录：" class="headerlink" title="10.3.1基于表记录："></a>10.3.1基于表记录：</h4><p>要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。当我们想要获得锁的时候，就可以在该表中增加一条记录，想要释放锁的时候就删除这条记录。<br>缺点：<br>这种锁没有失效时间，一旦释放锁的操作失败就会导致锁记录一直在数据库中，其它线程无法获得锁。这个缺陷也很好解决，比如可以做一个定时任务去定时清理。<br>这种锁的可靠性依赖于数据库。建议设置备库，避免单点，进一步提高可靠性。<br>这种锁是非阻塞的，因为插入数据失败之后会直接报错，想要获得锁就需要再次操作。如果需要阻塞式的，可以弄个for循环、while循环之类的，直至INSERT成功再返回。<br>这种锁也是非可重入的，因为同一个线程在没有释放锁之前无法再次获得锁，因为数据库中已经存在同一份记录了。想要实现可重入锁，可以在数据库中添加一些字段，比如获得锁的主机信息、线程信息等，那么在再次获得锁的时候可以先查询数据，如果当前的主机信息和线程信息等能被查到的话，可以直接把锁分配给它。</p><h4 id="10-3-2基于乐观锁"><a href="#10-3-2基于乐观锁" class="headerlink" title="10.3.2基于乐观锁"></a>10.3.2基于乐观锁</h4><p>乐观锁大多数是基于数据版本(version)的记录机制实现的。何谓数据版本号？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表添加一个 “version”字段来实现读取出数据时，将此版本号一同读出，之后更新时，对此版本号加1。在更新过程中，会对版本号进行比较，如果是一致的，没有发生改变，则会成功执行本次操作；如果版本号不一致，则会更新失败。</p><h4 id="10-3-3基于悲观锁"><a href="#10-3-3基于悲观锁" class="headerlink" title="10.3.3基于悲观锁"></a>10.3.3基于悲观锁</h4><p>除了可以通过增删操作数据库表中的记录以外，我们还可以借助数据库中自带的锁来实现分布式锁。在查询语句后面增加FOR UPDATE，数据库会在查询过程中给数据库表增加悲观锁，也称排他锁。当某条记录被加上悲观锁之后，其它线程也就无法再改行上增加悲观锁。<br>在使用悲观锁的同时，我们需要注意一下锁的级别。MySQL InnoDB引起在加锁的时候，只有明确地指定主键(或索引)的才会执行行锁 (只锁住被选取的数据)，否则MySQL 将会执行表锁(将整个数据表单给锁住)。<br>在使用悲观锁时，我们必须关闭MySQL数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。</p><h4 id="10-3-4基于Redis"><a href="#10-3-4基于Redis" class="headerlink" title="10.3.4基于Redis"></a>10.3.4基于Redis</h4><p>1, 使用SETNX命令：有漏洞。</p><p>2, 使用Redlock算法<br>假设有5个独立的Redis节点（注意这里的节点可以是5个Redis单master实例，也可以是5个Redis Cluster集群，但并不是有5个主节点的cluster集群）：<br>获取当前Unix时间，以毫秒为单位<br>依次尝试从5个实例，使用相同的key和具有唯一性的value(例如UUID)获取锁，当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应用小于锁的失效时间，例如你的锁自动失效时间为10s，则超时时间应该在5~50毫秒之间，这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁<br>客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间，当且仅当从大多数(N/2+1，这里是3个节点)的Redis节点都取到锁，并且使用的时间小于锁失败时间时，锁才算获取成功。<br>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）<br>如果某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）</p><p>3, 基于Zookeeper</p><h2 id="11-为什么Redis使用跳表而不是红黑树来实现"><a href="#11-为什么Redis使用跳表而不是红黑树来实现" class="headerlink" title="11. 为什么Redis使用跳表而不是红黑树来实现?"></a>11. 为什么Redis使用跳表而不是红黑树来实现?</h2><p>TODO</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NameServer</title>
      <link href="/2020/02/24/nameserver/"/>
      <url>/2020/02/24/nameserver/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Eureka"><a href="#1-Eureka" class="headerlink" title="1.Eureka"></a>1.Eureka</h1><p>Eureka是Netfix的一个子模块,也是核心模块之一. Eureka是一个基于REST的服务,用于定位服务,以实现云端中间层服务发现和故障转移。服务注册与发现对于微服务架构来说是非常重要的,有了服务发现与注册,只需要使用服务的标识符,就可以访问到服务,而不需要修改服务调用的配置文件了。功能类似于dubbo的注册中心,比如Zookeeper</p><h2 id="1-1Eureka-Service和Eureka-Client"><a href="#1-1Eureka-Service和Eureka-Client" class="headerlink" title="1.1Eureka Service和Eureka Client"></a>1.1Eureka Service和Eureka Client</h2><p>Eureka Server提供服务注册服务,各个节点启动后会在这里进行注册,这样Eureka Server中的服务注册表中将会存储所有可用服务节点的信息,服务节点的信息可以在界面中直观的看到.</p><p>Eureka Client是一个java客户端,用于简化Eureka Server的交互,客户端同时也具备一个内置的、使用轮询(round-robin)负载复法的负载均衡器。在应用启动后,将会向Eureka Server发送心跳(默认周期为30秒),如果Eureka Server在多个心跳周期内没有接收到某服务节点的心跳, Eureka Server将会从服务注册表中把这个服务节点移除(默认90).</p><h1 id="2-zookeeper和eureka的区别在哪"><a href="#2-zookeeper和eureka的区别在哪" class="headerlink" title="2.zookeeper和eureka的区别在哪?"></a>2.zookeeper和eureka的区别在哪?</h1><p>Zookeeper:<br>当向注册中心查询服务列表时,我们可以容忍注册中心返回的是几分钟以前的注册信息,但不能接受服务直接down掉不可用。也就是说,服务注册功能对可用性的要求要高于一致性。</p><p>但是zk会出现这样一种情况,当master节点因为网络故障与其他节点失去取系时,剩余节点会重新进行leader选举。问题在于,选举leader的时间太长, 30 ~ 120s,且选举期间整个2k集群都是不可用的,这就导致在选举期间注册服务瘫痪。在云部署的环境下,因网络问题使得zk集群失去master节点是较大概率会发生的事,虽然服务能够恢复,但是漫长的选举时间导致的注册长期不可用是不能容忍的.</p><p>Eureka:</p><p>Eureka想明白了这一点,因此在设计时就优先保证可用性。</p><p>Eureka各个节点都是平等的,几个节点挂掉不会影响正常节点的工作剩余的节点依然可以提供注册和查询服务。</p><p>而Eureka的客户端在向某个Eureka注册或时如果发现连接失败,则会自动切换至其它节点,只要有一台Eureka还在,就能保证注册服务可用(保证可用性),只不过查到的信息可能不是最新的(不保证强一致性)。</p><p>除此之外, Eureka还有一种自我保护机制,如果在15分钟内超过85%的节点都没有正常的心跳,那么Eureka就认为客户端与注册中心出现了网络故障,此时会出现以下几种情况</p><p>1, Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务</p><p>2.Eureka仍然能够接受新服务的注册和查询请求,但是不会被同步到其它节点上(即保证当前节点依然可用)</p><p>3,当网络稳定时,当前实例新的注册信息会被同步到其它节点中.</p><p>因此, Eureka可以很好的应对因网络故障导致部分节点失去联系的情况,而不会像zookeeper那样便整个注册服务瘫痪。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NameServer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列8: SpringBoot</title>
      <link href="/2020/02/16/javaweb-xi-lie-8-springboot/"/>
      <url>/2020/02/16/javaweb-xi-lie-8-springboot/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列8-SpringBoot"><a href="#JavaWeb系列8-SpringBoot" class="headerlink" title="JavaWeb系列8: SpringBoot"></a>JavaWeb系列8: SpringBoot</h1><p>本文是作者的读博客笔记和心得整理，也引用了一些比较好的博客文章,部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是SpringBoot"><a href="#什么是SpringBoot" class="headerlink" title="什么是SpringBoot"></a>什么是SpringBoot</h2><p>springboot的优点在于他的项目中存在大量的配置,内置好了,而且默认配置了很多框架的使用方式.</p><p>使用的优点:快速的让项目跑起来.</p><h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><p>1,选择springboot初始化器,然后一路next<br>生成之后的初始化文件包括以下内容:<br>SpringbootApplication: 一个带有main方法的类,用于启动应用程序<br>SpringbootApplicationTests: 一个空的JUnit测试<br>application.properties:一个空的文件,用于加载默认配置</p><p>2,新建一个controller<br>以下是一个示例:</p><pre><code>package cn.wmyskxz.springboot;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 测试控制器 * * @author: @我没有三颗心脏 * @create: 2018-05-08-下午 16:46 */@RestControllerpublic class HelloController {    @RequestMapping(&quot;/hello&quot;)    public String hello() {        return &quot;Hello Spring Boot!&quot;;    }}</code></pre><p>这里用到了一个注解,@RestController,相当于声明这是一个controller,并且这是一个@ResponseBody</p><p>3,回到SpringbootApplication这个类,运行.<br>Tomcat服务器自动启动在8080端口.</p><h2 id="常用的一些核心机制"><a href="#常用的一些核心机制" class="headerlink" title="常用的一些核心机制"></a>常用的一些核心机制</h2><p>@SpringBootApplication:组合注解,组会了@Configuration,@EnableAutoConfiguration,@ComponentScan.<br>    EnableAutoConfiguration让 Spring Boot 根据类路径中的 jar 包依赖为当前项目进行自动配置</p><p>application.properties这个文件其实一般不太常用,更多的是用yml后缀,放在src/main/resources这个目录下</p><p>SpringBoot同时支持热部署,只要添加以下依赖:</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    spring-boot-devtools    &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt;&lt;/dependency&gt;</code></pre><h2 id="视图模式的更改"><a href="#视图模式的更改" class="headerlink" title="视图模式的更改"></a>视图模式的更改</h2><p>SpringBoot默认支持的是Thymeleaf,这个其实蛮好用的,大家可以学一下.<br><a href="https://blog.csdn.net/u014042066/article/details/75614906" target="_blank" rel="noopener">https://blog.csdn.net/u014042066/article/details/75614906</a></p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列7: Hibernate</title>
      <link href="/2020/02/14/javaweb-xi-lie-7-hibernate/"/>
      <url>/2020/02/14/javaweb-xi-lie-7-hibernate/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列7-Hibernate"><a href="#JavaWeb系列7-Hibernate" class="headerlink" title="JavaWeb系列7: Hibernate"></a>JavaWeb系列7: Hibernate</h1><p>本文是作者的读博客笔记和心得整理，也引用了一些比较好的博客文章,部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是Hibernate"><a href="#什么是Hibernate" class="headerlink" title="什么是Hibernate"></a>什么是Hibernate</h2><p>这是一种ORM的框架,全称是Object Relative DataBase-Mapping,在java对象和关系数据库之间建立某种映射,直接存取java对象.</p><p>属于在MVC中的数据持久层,也就是DAO层.</p><p>DAO层主要过程是:<br>操作XML,将数据封装到XML文件上,读写XML文件实现CURD</p><p>或者使用JDBC连接数据库,实现CURD</p><p>Hibernate提供的简化就是JavaBean对象和数据表中的列存在映射关系,这样就可以避免写SQL语句了.<br>示例讲解一个Hibernate配置</p><pre><code>先编写一个对象public class User {    private int id;    private String username;    private String password;    private String cellphone;    //各种setter和getter}然后配置一个XML&lt;!--在domain包下--&gt;    &lt;hibernate-mapping package=&quot;zhongfucheng.domain&quot;&gt;        &lt;!--类名为User，表名也为User--&gt;        &lt;class name=&quot;User&quot;  table=&quot;user&quot;&gt;            &lt;!--主键映射，属性名为id，列名也为id--&gt;            &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt;                &lt;!--根据底层数据库主键自动增长--&gt;                &lt;generator class=&quot;native&quot;/&gt;            &lt;/id&gt;            &lt;!--非主键映射，属性和列名一一对应--&gt;            &lt;property name=&quot;username&quot; column=&quot;username&quot;/&gt;            &lt;property name=&quot;cellphone&quot; column=&quot;cellphone&quot;/&gt;            &lt;property name=&quot;password&quot; column=&quot;password&quot;/&gt;        &lt;/class&gt;    &lt;/hibernate-mapping&gt;注意name是类中的属性,column是表中的列名.</code></pre><pre><code>看一个入门案例public static void main(String[] args) {    //创建对象    User user = new User();    user.setPassword(&quot;123&quot;);    user.setCellphone(&quot;122222&quot;);    user.setUsername(&quot;nihao&quot;);    //获取加载配置管理类    Configuration configuration = new Configuration();    //不给参数就默认加载hibernate.cfg.xml文件，    configuration.configure();    //创建Session工厂对象    SessionFactory factory = configuration.buildSessionFactory();    //得到Session对象    Session session = factory.openSession();    //使用Hibernate操作数据库，都要开启事务,得到事务对象    Transaction transaction = session.getTransaction();    //开启事务    transaction.begin();    //把对象添加到数据库中    session.save(user);    //提交事务    transaction.commit();    //关闭Session    session.close();}</code></pre><p>同时Hibernate还提供了一些常用的Session的方法来实现:</p><pre><code>public interface IEmployeeDao {    void save(Employee emp);    void update(Employee emp);    Employee findById(Serializable id);    List&lt;Employee&gt; getAll();    List&lt;Employee&gt; getAll(String employeeName);    List&lt;Employee&gt; getAll(int index, int count);    void delete(Serializable id);}</code></pre><p>同时当然也支持注解开发方式,而且比较常用:</p><pre><code>@Entity // 定义了一个实体@Table(name=&quot;t_book&quot;,catalog=&quot;hibernateTest&quot;)public class Book {@Id // 这表示一个主键// @GeneratedValue 相当于native主键生成策略@GeneratedValue(strategy=GenerationType.IDENTITY) // 相当于identity主键生成策略private Integer id; // 主键@Column(name=&quot;c_name&quot;, length=30, nullable=true)private String name;@Temporal(TemporalType.TIMESTAMP) // 是用来定义日期类型private Date publicationDate; // 出版日期@Type(type=&quot;double&quot;) // 允许你去指定Hibernate里面的一些类型private Double price; // 价格，如果没有添加注解，也会自动的生成在表中</code></pre><p>对于PO类的使用<br>@Entity是用来声明一个实体<br>@Table来声明一个表<br>@id声明一个主键,常常和@GeneratedValue一起,表面一个主键的声明策略<br>@Id表示这是一个主键<br>@Column定义一个列<br>@Temporal声明日期类型<br>@Transient表面这个属性不生成在表中<br>下面是一个比较简单的测试类:</p><pre><code>public class HibernateAnnotationTest {    // 测试PO的注解开发    @Test    public void test1() {        Session session = HibernateUtils.openSession();        session.beginTransaction();        Book b = new Book();        b.setName(&quot;情书&quot;);        b.setPrice(56.78);        b.setPublicationDate(new Date());        session.save(b);        session.getTransaction().commit();        session.close();    }}</code></pre><p>还有@OneToMany和@ManyToOne这两个注解用来生成外键.</p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> Hibernate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列6: Maven</title>
      <link href="/2020/02/12/javaweb-xi-lie-6-maven/"/>
      <url>/2020/02/12/javaweb-xi-lie-6-maven/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列6-Maven"><a href="#JavaWeb系列6-Maven" class="headerlink" title="JavaWeb系列6: Maven"></a>JavaWeb系列6: Maven</h1><p>本文是作者的读博客笔记和心得整理，也引用了一些比较好的博客文章,部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h2><p>在maven出来之前,都是用Ant作为一个构建工具,并未对项目中低端工程依赖和项目本身进行管理.<br>核心是:依赖管理， 项目信息管理， 中央仓库， 约定大于配置的核心功能使得Maven成为当前Java项目构建和管理工具的标准选择。</p><h2 id="常用maven命令"><a href="#常用maven命令" class="headerlink" title="常用maven命令"></a>常用maven命令</h2><p>mvn clean:运行清理操作<br>mvn clean compile: 表示运行清理之后进行编译<br>mvn clean test: 运行清理和测试<br>mvn clean package: 清理和打包<br>mvn clean install：运行清理和安装，会将打好的包安装到本地仓库中，以便其他的项目可以调用。<br>mvn clean deploy：运行清理和发布（发布到私服上面）</p><h2 id="Maven使用格式"><a href="#Maven使用格式" class="headerlink" title="Maven使用格式"></a>Maven使用格式</h2><p>一个配置的示例:</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;https://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;https://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;https://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.tengj&lt;/groupId&gt;    &lt;artifactId&gt;springBootDemo1&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;name&gt;springBootDemo1&lt;/name&gt;&lt;/project&gt;</code></pre><p>第一行是XML头,指定版本号<br>project指定根元素<br>modelVersion指定当前POM模型的版本号<br>groupId,artifactId和version指定了一个项目的基本坐标.<br>groupId指定的是组,artifactId指定的是组中id,version指定版本号</p><p>接下来是依赖范围:<br>示例:</p><pre><code>&lt;project&gt;...&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;实际项目&lt;/groupId&gt;　　　　 &lt;artifactId&gt;模块&lt;/artifactId&gt;　　　　 &lt;version&gt;版本&lt;/version&gt;　　　　 &lt;type&gt;依赖类型&lt;/type&gt;　　　　 &lt;scope&gt;依赖范围&lt;/scope&gt;　　　　 &lt;optional&gt;依赖是否可选&lt;/optional&gt;　　　　 &lt;!—主要用于排除传递性依赖--&gt;　　　　 &lt;exclusions&gt;　　　　     &lt;exclusion&gt;　　　　　　　    &lt;groupId&gt;…&lt;/groupId&gt;　　　　　　　　　 &lt;artifactId&gt;…&lt;/artifactId&gt;　　　　　　　&lt;/exclusion&gt;　　　　 &lt;/exclusions&gt;　　&lt;/dependency&gt;&lt;dependencies&gt;...&lt;/project&gt;</code></pre><p>type:大部分时候为jar<br>scope:依赖的范围<br>optional:标记依赖是否可选<br>exclusions:用来排除传递性依赖</p><h2 id="依赖范围"><a href="#依赖范围" class="headerlink" title="依赖范围"></a>依赖范围</h2><p>compile:默认范围,对于编译测试运行3种classpath全部有效<br>test:只在测试classpath有效,JUnit<br>provided:对于编译和测试有效,运行无效.<br>runtime:只在测试和运行有效,JDBC</p><h2 id="和Gradle的比较"><a href="#和Gradle的比较" class="headerlink" title="和Gradle的比较"></a>和Gradle的比较</h2><p>使用Groovy来声明项目设置,抛弃了基于XML的各种繁琐配置.<br>比如一个典型的Gradle项目:</p><pre><code>dependencies {// This dependency is exported to consumers, that is to say found on their compile classpath.api &#39;org.apache.commons:commons-math3:3.6.1&#39;// This dependency is used internally, and not exposed to consumers on their own compile classpath.implementation &#39;com.google.guava:guava:23.0&#39;// Use JUnit test frameworktestImplementation &#39;junit:junit:4.12&#39;compile &#39;org.hibernate:hibernate-core:3.6.7.Final&#39;testCompile ‘junit:junit:4.+&#39;}</code></pre><p>Gradle的优点是可以动态的实现版本管理,而且先天可以解决依赖冲突的问题.</p><h2 id="多模块构建"><a href="#多模块构建" class="headerlink" title="多模块构建"></a>多模块构建</h2><p>一般一个项目分解为多个模块,需要定义一个parent POM来作为一组module的通用配置模型. 也可以用标签来定义一组子模块,<br>parent的配置会自动继承给子module.</p><p>Gradle也支持多模块构建,在parent的build.gradle中可以使用allproject和subproject来分别定义应用于所有项目/子项目,<br>子模块的定义放置在settings.gradle中,每一个模块代表一个project的对象实例.<br>执行gradle -q nice会依次打印出各模块的项目名称.</p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列5: Test</title>
      <link href="/2020/02/10/javaweb-xi-lie-5-test/"/>
      <url>/2020/02/10/javaweb-xi-lie-5-test/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列5-Test"><a href="#JavaWeb系列5-Test" class="headerlink" title="JavaWeb系列5: Test"></a>JavaWeb系列5: Test</h1><p>本文是作者的读博客笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p>主要用JUnit或者TestNG,开发者编写,针对方法级别的测试.</p><h2 id="集成测试"><a href="#集成测试" class="headerlink" title="集成测试"></a>集成测试</h2><p>用于检测系统能否正常工作,主要是跨组件实现测试.</p><h2 id="功能性测试"><a href="#功能性测试" class="headerlink" title="功能性测试"></a>功能性测试</h2><p>专门的测试团队进行测试.</p><h2 id="JUnit"><a href="#JUnit" class="headerlink" title="JUnit"></a>JUnit</h2><h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3><p>@Test:用这个注解的方法可以作为一个测试用例.<br>@Before:这个方法必须在每个测试之前运行<br>@BeforeClass:在本类所有测试之前运行<br>@After/@AfterClass:类似上面<br>@Ignore:被修饰的不被执行</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>1,注意写一点测一点,保存测试样例<br>2,不要使用过期数据进行测试<br>3,测试类的命名需要注意<br>4,避免更改数据库中的数据,及时回滚.<br>5,不要写死数据路径<br>6,使用文档生成器作为测试文档.</p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> Test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列4: Spring</title>
      <link href="/2020/02/08/javaweb-xi-lie-4-spring/"/>
      <url>/2020/02/08/javaweb-xi-lie-4-spring/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列4-Spring"><a href="#JavaWeb系列4-Spring" class="headerlink" title="JavaWeb系列4: Spring"></a>JavaWeb系列4: Spring</h1><p>本文是作者的读博客笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是Bean"><a href="#什么是Bean" class="headerlink" title="什么是Bean"></a>什么是Bean</h2><p>比如类里面的定义一个size变量为private,然后定义一个public的get方法,保持向后兼容性,这种手法就是bean.</p><h2 id="J2EE"><a href="#J2EE" class="headerlink" title="J2EE"></a>J2EE</h2><p>出现的原因:我们只想关注我们的业务逻辑， 我们不想， 也不应该由我们来处理‘低级’的事务， 多线程，连接池，以及其他各种各种的‘低级’API， 此外Java帝国一定得提供集群功能， 这样我们的一台机器死机以后，整个系统还能运转。 </p><p>J2EE包含以下内容:<br>JDBC: Java 数据库连接</p><p>JNDI : Java 命名和目录接口， 通过一个名称就可以定位到一个数据源， 连jdbc连接都不用了</p><p>RMI： 远程过程调用， 让一个机器上的java 对象可以调用另外一个机器上的java 对象</p><p>JMS : Java 消息服务， 可以使用消息队列了</p><p>JTA： Java 事务管理， 支持分布式事务， 能在访问、更新多个数据库的时候，仍然保证事务， 还是分布式。</p><p>Java mail : 收发邮件</p><h2 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h2><p>spring容器主要负责把依赖的bean注入到服务当中,正常的流程应该是比如A需要B,就先执行A,然后创建B的对象,再调用B.<br>但是控制反转的意思是,我先创建B的对象封装为bean,然后要使用A的时候就把这个bean注入进来.</p><p>面向切面:如果一个Bean 需要一些像事务，日志，安全这样的通用的服务， 也是只需要声明即可， spring 容器在运行时能够动态的“织入”这些服务， 这叫面向切面（AOP）。</p><h2 id="Bean的区别和联系"><a href="#Bean的区别和联系" class="headerlink" title="Bean的区别和联系"></a>Bean的区别和联系</h2><p>首先是Java Bean.说白了就是一个实体类,用来封装很多对象里面全部都是属性值和getset方法.</p><p>但是SpringBean就不太一样.Spring会按照配置文件来创建bean实例,并且调用;不需要去人为的创造对象了.</p><pre><code>&lt;bean id=&quot;p1&quot; class=&quot;com.zking.Pojo.Person&quot; scope=&quot;prototype&quot;&gt;//及时加载 加载你的xml配置文件ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;ApplicationContext.xml&quot;);//getbean输入你配置类的别名得到 person对象 Person p = (Person) applicationContext.getBean(&quot;p1&quot;);</code></pre>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列3: Tomcat</title>
      <link href="/2020/02/06/javaweb-xi-lie-3-tomcat/"/>
      <url>/2020/02/06/javaweb-xi-lie-3-tomcat/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列3-Tomcat"><a href="#JavaWeb系列3-Tomcat" class="headerlink" title="JavaWeb系列3: Tomcat"></a>JavaWeb系列3: Tomcat</h1><p>本文是作者的读博客笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="Tomcat-体系结构"><a href="#Tomcat-体系结构" class="headerlink" title="Tomcat 体系结构"></a>Tomcat 体系结构</h2><p>Tomcat是一个基于组件的服务器，它的构成组件都是可配置的，其中最外层的是Catalina servlet容器，其他组件按照一定的格式要求配置在这个顶层容器中。<br>Tomcat的各种组件都是在Tomcat安装目录下的/conf/server.xml文件中配置的。</p><pre><code>&lt;Server&gt;                                                //顶层类元素，可以包括多个Service       &lt;Service&gt;                                           //顶层类元素，可包含一个Engine，多个Connecter        &lt;Connector&gt;                                     //连接器类元素，代表通信接口                &lt;Engine&gt;                                //容器类元素，为特定的Service组件处理客户请求，要包含多个Host                        &lt;Host&gt;                          //容器类元素，为特定的虚拟主机组件处理客户请求，可包含多个Context                                &lt;Context&gt;               //容器类元素，为特定的Web应用处理所有的客户请求                                &lt;/Context&gt;                        &lt;/Host&gt;                &lt;/Engine&gt;        &lt;/Connector&gt;    &lt;/Service&gt;&lt;/Server&gt;</code></pre><p>一个标准的执行流程:<br>1、用户点击网页内容，请求被发送到本机端口8080，被在那里监听的Coyote HTTP/1.1 Connector获得。</p><p>2、Connector把该请求交给它所在的Service的Engine来处理，并等待Engine的回应。</p><p>3、Engine获得请求localhost/test/index.jsp，匹配所有的虚拟主机Host。</p><p>4、Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机），名为localhost的Host获得请求/test/index.jsp，匹配它所拥有的所有的Context。Host匹配到路径为/test的Context（如果匹配不到就把该请求交给路径名为“ ”的Context去处理）。</p><p>5、path=“/test”的Context获得请求/index.jsp，在它的mapping table中寻找出对应的Servlet。Context匹配到URL PATTERN为*.jsp的Servlet,对应于JspServlet类。</p><p>6、构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet（）或doPost（）.执行业务逻辑、数据存储等程序。</p><p>7、Context把执行完之后的HttpServletResponse对象返回给Host。</p><p>8、Host把HttpServletResponse对象返回给Engine。</p><p>9、Engine把HttpServletResponse对象返回Connector。</p><p>10、Connector把HttpServletResponse对象返回给客户Browser。　</p><h2 id="Connector组件"><a href="#Connector组件" class="headerlink" title="Connector组件"></a>Connector组件</h2><p>一个connector和一个container组成一个最小的单元,被service封装一下就成了一个基本结构.<br>一个container可以有很多个connector.<br>Connector 组件是 Tomcat 中两个核心组件之一，它的主要任务是负责接收浏览器的发过来的 tcp 连接请求，创建一个 Request 和 Response 对象分别用于和请求端交换数据，然后会产生一个线程来处理这个请求并把产生的 Request 和 Response 对象传给处理这个请求的线程，处理这个请求的线程就是 Container 组件要做的事了。</p><h2 id="Container组件"><a href="#Container组件" class="headerlink" title="Container组件"></a>Container组件</h2><p>Container 是容器的父接口，所有子容器都必须实现这个接口，Container 容器的设计用的是典型的责任链的设计模式，它有四个子容器组件构成，分别是：Engine、Host、Context、Wrapper，这四个组件不是平行的，而是父子关系，Engine 包含 Host,Host 包含 Context，Context 包含 Wrapper。通常一个 Servlet class 对应一个 Wrapper，如果有多个 Servlet 就可以定义多个 Wrapper，如果有多个 Wrapper 就要定义一个更高的 Container 了，如 Context</p><h2 id="Nginx和apache的优点"><a href="#Nginx和apache的优点" class="headerlink" title="Nginx和apache的优点"></a>Nginx和apache的优点</h2><p>轻量级，同样起web 服务，比apache占用更少的内存及资源 抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能高度模块化的设计，编写模块相对简单提供负载均衡</p><p>社区活跃，各种高性能模块出品迅速</p><p>但是Nginx只适合做静态页面和反向，一般用于负载均衡。</p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列2: JSP与Servlet</title>
      <link href="/2020/02/04/javaweb-xi-lie-2-jsp-yu-servlet/"/>
      <url>/2020/02/04/javaweb-xi-lie-2-jsp-yu-servlet/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列2-JSP与Servlet"><a href="#JavaWeb系列2-JSP与Servlet" class="headerlink" title="JavaWeb系列2: JSP与Servlet"></a>JavaWeb系列2: JSP与Servlet</h1><p>本文是作者的读博客笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是JSP和Servlet"><a href="#什么是JSP和Servlet" class="headerlink" title="什么是JSP和Servlet"></a>什么是JSP和Servlet</h2><p>servlet:使得java可以通过HttpServletResponse对象输出HTML的内容.<br>JSP:JavaServer Pages,在静态的HTML内容中嵌入Java代码,执行后动态生成HTML的内容</p><h2 id="各自缺点"><a href="#各自缺点" class="headerlink" title="各自缺点"></a>各自缺点</h2><p>JSP:HTML中混入大量业务逻辑,隔离性不好<br>Servlet:java生成html,可读性很差.</p><h2 id="改良-MVC"><a href="#改良-MVC" class="headerlink" title="改良:MVC"></a>改良:MVC</h2><p>MVC模式，是Model-View-Controller的简称，是软件工程中的一种软件架构模式，分为三个基本部分，分别是：模型（Model）、视图（View）和控制器（Controller）：</p><p>Controller——负责转发请求，对请求进行处理</p><p>View——负责界面显示</p><p>Model——业务功能编写（例如算法实现）、数据库设计以及数据存取操作实现</p><p>1、Web浏览器发送HTTP请求到服务端，然后被Controller(Servlet)获取并进行处理（例如参数解析、请求转发）</p><p>2、Controller(Servlet)调用核心业务逻辑——Model部分，获得结果</p><p>3、Controller(Servlet)将逻辑处理结果交给View（JSP），动态输出HTML内容</p><p>4、动态生成的HTML内容返回到浏览器显示</p><h2 id="Servlet详解"><a href="#Servlet详解" class="headerlink" title="Servlet详解"></a>Servlet详解</h2><p>Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。</p><p>使用 Servlet，您可以收集来自网页表单的用户输入，呈现来自数据库或者其他源的记录，还可以动态创建网页。</p><h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>1、Servlet 通过调用 init () 方法进行初始化。<br>2、Servlet 调用 service() 方法来处理客户端的请求。<br>3、Servlet 通过调用 destroy() 方法终止（结束）。<br>4、最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。</p><h2 id="经典面试题"><a href="#经典面试题" class="headerlink" title="经典面试题"></a>经典面试题</h2><p>1,不同的用户同时对同一个业务（如注册）发出请求，那这个时候容器里产生的有是几个servlet实例呢？<br>只有一个实例,同一个业务共享一个第一次被访问的时候创建的实例,但是不同业务不同的实例.</p><p>2,Servlet单实例多线程机制：<br>Servlet采用多线程来处理多个请求同时访问。servlet依赖于一个线程池来服务请求。线程池实际上是一系列的工作者线程集合。Servlet使用一个调度线程来管理工作者线程。</p><p>当容器收到一个Servlet请求，调度线程从线程池中选出一个工作者线程,将请求传递给该工作者线程，然后由该线程来执行Servlet的service方法。</p><p>当这个线程正在执行的时候,容器收到另外一个请求,调度线程同样从线程池中选出另一个工作者线程来服务新的请求,容器并不关心这个请求是否访问的是同一个Servlet.当容器同时收到对同一个Servlet的多个请求的时候，那么这个Servlet的service()方法将在多线程中并发执行。</p><p>Servlet容器默认采用单实例多线程的方式来处理请求，这样减少产生Servlet实例的开销，提升了对请求的响应时间，对于Tomcat可以在server.xml中通过元素设置线程池中线程的数目。</p><p>3,如何解决线程安全问题<br>实现SingleThreadModel接口</p><pre><code>Public class Concurrent Test extends HttpServlet implements SingleThreadModel { ………… }  </code></pre>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> Servlet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaWeb系列1: 连接池</title>
      <link href="/2020/02/02/javaweb-xi-lie-1-lian-jie-chi/"/>
      <url>/2020/02/02/javaweb-xi-lie-1-lian-jie-chi/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaWeb系列1-连接池"><a href="#JavaWeb系列1-连接池" class="headerlink" title="JavaWeb系列1: 连接池"></a>JavaWeb系列1: 连接池</h1><p>本文是作者的读博客笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="连接池"><a href="#连接池" class="headerlink" title="连接池"></a>连接池</h2><p>连接池技术的核心是通过减少对于连接创建和关闭来提升性能,从而便利用户复用.<br>本质是一个容器,存放创建好的线程、http连接、数据库连接、netty连接等.<br>构建连接池分为3步;<br>1,初始化连接池，根据设置相应参数，连接池大小、核心线程数、核心连接数等参数，初始化创建数据库、http、netty连接以及jdk线程。<br>2,连接池使用,前边初始化好的连接池、线程池，直接从连接池、线程中取出资源即可进行使用，使用完后要记得交还连接池、线程池，通过池容器来对资源进行管理。<br>3,连接池、线程池来维护连接、线程状态，不可用连接、线程进行销毁，正在使用连接、线程进行状态标注，连接、线程不够后并且少于设置最大连接、线程数，要进行新连接、线程创建。</p><p>连接池主要应对复杂的数据库应用,避免对于连接的使用构成了系统性能的瓶颈.</p><h2 id="连接池的实现"><a href="#连接池的实现" class="headerlink" title="连接池的实现"></a>连接池的实现</h2><p>数据库连接池的基本原理是在内部对象池中维护一定数量的数据库连接，并对外暴露数据库连接获取和返回方法。<br>外部使用者可通过 getConnection 方法获取连接，使用完毕后再通过 close 方法将连接返回，注意此时连接并没有关闭，而是由连接池管理器回收，并为下一次使用做好准备。<br>Java 中有一个 DataSource 接口, 数据库连接池就是 DataSource 的一个实现</p><h2 id="为什么要使用连接池"><a href="#为什么要使用连接池" class="headerlink" title="为什么要使用连接池"></a>为什么要使用连接池</h2><p>一个简单的程序的连接操作:<br>主程序中建立连接-curd-close连接<br>缺点:<br>1,普通的JDBC数据库连接使用 DriverManager 来获取，每次向数据库建立连接的时候都要将 Connection 加载到内存中，再验证用户名和密码(得花费0.05s～1s的时间)。需要数据库连接的时候，就向数据库要求一个，执行完成后再断开连接。这样的方式将会消耗大量的资源和时间。数据库的连接资源并没有得到很好的重复利用.若同时有几百人甚至几千人在线，频繁的进行数据库连接操作将占用很多的系统资源，严重的甚至会造成服务器的崩溃。<br>2,对于每一次数据库连接，使用完后都得断开。否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将导致重启数据库。<br>3,这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。</p><h2 id="数据库连接池的使用"><a href="#数据库连接池的使用" class="headerlink" title="数据库连接池的使用"></a>数据库连接池的使用</h2><p>数据库连接池的基本思想就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。<br>数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。</p>]]></content>
      
      
      <categories>
          
          <category> JavaWeb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaWeb </tag>
            
            <tag> 连接池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列19: Java序列化和反序列化</title>
      <link href="/2019/12/08/java-ji-chu-xi-lie-19-java-xu-lie-hua-he-fan-xu-lie-hua/"/>
      <url>/2019/12/08/java-ji-chu-xi-lie-19-java-xu-lie-hua-he-fan-xu-lie-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列19-Java序列化和反序列化"><a href="#Java基础系列19-Java序列化和反序列化" class="headerlink" title="Java基础系列19: Java序列化和反序列化"></a>Java基础系列19: Java序列化和反序列化</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是序列化"><a href="#什么是序列化" class="headerlink" title="什么是序列化"></a>什么是序列化</h2><p>对象序列化在java中代表把一个对象转换成一个字节数组存储起来.</p><h2 id="如何实现序列化"><a href="#如何实现序列化" class="headerlink" title="如何实现序列化"></a>如何实现序列化</h2><p>类通过实现 java.io.Serializable 接口以启用其序列化功能。<br>注意内部类是不能序列化的,因为依赖于外部类.<br>以及静态变量也不属于对象的状态,属于类的状态,所以也不保存.</p><h2 id="总结部分"><a href="#总结部分" class="headerlink" title="总结部分:"></a>总结部分:</h2><p>1、如果一个类想被序列化，需要实现Serializable接口。否则将抛出NotSerializableException异常，这是因为，在序列化操作过程中会对类型进行检查，要求被序列化的类必须属于Enum、Array和Serializable类型其中的任何一种。</p><p>2、通过ObjectOutputStream和ObjectInputStream对对象进行序列化及反序列化</p><p>3、虚拟机是否允许反序列化，不仅取决于类路径和功能代码是否一致，一个非常重要的一点是两个类的序列化 ID 是否一致（就是 private static final long serialVersionUID）</p><p>序列化 ID 在 Eclipse 下提供了两种生成策略，一个是固定的 1L，一个是随机生成一个不重复的 long 类型数据（实际上是使用 JDK 工具生成），在这里有一个建议，如果没有特殊需求，就是用默认的 1L 就可以，这样可以确保代码一致时反序列化成功。那么随机生成的序列化 ID 有什么作用呢，有些时候，通过改变序列化 ID 可以用来限制某些用户的使用。</p><p>4、序列化并不保存静态变量。</p><p>5、要想将父类对象也序列化，就需要让父类也实现Serializable 接口。</p><p>6、Transient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。</p><p>7、服务器端给客户端发送序列化对象数据，对象中有一些数据是敏感的，比如密码字符串等，希望对该密码字段在序列化时，进行加密，而客户端如果拥有解密的密钥，只有在客户端进行反序列化时，才可以对密码进行读取，这样可以一定程度保证序列化对象的数据安全。</p><p>8、在类中增加writeObject 和 readObject 方法可以实现自定义序列化策略</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列18: Java8新特性</title>
      <link href="/2019/12/06/java-ji-chu-xi-lie-18-java8-xin-te-xing/"/>
      <url>/2019/12/06/java-ji-chu-xi-lie-18-java8-xin-te-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列18-Java8新特性"><a href="#Java基础系列18-Java8新特性" class="headerlink" title="Java基础系列18: Java8新特性"></a>Java基础系列18: Java8新特性</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="Lambad表达式"><a href="#Lambad表达式" class="headerlink" title="Lambad表达式"></a>Lambad表达式</h2><p>在最简单的形式中，一个lambda可以由用逗号分隔的参数列表、–&gt;符号与函数体三部分表示<br>eg：</p><pre><code>Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( e -&gt; System.out.println( e ) );</code></pre><p>注意e的类型可以不写,编译器会自动推测是什么类型</p><p>当然也可以把单句指令写成大括号包含的函数体</p><pre><code>Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( e -&gt; {    System.out.print( e );    System.out.print( e );} );</code></pre><p>注意lambda引用的变量会被转为final</p><p>也可以返回值,返回值类型也是编译器自动推断的</p><p>一种特殊的注解:@FunctionalInterface,使得这个类或者方法支持lambda表达式</p><h2 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h2><p>使用::操作符<br>直接上例子:</p><pre><code>Function&lt;String, Integer&gt; stringToInteger = (String s) -&gt; Integer.parseInt(s);有了方法引用之后:Function&lt;String, Integer&gt; stringToInteger = Integer::parseInt;</code></pre><p>如果是引用构造函数,可以使用new关键字:<br>Supplier<someclass> c1 = SomeClass::new;<br>SomeClass s1 = c1.get();</someclass></p><h2 id="拓展方法"><a href="#拓展方法" class="headerlink" title="拓展方法"></a>拓展方法</h2><p>可以使用default方法来给接口增加非抽象的方法实现.</p><h2 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h2><p>在java.utli.stream里面<br>举例分析:<br>首先定义一个集合:</p><pre><code>final Collection&lt; Task &gt; tasks = Arrays.asList(    new Task( Status.OPEN, 5 ),    new Task( Status.OPEN, 13 ),    new Task( Status.CLOSED, 8 ) );</code></pre><p>然后使用steam来寻找所有状态为open的任务的分数和:</p><pre><code>final long totalPointsOfOpenTasks = tasks    .stream()    .filter( task -&gt; task.getStatus() == Status.OPEN )    .mapToInt( Task::getPoints )    .sum();System.out.println( &quot;Total points: &quot; + totalPointsOfOpenTasks );</code></pre><p>一个很有价值的点在于stream是支持并行的<br>还是上面那个例子,这次使用并行计算来解决:</p><pre><code>// Calculate total points of all tasksfinal double totalPoints = tasks   .stream()   .parallel()   .map( task -&gt; task.getPoints() ) // or map( Task::getPoints )    .reduce( 0, Integer::sum );System.out.println( &quot;Total points (all tasks): &quot; + totalPoints );</code></pre><p>再看一个例子,按照某个准则进行分组:</p><pre><code>// Group tasks by their statusfinal Map&lt; Status, List&lt; Task &gt; &gt; map = tasks    .stream()    .collect( Collectors.groupingBy( Task::getStatus ) );System.out.println( map );</code></pre><h2 id="Date和time"><a href="#Date和time" class="headerlink" title="Date和time"></a>Date和time</h2><p>主要用duration类:<br>看一个例子:</p><pre><code>// Get duration between two datesfinal LocalDateTime from = LocalDateTime.of( 2014, Month.APRIL, 16, 0, 0, 0 );final LocalDateTime to = LocalDateTime.of( 2015, Month.APRIL, 16, 23, 59, 59 );final Duration duration = Duration.between( from, to );System.out.println( &quot;Duration in days: &quot; + duration.toDays() );System.out.println( &quot;Duration in hours: &quot; + duration.toHours() );</code></pre><h2 id="CompletableFuture"><a href="#CompletableFuture" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h2><p>CompletableFuture也是实现了Future接口， 并且基于ForkJoinPool来执行任务，因此本质上来讲，CompletableFuture只是对原有API的封装， 而使用CompletableFuture与原来的Future的不同之处在于可以将两个Future组合起来，或者如果两个Future是有依赖关系的，可以等第一个执行完毕后再实行第二个等特性</p><pre><code>public Future&lt;Double&gt; getPriceAsync(final String product) {    final CompletableFuture&lt;Double&gt; futurePrice = new CompletableFuture&lt;&gt;();    new Thread(() -&gt; {        double price = calculatePrice(product);        futurePrice.complete(price);  //完成后使用complete方法，设置future的返回值    }).start();    return futurePrice;}等价于:Fufure price = CompletableFuture.supplyAsync(() -&gt; calculatePrice(product));如果第二个请求依赖于第一个请求的结果，那么可以使用thenCompose方法来组合两个Future;public List&lt;String&gt; findPriceAsync(String product) {    List&lt;CompletableFutute&lt;String&gt;&gt; priceFutures = tasks.stream()    .map(task -&gt; CompletableFuture.supplyAsync(() -&gt; task.getPrice(product),executor))    .map(future -&gt; future.thenApply(Work::parse))    .map(future -&gt; future.thenCompose(work -&gt; CompletableFuture.supplyAsync(() -&gt; Count.applyCount(work), executor)))    .collect(Collectors.toList());    return priceFutures.stream().map(CompletableFuture::join).collect(Collectors.toList());}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列17: 集合类</title>
      <link href="/2019/12/04/java-ji-chu-xi-lie-17-ji-he-lei/"/>
      <url>/2019/12/04/java-ji-chu-xi-lie-17-ji-he-lei/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列17-集合类"><a href="#Java基础系列17-集合类" class="headerlink" title="Java基础系列17: 集合类"></a>Java基础系列17: 集合类</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="Collection接口"><a href="#Collection接口" class="headerlink" title="Collection接口"></a>Collection接口</h2><p>最基本的集合接口,并不提供类的实现,有List和Set两个子接口</p><p>在Java中所有实现了Collection接口的类都必须提供两套标准的构造函数，一个是无参，用于创建一个空的Collection，一个是带有Collection参数的有参构造函数，用于创建一个新的Collection，这个新的Collection与传入进来的Collection具备相同的元素。</p><h2 id="List接口"><a href="#List接口" class="headerlink" title="List接口"></a>List接口</h2><p>List代表的是有序的,以某种特定的插入顺序来维护元素顺序,根据整数索引来搜索和访问元素.</p><h3 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h3><p>这是一个动态数组,有add,size,get,set,isEmpty,iterator等方法.适合随机访问,同时是非同步的.</p><h3 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h3><p>这是一个双向链表,提供了get,remove,insert等方法.<br>强行索引的话会从近的一端开始遍历,插入是O(1),查询O(n)</p><p>也是不同步的,一种可行的解决方法:</p><pre><code>List list = Collections.synchronizedList(new LinkedList(…));</code></pre><h3 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h3><p>和ArrayList几乎一样,但是是同步的,所以效率低.</p><h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><p>Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置(O(n))。Stack刚创建后是空栈。。</p><h2 id="Set接口"><a href="#Set接口" class="headerlink" title="Set接口"></a>Set接口</h2><p>不可随机访问，维持自己的内部排序</p><h2 id="Map接口"><a href="#Map接口" class="headerlink" title="Map接口"></a>Map接口</h2><p>元素都是键值对</p><p>以下部分引用自<a href="https://how2playlife.com/2019/09/19/19%E3%80%81Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%A2%B3%E7%90%86/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/19/19%E3%80%81Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%A2%B3%E7%90%86/</a>, 背熟就完事了.</p><h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><h2 id="ArrayList-1"><a href="#ArrayList-1" class="headerlink" title="ArrayList"></a>ArrayList</h2><p>以数组实现。节约空间，但数组有容量限制。超出限制时会增加50%容量，用System.arraycopy（）复制到新的数组。因此最好能给出数组大小的预估值。默认第一次插入元素时创建大小为10的数组。</p><p>按数组下标访问元素－get（i）、set（i,e） 的性能很高，这是数组的基本优势。</p><p>如果按下标插入元素、删除元素－add（i,e）、 remove（i）、remove（e），则要用System.arraycopy（）来复制移动部分受影响的元素，性能就变差了。</p><p>越是前面的元素，修改时要移动的元素越多。直接在数组末尾加入元素－常用的add（e），删除最后一个元素则无影响。</p><h2 id="LinkedList-1"><a href="#LinkedList-1" class="headerlink" title="LinkedList"></a>LinkedList</h2><p>以双向链表实现。链表无容量限制，但双向链表本身使用了更多空间，每插入一个元素都要构造一个额外的Node对象，也需要额外的链表指针操作。</p><p>按下标访问元素－get（i）、set（i,e） 要悲剧的部分遍历链表将指针移动到位 （如果i&gt;数组大小的一半，会从末尾移起）。</p><p>插入、删除元素时修改前后节点的指针即可，不再需要复制移动。但还是要部分遍历链表的指针才能移动到下标所指的位置。</p><p>只有在链表两头的操作－add（）、addFirst（）、removeLast（）或用iterator（）上的remove（）倒能省掉指针的移动。</p><p>Apache Commons 有个TreeNodeList，里面是棵二叉树，可以快速移动指针到位。</p><h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h2><p>并发优化的ArrayList。基于不可变对象策略，在修改时先复制出一个数组快照来修改，改好了，再让内部指针指向新数组。</p><p>因为对快照的修改对读操作来说不可见，所以读读之间不互斥，读写之间也不互斥，只有写写之间要加锁互斥。但复制快照的成本昂贵，典型的适合读多写少的场景。</p><p>虽然增加了addIfAbsent（e）方法，会遍历数组来检查元素是否已存在，性能可想像的不会太好。</p><h2 id="遗憾"><a href="#遗憾" class="headerlink" title="遗憾"></a>遗憾</h2><p>无论哪种实现，按值返回下标contains（e）, indexOf（e）, remove（e） 都需遍历所有元素进行比较，性能可想像的不会太好。</p><p>没有按元素值排序的SortedList。</p><p>除了CopyOnWriteArrayList，再没有其他线程安全又并发优化的实现如ConcurrentLinkedList。凑合着用Set与Queue中的等价类时，会缺少一些List特有的方法如get（i）。如果更新频率较高，或数组较大时，还是得用Collections.synchronizedList（list），对所有操作用同一把锁来保证线程安全。</p><h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><p>以Entry[]数组实现的哈希桶数组，用Key的哈希值取模桶数组的大小可得到数组下标。</p><p>插入元素时，如果两条Key落在同一个桶（比如哈希值1和17取模16后都属于第一个哈希桶），我们称之为哈希冲突。</p><p>JDK的做法是链表法，Entry用一个next属性实现多个Entry以单向链表存放。查找哈希值为17的key时，先定位到哈希桶，然后链表遍历桶里所有元素，逐个比较其Hash值然后key值。</p><p>在JDK8里，新增默认为8的阈值，当一个桶里的Entry超过閥值，就不以单向链表而以红黑树来存放以加快Key的查找速度。</p><p>当然，最好还是桶里只有一个元素，不用去比较。所以默认当Entry数量达到桶数量的75%时，哈希冲突已比较严重，就会成倍扩容桶数组，并重新分配所有原来的Entry。扩容成本不低，所以也最好有个预估值。</p><p>取模用与操作（hash &amp; （arrayLength-1））会比较快，所以数组的大小永远是2的N次方， 你随便给一个初始值比如17会转为32。默认第一次放入元素时的初始值是16。</p><p>iterator（）时顺着哈希桶数组来遍历，看起来是个乱序。</p><h2 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h2><p>扩展HashMap，每个Entry增加双向链表，号称是最占内存的数据结构。</p><p>支持iterator（）时按Entry的插入顺序来排序（如果设置accessOrder属性为true，则所有读写访问都排序）。</p><p>插入时，Entry把自己加到Header Entry的前面去。如果所有读写访问都要排序，还要把前后Entry的before/after拼接起来以在链表中删除掉自己，所以此时读操作也是线程不安全的了。</p><h2 id="TreeMap"><a href="#TreeMap" class="headerlink" title="TreeMap"></a>TreeMap</h2><p>以红黑树实现，红黑树又叫自平衡二叉树：</p><p>对于任一节点而言，其到叶节点的每一条路径都包含相同数目的黑结点。<br>上面的规定，使得树的层数不会差的太远，使得所有操作的复杂度不超过 O（lgn），但也使得插入，修改时要复杂的左旋右旋来保持树的平衡。</p><p>支持iterator（）时按Key值排序，可按实现了Comparable接口的Key的升序排序，或由传入的Comparator控制。可想象的，在树上插入/删除元素的代价一定比HashMap的大。</p><p>支持SortedMap接口，如firstKey（），lastKey（）取得最大最小的key，或sub（fromKey, toKey）, tailMap（fromKey）剪取Map的某一段。</p><h2 id="EnumMap"><a href="#EnumMap" class="headerlink" title="EnumMap"></a>EnumMap</h2><p>EnumMap的原理是，在构造函数里要传入枚举类，那它就构建一个与枚举的所有值等大的数组，按Enum. ordinal（）下标来访问数组。性能与内存占用俱佳。</p><p>美中不足的是，因为要实现Map接口，而 V get（Object key）中key是Object而不是泛型K，所以安全起见，EnumMap每次访问都要先对Key进行类型判断，在JMC里录得不低的采样命中频率。</p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>并发优化的HashMap。</p><p>在JDK5里的经典设计，默认16把写锁（可以设置更多），有效分散了阻塞的概率。数据结构为Segment[]，每个Segment一把锁。Segment里面才是哈希桶数组。Key先算出它在哪个Segment里，再去算它在哪个哈希桶里。</p><p>也没有读锁，因为put/remove动作是个原子动作（比如put的整个过程是一个对数组元素/Entry 指针的赋值操作），读操作不会看到一个更新动作的中间状态。</p><p>但在JDK8里，Segment[]的设计被抛弃了，改为精心设计的，只在需要锁的时候加锁。</p><p>支持ConcurrentMap接口，如putIfAbsent（key，value）与相反的replace（key，value）与以及实现CAS的replace（key, oldValue, newValue）。</p><h3 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h3><p>指的是比较并替换,compare and swap<br>CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。<br>想把V和A对比,如果相同就换为B,否则就什么都不做.<br>这是个原子操作.</p><p>主要有3个缺点:<br>循环时间长开销很大：<br>我们可以看到getAndAddInt方法执行时，如果CAS失败，会一直进行尝试。如果CAS长时间一直不成功，可能会给CPU带来很大的开销。</p><p>只能保证一个共享变量的原子操作<br>：当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性。</p><p>什么是ABA问题？ABA问题怎么解决？</p><p>如果内存地址V初次读取的值是A，并且在准备赋值的时候检查到它的值仍然为A，那我们就能说它的值没有被其他线程改变过了吗？<br>如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。Java并发包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。因此，在使用CAS前要考虑清楚“ABA”问题是否会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。</p><h2 id="ConcurrentSkipListMap"><a href="#ConcurrentSkipListMap" class="headerlink" title="ConcurrentSkipListMap"></a>ConcurrentSkipListMap</h2><p>JDK6新增的并发优化的SortedMap，以SkipList结构实现。Concurrent包选用它是因为它支持基于CAS的无锁算法，而红黑树则没有好的无锁算法。</p><p>原理上，可以想象为多个链表组成的N层楼，其中的元素从稀疏到密集，每个元素有往右与往下的指针。从第一层楼开始遍历，如果右端的值比期望的大，那就往下走一层，继续往前走。</p><p>典型的空间换时间。每次插入，都要决定在哪几层插入，同时，要决定要不要多盖一层楼。</p><p>它的size（）同样不能随便调，会遍历来统计。</p><h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><p>所有Set几乎都是内部用一个Map来实现, 因为Map里的KeySet就是一个Set，而value是假值，全部使用同一个Object即可。</p><p>Set的特征也继承了那些内部的Map实现的特征。</p><p>HashSet：内部是HashMap。</p><p>LinkedHashSet：内部是LinkedHashMap。</p><p>TreeSet：内部是TreeMap的SortedSet。</p><p>ConcurrentSkipListSet：内部是ConcurrentSkipListMap的并发优化的SortedSet。</p><p>CopyOnWriteArraySet：内部是CopyOnWriteArrayList的并发优化的Set，利用其addIfAbsent（）方法实现元素去重，如前所述该方法的性能很一般。</p><p>好像少了个ConcurrentHashSet，本来也该有一个内部用ConcurrentHashMap的简单实现，但JDK偏偏没提供。Jetty就自己简单封了一个，Guava则直接用java.util.Collections.newSetFromMap（new ConcurrentHashMap（）） 实现。</p><h1 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h1><p>Queue是在两端出入的List，所以也可以用数组或链表来实现。</p><h2 id="普通队列"><a href="#普通队列" class="headerlink" title="普通队列"></a>普通队列</h2><p>LinkedList<br>是的，以双向链表实现的LinkedList既是List，也是Queue。</p><p>ArrayDeque<br>以循环数组实现的双向Queue。大小是2的倍数，默认是16。</p><p>为了支持FIFO，即从数组尾压入元素（快），从数组头取出元素（超慢），就不能再使用普通ArrayList的实现了，改为使用循环数组。</p><p>有队头队尾两个下标：弹出元素时，队头下标递增；加入元素时，队尾下标递增。如果加入元素时已到数组空间的末尾，则将元素赋值到数组[0]，同时队尾下标指向0，再插入下一个元素则赋值到数组[1]，队尾下标指向1。如果队尾的下标追上队头，说明数组所有空间已用完，进行双倍的数组扩容。</p><p>PriorityQueue<br>用平衡二叉最小堆实现的优先级队列，不再是FIFO，而是按元素实现的Comparable接口或传入Comparator的比较结果来出队，数值越小，优先级越高，越先出队。但是注意其iterator（）的返回不会排序。</p><p>平衡最小二叉堆，用一个简单的数组即可表达，可以快速寻址，没有指针什么的。最小的在queue[0] ，比如queue[4]的两个孩子，会在queue[24+1] 和 queue[2（4+1）]，即queue[9]和queue[10]。</p><p>入队时，插入queue[size]，然后二叉地往上比较调整堆。</p><p>出队时，弹出queue[0]，然后把queque[size]拿出来二叉地往下比较调整堆。</p><p>初始大小为11，空间不够时自动50%扩容。</p><h2 id="线程安全队列"><a href="#线程安全队列" class="headerlink" title="线程安全队列"></a>线程安全队列</h2><p>ConcurrentLinkedQueue/Deque<br>无界的并发优化的Queue，基于链表，实现了依赖于CAS的无锁算法。</p><p>ConcurrentLinkedQueue的结构是单向链表和head/tail两个指针，因为入队时需要修改队尾元素的next指针，以及修改tail指向新入队的元素两个CAS动作无法原子，所以需要的特殊的算法。</p><h2 id="线程安全的阻塞队列"><a href="#线程安全的阻塞队列" class="headerlink" title="线程安全的阻塞队列"></a>线程安全的阻塞队列</h2><p>BlockingQueue，一来如果队列已空不用重复的查看是否有新数据而会阻塞在那里，二来队列的长度受限，用以保证生产者与消费者的速度不会相差太远。当入队时队列已满，或出队时队列已空，不同函数的效果见下表</p><p>ArrayBlockingQueue<br>定长的并发优化的BlockingQueue，也是基于循环数组实现。有一把公共的锁与notFull、notEmpty两个Condition管理队列满或空时的阻塞状态。</p><p>LinkedBlockingQueue/Deque<br>可选定长的并发优化的BlockingQueue，基于链表实现，所以可以把长度设为Integer.MAX_VALUE成为无界无等待的。</p><p>利用链表的特征，分离了takeLock与putLock两把锁，继续用notEmpty、notFull管理队列满或空时的阻塞状态。</p><p>PriorityBlockingQueue<br>无界的PriorityQueue，也是基于数组存储的二叉堆（见前）。一把公共的锁实现线程安全。因为无界，空间不够时会自动扩容，所以入列时不会锁，出列为空时才会锁。</p><p>DelayQueue<br>内部包含一个PriorityQueue，同样是无界的，同样是出列时才会锁。一把公共的锁实现线程安全。元素需实现Delayed接口，每次调用时需返回当前离触发时间还有多久，小于0表示该触发了。</p><p>pull（）时会用peek（）查看队头的元素，检查是否到达触发时间。ScheduledThreadPoolExecutor用了类似的结构。</p><h2 id="同步队列"><a href="#同步队列" class="headerlink" title="同步队列"></a>同步队列</h2><p>SynchronousQueue同步队列本身无容量，放入元素时，比如等待元素被另一条线程的消费者取走再返回。JDK线程池里用它。</p><p>JDK7还有个LinkedTransferQueue，在普通线程安全的BlockingQueue的基础上，增加一个transfer（e） 函数，效果与SynchronousQueue一样。</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
            <tag> 集合类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列16: 内部类</title>
      <link href="/2019/12/02/java-ji-chu-xi-lie-16-nei-bu-lei/"/>
      <url>/2019/12/02/java-ji-chu-xi-lie-16-nei-bu-lei/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列16-内部类"><a href="#Java基础系列16-内部类" class="headerlink" title="Java基础系列16: 内部类"></a>Java基础系列16: 内部类</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是内部类"><a href="#什么是内部类" class="headerlink" title="什么是内部类"></a>什么是内部类</h2><p>在一个外部类的内部再定义一个类;</p><p>注意内部类有一些限制,比如不能被外界访问,如果定义为静态的就不能再访问外部类的变量.</p><p>但是内部类是可以访问外部类的所有成员变量的,包括private</p><h2 id="使用内部类的好处"><a href="#使用内部类的好处" class="headerlink" title="使用内部类的好处"></a>使用内部类的好处</h2><p>内部类可以继承自某个类,相当于提供了某种进入外围类的接口;<br>而且内部类能够独立的继承或者实现一个接口,而不用管外部类如何,也就是多重继承.</p><h2 id="静态内部类"><a href="#静态内部类" class="headerlink" title="静态内部类"></a>静态内部类</h2><p>主要的特点是不依赖于外部类,以及不能访问非静态成员变量.</p><h2 id="内部类的加载"><a href="#内部类的加载" class="headerlink" title="内部类的加载"></a>内部类的加载</h2><p>1,内部类只会在第一次使用的时候加载,不使用就不加载</p><h2 id="Java类加载的顺序"><a href="#Java类加载的顺序" class="headerlink" title="Java类加载的顺序:"></a>Java类加载的顺序:</h2><p>规律一、初始化构造时，先父后子；只有在父类所有都构造完后子类才被初始化</p><p>规律二、类加载先是静态、后非静态、最后是构造函数。</p><p>静态构造块、静态类属性按出现在类定义里面的先后顺序初始化，同理非静态的也是一样的，只是静态的只在加载字节码时执行一次，不管你new多少次，非静态会在new多少次就执行多少次</p><p>规律三、java中的类只有在被用到的时候才会被加载</p><p>规律四、java类只有在类字节码被加载后才可以被构造成对象实例</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列15: 多线程</title>
      <link href="/2019/11/30/java-ji-chu-xi-lie-15-duo-xian-cheng/"/>
      <url>/2019/11/30/java-ji-chu-xi-lie-15-duo-xian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列15-多线程"><a href="#Java基础系列15-多线程" class="headerlink" title="Java基础系列15: 多线程"></a>Java基础系列15: 多线程</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是线程"><a href="#什么是线程" class="headerlink" title="什么是线程"></a>什么是线程</h2><p>线程是一个独立执行的调用序列，同一个进程的线程在同一时刻共享一些系统资源（比如文件句柄等）也能访问同一个进程所创建的对象资源（内存资源）。java.lang.Thread对象负责统计和控制这种行为。<br>实现多线程主要是继承Thread类和实现Runable接口</p><h2 id="线程的生命周期"><a href="#线程的生命周期" class="headerlink" title="线程的生命周期"></a>线程的生命周期</h2><p>如下图,引用自:<a href="https://www.runoob.com/wp-content/uploads/2014/01/java-thread.jpg" target="_blank" rel="noopener">https://www.runoob.com/wp-content/uploads/2014/01/java-thread.jpg</a></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cucnVub29iLmNvbS93cC1jb250ZW50L3VwbG9hZHMvMjAxNC8wMS9qYXZhLXRocmVhZC5qcGc?x-oss-process=image/format,png" alt></p><ul><li>新建状态:使用new关键字创建一个Thread或者其子类的对象之后,就处于这个状态,直到start()</li><li>就绪状态:start之后</li><li>运行状态:CPU调用之后执行run()方法</li><li>阻塞状态:执行了sleep或者suspend方法,可能是因为等待阻塞wait方法,或者是synchronized同步锁被占用,或者是sleep/join发出了阻塞请求</li><li>运行完毕之后就进入终止状态</li></ul><h2 id="多线程的实现"><a href="#多线程的实现" class="headerlink" title="多线程的实现"></a>多线程的实现</h2><p>例子代码来源于:<a href="https://how2playlife.com/2019/09/17/17%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/17/17%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B/</a><br>分别实现两个子类继承自Thread/实现Runnable接口,注意及时是继承了Runnable接口的类也要用Thread包装之后才能运行</p><pre><code>//继承thread@Testpublic void test1() {    class A extends Thread {        @Override        public void run() {            System.out.println(&quot;A run&quot;);        }    }    A a = new A();    a.start();}//实现Runnable@Testpublic void test2() {    class B implements Runnable {        @Override        public void run() {            System.out.println(&quot;B run&quot;);        }    }    B b = new B();    //Runable实现类需要由Thread类包装后才能执行    new Thread(b).start();}//有返回值的线程@Testpublic void test3() {    Callable callable = new Callable() {        int sum = 0;        @Override        public Object call() throws Exception {            for (int i = 0;i &lt; 5;i ++) {                sum += i;            }            return sum;        }    };    //这里要用FutureTask，否则不能加入Thread构造方法    FutureTask futureTask = new FutureTask(callable);    new Thread(futureTask).start();    try {        System.out.println(futureTask.get());    } catch (InterruptedException e) {        e.printStackTrace();    } catch (ExecutionException e) {        e.printStackTrace();    }}//线程池实现@Testpublic void test4() {    ExecutorService executorService = Executors.newFixedThreadPool(5);    //execute直接执行线程    executorService.execute(new Thread());    executorService.execute(new Runnable() {        @Override        public void run() {            System.out.println(&quot;runnable&quot;);        }    });    //submit提交有返回结果的任务，运行完后返回结果。    Future future = executorService.submit(new Callable&lt;String&gt;() {        @Override        public String call() throws Exception {            return &quot;a&quot;;        }    });    try {        System.out.println(future.get());    } catch (InterruptedException e) {        e.printStackTrace();    } catch (ExecutionException e) {        e.printStackTrace();    }    ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();    //有返回值的线程组将返回值存进集合    for (int i = 0;i &lt; 5;i ++ ) {        int finalI = i;        Future future1 = executorService.submit(new Callable&lt;String&gt;() {            @Override            public String call() throws Exception {                return &quot;res&quot; + finalI;            }        });        try {            list.add((String) future1.get());        } catch (InterruptedException e) {            e.printStackTrace();        } catch (ExecutionException e) {            e.printStackTrace();        }    }    for (String s : list) {        System.out.println(s);    }}</code></pre><p>这里主要是要提示一下使用callable,要先声明一个callable对象,再声明一个FutureTask对象,最后用Thread包装一下才能运行.<br>获取结果要用futureTake.get来获得</p><h2 id="线程状态的切换"><a href="#线程状态的切换" class="headerlink" title="线程状态的切换"></a>线程状态的切换</h2><p>同样是直接上例子</p><pre><code>public class 线程的状态转换 {//一开始线程是init状态，结束时是terminated状态class t implements Runnable {    private String name;    public t(String name) {        this.name = name;    }    @Override    public void run() {        System.out.println(name + &quot;run&quot;);    }}//测试join，父线程在子线程运行时进入waiting状态@Testpublic void test1() throws InterruptedException {    Thread dad = new Thread(new Runnable() {        Thread son = new Thread(new t(&quot;son&quot;));        @Override        public void run() {            System.out.println(&quot;dad init&quot;);            son.start();            try {                //保证子线程运行完再运行父线程,join非常重要                son.join();                System.out.println(&quot;dad run&quot;);            } catch (InterruptedException e) {                e.printStackTrace();            }        }    });    //调用start，线程进入runnable状态，等待系统调度    dad.start();    //在父线程中对子线程实例使用join，保证子线程在父线程之前执行完}//测试sleep@Testpublic void test2(){    Thread t1 = new Thread(new Runnable() {        @Override        public void run() {            System.out.println(&quot;t1 run&quot;);            try {                Thread.sleep(3000);            } catch (InterruptedException e) {                e.printStackTrace();            }        }    });    //主线程休眠。进入time waiting状态    try {        Thread.sleep(3000);    } catch (InterruptedException e) {        e.printStackTrace();    }    t1.start();}//线程2进入blocked状态。public static void main(String[] args) {    test4();    Thread.yield();//进入runnable状态}//测试blocked状态public static void test4() {    class A {        //线程1获得实例锁以后线程2无法获得实例锁，所以进入blocked状态        synchronized void run() {            while (true) {                System.out.println(&quot;run&quot;);            }        }    }    A a = new A();    new Thread(new Runnable() {        @Override        public void run() {            System.out.println(&quot;t1 get lock&quot;);            a.run();        }    }).start();    new Thread(new Runnable() {        @Override        public void run() {            System.out.println(&quot;t2 get lock&quot;);            a.run();        }    }).start();}//volatile保证线程可见性volatile static int flag = 1;//object作为锁对象，用于线程使用wait和notify方法volatile static Object o = new Object();//测试wait和notify//wait后进入waiting状态，被notify进入blocked（阻塞等待锁释放）或者runnable状态（获取到锁）public void test5() {    new Thread(new Runnable() {        @Override        public void run() {            //wait和notify只能在同步代码块内使用            synchronized (o) {                while (true) {                    if (flag == 0) {                        try {                            Thread.sleep(2000);                            System.out.println(&quot;thread1 wait&quot;);                            //释放锁，线程挂起进入object的等待队列，后续代码运行                            o.wait();                        } catch (InterruptedException e) {                            e.printStackTrace();                        }                    }                    System.out.println(&quot;thread1 run&quot;);                    System.out.println(&quot;notify t2&quot;);                    flag = 0;                    //通知等待队列的一个线程获取锁                    o.notify();                }            }        }    }).start();    //解释同上    new Thread(new Runnable() {        @Override        public void run() {            while (true) {                synchronized (o) {                    if (flag == 1) {                        try {                            Thread.sleep(2000);                            System.out.println(&quot;thread2 wait&quot;);                            o.wait();                        } catch (InterruptedException e) {                            e.printStackTrace();                        }                    }                    System.out.println(&quot;thread2 run&quot;);                    System.out.println(&quot;notify t1&quot;);                    flag = 1;                    o.notify();                }            }        }    }).start();}//输出结果是//    thread1 run//    notify t2//    thread1 wait//    thread2 run//    notify t1//    thread2 wait//    thread1 run//    notify t2//不断循环}</code></pre><h2 id="Java-Thread-常用方法"><a href="#Java-Thread-常用方法" class="headerlink" title="Java Thread 常用方法"></a>Java Thread 常用方法</h2><h3 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h3><p>放弃当前CPU的使用,但是保留当前运行情况</p><h3 id="interrupt"><a href="#interrupt" class="headerlink" title="interrupt"></a>interrupt</h3><p>中断当前线程执行,调用之后会清除当前线程的interrupt status</p><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>A线程调用B线程的join()方法，将会使A等待B执行，直到B线程终止。如果传入time参数，将会使A等待B执行time的时间，如果time时间到达，将会切换进A线程，继续执行A线程。</p><h2 id="线程的构造方法"><a href="#线程的构造方法" class="headerlink" title="线程的构造方法"></a>线程的构造方法</h2><p>构造方法<br>Thread类中不同的构造方法接受如下参数的不同组合：<br>一个Runnable对象，这种情况下，Thread.start方法将会调用对应Runnable对象的run方法。如果没有提供Runnable对象，那么就会立即得到一个Thread.run的默认实现。<br>一个作为线程标识名的String字符串，该标识在跟踪和调试过程中会非常有用，除此别无它用。<br>线程组（ThreadGroup），用来放置新创建的线程，如果提供的ThreadGroup不允许被访问，那么就会抛出一个SecurityException 。<br>Thread对象拥有一个守护(daemon)标识属性，这个属性无法在构造方法中被赋值，但是可以在线程启动之前设置该属性(通过setDaemon方法)。<br>当程序中所有的非守护线程都已经终止，调用setDaemon方法可能会导致虚拟机粗暴的终止线程并退出。<br>isDaemon方法能够返回该属性的值。守护状态的作用非常有限，即使是后台线程在程序退出的时候也经常需要做一些清理工作。<br>（daemon的发音为”day-mon”,这是系统编程传统的遗留，系统守护进程是一个持续运行的进程，比如打印机队列管理，它总是在系统中运行。）</p><h2 id="线程的启动"><a href="#线程的启动" class="headerlink" title="线程的启动"></a>线程的启动</h2><p>调用start方法会触发Thread实例启动一个线程并运行run方法.<br>当线程运行完之后则会终止.终止态的线程是无法被重新启动的.<br>可以调用isAlive方法来判断线程是否终止.</p><h2 id="线程的优先权"><a href="#线程的优先权" class="headerlink" title="线程的优先权"></a>线程的优先权</h2><p>引用自:<a href="https://how2playlife.com/2019/09/17/17%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/17/17%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B/</a><br>    Java的线程实现基本上都是内核级线程的实现，所以Java线程的具体执行还取决于操作系统的特性。</p><pre><code>Java虚拟机为了实现跨平台(不同的硬件平台和各种操作系统)的特性，Java语言在线程调度与调度公平性上未作出任何的承诺，甚至都不会严格保证线程会被执行。但是Java线程却支持优先级的方法，这些方法会影响线程的调度：每个线程都有一个优先级，分布在Thread.MIN_PRIORITY和Thread.MAX_PRIORITY之间（分别为1和10）默认情况下，新创建的线程都拥有和创建它的线程相同的优先级。main方法所关联的初始化线程拥有一个默认的优先级，这个优先级是Thread.NORM_PRIORITY (5).线程的当前优先级可以通过getPriority方法获得。线程的优先级可以通过setPriority方法来动态的修改，一个线程的最高优先级由其所在的线程组限定。</code></pre><h2 id="经典多线程面经"><a href="#经典多线程面经" class="headerlink" title="经典多线程面经"></a>经典多线程面经</h2><p>1,volatile关键字的作用:<br>    1）多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据。</p><pre><code>2）代码底层执行不像我们看到的高级语言—-Java程序这么简单，它的执行是Java代码–&gt;字节码–&gt;根据字节码执行对应的C/C++代码–&gt;C/C++代码被编译成汇编语言–&gt;和硬件电路交互，现实中，为了获取更好的性能JVM可能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序，当然这也一定程度上降低了代码执行效率。使用volatile有以下条件:1、对变量的写操作不依赖当前变量的值；2、该变量没有包含在其他变量的不变式中。主要是因为只有可见性,但是没有原子性,用于读多写少的情况.</code></pre><p>2,什么是线程安全<br>    如果你的代码在多线程下执行和在单线程下执行永远都能获得一样的结果，那么你的代码就是线程安全的</p><p>3,如何在线程之间共享数据<br>    1,通过共享对象<br>    2,使用阻塞队列BlockingQueue<br>4,wait和sleep的区别<br>    wait会放弃对象监视器,sleep不会<br>5,ThreadLocal方法<br>    ThreadLocal就是一种以空间换时间的做法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了<br>6,高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？<br>    高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换<br>    并发不高、任务执行时间长的业务要区分开看：</p><pre><code>    a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以加大线程池中的线程数目，让CPU处理更多的业务    b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换    c）并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考其他有关线程池的文章。最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列14: 注解</title>
      <link href="/2019/11/28/java-ji-chu-xi-lie-14-zhu-jie/"/>
      <url>/2019/11/28/java-ji-chu-xi-lie-14-zhu-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列14-注解"><a href="#Java基础系列14-注解" class="headerlink" title="Java基础系列14: 注解"></a>Java基础系列14: 注解</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是注解"><a href="#什么是注解" class="headerlink" title="什么是注解"></a>什么是注解</h2><p>引用自<a href="https://how2playlife.com/2019/09/15/15%E3%80%81Java%E6%B3%A8%E8%A7%A3%E5%92%8C%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/15/15%E3%80%81Java%E6%B3%A8%E8%A7%A3%E5%92%8C%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</a>, 的定义,注解可以用标签来进行解释.<br>相当于是提供一些元数据,起到说明和配置的功能,位于java.lang.annotation中</p><h2 id="注解的用途"><a href="#注解的用途" class="headerlink" title="注解的用途"></a>注解的用途</h2><p>1、生成文档。这是最常见的，也是java 最早提供的注解。常用的有@param @return 等<br>2、跟踪代码依赖性，实现替代配置文件功能。比如Dagger 2依赖注入，未来java开发，将大量注解配置，具有很大用处;<br>3、在编译时进行格式检查。如@override 放在方法前，如果你这个方法并不是覆盖了超类方法，则编译时就能检查出。</p><h2 id="注解的原理"><a href="#注解的原理" class="headerlink" title="注解的原理"></a>注解的原理</h2><p>注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池。</p><h2 id="元注解"><a href="#元注解" class="headerlink" title="元注解"></a>元注解</h2><p>用来定义其他注解的注解:<br>1,Documented 注解是否包含在javaDoc中<br>2,Retention 决定注解的生命周期</p><pre><code>RetentionPolicy.SOURCE : 在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。RetentionPolicy.CLASS : 在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式RetentionPolicy.RUNTIME : 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。</code></pre><p>3,Target 决定注解用于什么地方<br>● ElementType.CONSTRUCTOR:用于描述构造器<br>● ElementType.FIELD:成员变量、对象、属性（包括enum实例）<br>● ElementType.LOCAL_VARIABLE:用于描述局部变量<br>● ElementType.METHOD:用于描述方法<br>● ElementType.PACKAGE:用于描述包<br>● ElementType.PARAMETER:用于描述参数<br>● ElementType.TYPE:用于描述类、接口(包括注解类型) 或enum声明</p><pre><code>这样就限制了这个注解只能用于字段,可以传递多个变量进去从而拓展@Target(ElementType.FIELD)public @interface SimpleAnnotation {    // ...}</code></pre><p>4,Inherited 是否允许子类继承</p><h2 id="内置基础注解"><a href="#内置基础注解" class="headerlink" title="内置基础注解"></a>内置基础注解</h2><p>@Override<br>用于检验此方法是否真的是重写了父类的方法,我们就不用肉眼再去对比了.</p><p>@Deprecated<br>代表该方法已经过时,有可能在以后的升级中被慢慢淘汰</p><p>@SuppressWarning<br>可以屏蔽掉不想看到的编译时期的警告</p><p>@Functionalinterface<br>接口中只允许有一个抽象方法</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列13: 枚举</title>
      <link href="/2019/11/26/java-ji-chu-xi-lie-13-mei-ju/"/>
      <url>/2019/11/26/java-ji-chu-xi-lie-13-mei-ju/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列13-枚举"><a href="#Java基础系列13-枚举" class="headerlink" title="Java基础系列13: 枚举"></a>Java基础系列13: 枚举</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是枚举类"><a href="#什么是枚举类" class="headerlink" title="什么是枚举类"></a>什么是枚举类</h2><p>用枚举类型定义的枚举变量只能取集合中的某一元素值,且是固定的.</p><pre><code>enum weekdays 　　{ Sun,Mon,Tue,Wed,Thu,Fri,Sat };</code></pre><p>可以给上述的这些字符都进行赋值.</p><h2 id="枚举类的定义"><a href="#枚举类的定义" class="headerlink" title="枚举类的定义"></a>枚举类的定义</h2><p>1,不能继承其他父类,默认继承java.lang.Enum类<br>2,默认使用final修饰<br>3,所有实例必须在第一行给出</p><p>可以拥有实例,比如上面的sun,mon都是实例,有且仅有这几个实例.</p><p>一个例子,使用Color.values()可以获取枚举类的所有实例</p><pre><code>enum Color {    //每个颜色都是枚举类的一个实例，并且构造方法要和枚举类的格式相符合。    //如果实例后面有其他内容，实例序列结束时要加分号。    Red(&quot;红色&quot;, 1), Green(&quot;绿色&quot;, 2), Blue(&quot;蓝色&quot;, 3), Yellow(&quot;黄色&quot;, 4);    String name;    int index;    Color(String name, int index) {        this.name = name;        this.index = index;    }    public void showAllColors() {        //values是Color实例的数组，在通过index和name可以获取对应的值。        for (Color color : Color.values()) {            System.out.println(color.index + &quot;:&quot; + color.name);        }    }}</code></pre><p>调用枚举类的实例可以直接用’类名.实例名’这种方法来使用</p><h2 id="枚举类集合"><a href="#枚举类集合" class="headerlink" title="枚举类集合"></a>枚举类集合</h2><p>java.util.EnumMap下面的EnumMap的一个例子:</p><pre><code>public class 枚举类集合 {    public static void main(String[] args) {        EnumMap&lt;Color, String&gt; map = new EnumMap&lt;Color, String&gt;(Color.class);        map.put(Color.Blue, &quot;Blue&quot;);        map.put(Color.Yellow, &quot;Yellow&quot;);        map.put(Color.Red, &quot;Red&quot;);        System.out.println(map.get(Color.Red));    }}</code></pre><h2 id="枚举类构造实例"><a href="#枚举类构造实例" class="headerlink" title="枚举类构造实例:"></a>枚举类构造实例:</h2><p>代码来源于:<a href="https://how2playlife.com/2019/09/14/14%E6%9E%9A%E4%B8%BE%E7%B1%BB/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/14/14%E6%9E%9A%E4%B8%BE%E7%B1%BB/</a><br>定义只有一个参数的枚举类:</p><pre><code>enum SeasonType {    // 通过构造函数传递参数并创建实例    SPRING(&quot;spring&quot;),    SUMMER(&quot;summer&quot;),    AUTUMN(&quot;autumn&quot;),    WINTER(&quot;winter&quot;);    // 定义实例对应的参数    private String msg;    // 必写：通过此构造器给枚举值创建实例    SeasonType(String msg) {        this.msg = msg;    }    // 通过此方法可以获取到对应实例的参数值    public String getMsg() {        return msg;    }}</code></pre><p>如果有两个参数:</p><pre><code>public enum Season {    // 通过构造函数传递参数并创建实例    SPRING(1, &quot;spring&quot;),    SUMMER(2, &quot;summer&quot;),    AUTUMN(3, &quot;autumn&quot;),    WINTER(4, &quot;winter&quot;);    // 定义实例对应的参数    private Integer key;    private String msg;    // 必写：通过此构造器给枚举值创建实例    Season(Integer key, String msg) {        this.key = key;        this.msg = msg;    }    // 很多情况，我们可能从前端拿到的值是枚举类的 key ，然后就可以通过以下静态方法获取到对应枚举值    public static Season valueofKey(Integer key) {        for (Season season : Season.values()) {            if (season.key.equals(key)) {                return season;            }        }        throw new IllegalArgumentException(&quot;No element matches &quot; + key);    }    // 通过此方法可以获取到对应实例的 key 值    public Integer getKey() {        return key;    }    // 通过此方法可以获取到对应实例的 msg 值    public String getMsg() {        return msg;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列12: 泛型</title>
      <link href="/2019/11/24/java-ji-chu-xi-lie-12-fan-xing/"/>
      <url>/2019/11/24/java-ji-chu-xi-lie-12-fan-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列12-泛型"><a href="#Java基础系列12-泛型" class="headerlink" title="Java基础系列12: 泛型"></a>Java基础系列12: 泛型</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是泛型"><a href="#什么是泛型" class="headerlink" title="什么是泛型"></a>什么是泛型</h2><p>直接看例子</p><pre><code>List arrayList = new ArrayList();arrayList.add(&quot;aaaa&quot;);arrayList.add(100);for(int i = 0; i&lt; arrayList.size();i++){    String item = (String)arrayList.get(i);    Log.d(&quot;泛型测试&quot;,&quot;item = &quot; + item);}</code></pre><p>这个代码会报错,因为没有给arraylist加泛型,所以无法转换.</p><p>注意泛型是会在编译期使用,不会进入到运行期</p><h2 id="泛型类的初始化"><a href="#泛型类的初始化" class="headerlink" title="泛型类的初始化"></a>泛型类的初始化</h2><p>一个最简单的例子:</p><pre><code>//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;{    //在类中声明的泛型整个类里面都可以用，除了静态部分，因为泛型是实例化时声明的。    //静态区域的代码在编译时就已经确定，只与类相关    class A &lt;E&gt;{        T t;    }    //类里面的方法或类中再次声明同名泛型是允许的，并且该泛型会覆盖掉父类的同名泛型T    class B &lt;T&gt;{        T t;    }    //静态内部类也可以使用泛型，实例化时赋予泛型实际类型    static class C &lt;T&gt; {        T t;    }    public static void main(String[] args) {        //报错，不能使用T泛型，因为泛型T属于实例不属于类//        T t = null;    }    //key这个成员变量的类型为T,T的类型由外部指定    private T key;    public Generic(T key) { //泛型构造方法形参key的类型也为T，T的类型由外部指定        this.key = key;    }    public T getKey(){ //泛型方法getKey的返回值类型为T，T的类型由外部指定        return key;    }}</code></pre><p>一个更加具体的例子:</p><pre><code>Generic generic = new Generic(&quot;111111&quot;);Generic generic1 = new Generic(4444);Generic generic2 = new Generic(55.55);Generic generic3 = new Generic(false);Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic1.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic2.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic3.getKey());D/泛型测试: key is 111111D/泛型测试: key is 4444D/泛型测试: key is 55.55D/泛型测试: key is false</code></pre><p>需要注意的是,不允许对泛型使用instanceof操作</p><h2 id="泛型接口"><a href="#泛型接口" class="headerlink" title="泛型接口"></a>泛型接口</h2><p>常常被用于各种类的生产器中</p><pre><code>//定义一个泛型接口public interface Generator&lt;T&gt; {    public T next();}</code></pre><p>有两种使用方法:<br>当实现泛型接口的类，未传入泛型实参时：</p><pre><code>/** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;{ * 如果不声明泛型，如：class FruitGenerator implements Generator&lt;T&gt;，编译器会报错：&quot;Unknown class&quot; */class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;{    @Override    public T next() {        return null;    }}</code></pre><p>当实现泛型接口的类，传入泛型实参时：</p><pre><code>/** * 传入泛型实参时： * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口Generator&lt;T&gt; * 但是我们可以为T传入无数个实参，形成无数种类型的Generator接口。 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型 * 即：Generator&lt;T&gt;，public T next();中的的T都要替换成传入的String类型。 */public class FruitGenerator implements Generator&lt;String&gt; {    private String[] fruits = new String[]{&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;};    @Override    public String next() {        Random rand = new Random();        return fruits[rand.nextInt(3)];    }}</code></pre><h2 id="泛型通配符"><a href="#泛型通配符" class="headerlink" title="泛型通配符"></a>泛型通配符</h2><pre><code>public void showKeyValue1(Generic&lt;?&gt; obj);</code></pre><p>这里就是一个不确定是什么类型的通配符</p><h2 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h2><p>如何定义一个类型未知的方法,看下面这个例子:</p><pre><code>/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： *     1）public 与 返回值中间&lt;T&gt;非常重要，可以理解为声明此方法为泛型方法,声明T是一个泛型,可以有多个。 *     2）只有声明了&lt;T&gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 *     3）&lt;T&gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 *     4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */    public &lt;T&gt; T genericMethod(Class&lt;T&gt; tClass)throws InstantiationException ,      IllegalAccessException{            T instance = tClass.newInstance();            return instance;    }Object obj = genericMethod(Class.forName(&quot;com.test.test&quot;));</code></pre><h3 id="泛型方法和可变参数"><a href="#泛型方法和可变参数" class="headerlink" title="泛型方法和可变参数"></a>泛型方法和可变参数</h3><p>引用自<a href="https://how2playlife.com/2019/09/13/13%E6%B3%9B%E5%9E%8B/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/13/13%E6%B3%9B%E5%9E%8B/</a> , 感觉这个例子非常的好</p><pre><code>public class 泛型和可变参数 {    @Test    public void test () {        printMsg(&quot;dasd&quot;,1,&quot;dasd&quot;,2.0,false);        print(&quot;dasdas&quot;,&quot;dasdas&quot;, &quot;aa&quot;);    }    //普通可变参数只能适配一种类型    public void print(String ... args) {        for(String t : args){            System.out.println(t);        }    }    //泛型的可变参数可以匹配所有类型的参数。。有点无敌    public &lt;T&gt; void printMsg( T... args){        for(T t : args){            System.out.println(t);        }    }        //打印结果：    //dasd    //1    //dasd    //2.0    //false}</code></pre><p>注意静态方法要使用泛型的时候必须二次声明.</p><pre><code>public class StaticGenerator&lt;T&gt; {    ....    ....    /**     * 如果在类中定义使用泛型的静态方法，需要添加额外的泛型声明（将这个方法定义成泛型方法）     * 即使静态方法要使用泛型类中已经声明过的泛型也不可以。     * 如：public static void show(T t){..},此时编译器会提示错误信息：          &quot;StaticGenerator cannot be refrenced from static context&quot;     */    public static &lt;T&gt; void show(T t){    }}</code></pre><h2 id="泛型的上下界"><a href="#泛型的上下界" class="headerlink" title="泛型的上下界"></a>泛型的上下界</h2><p>比如只有Number的子类或者是Integer的父类才能传入.</p><pre><code>public class 泛型通配符与边界 {    public void showKeyValue(Generic&lt;Number&gt; obj){        System.out.println(&quot;key value is &quot; + obj.getKey());    }    @Test    public void main() {        Generic&lt;Integer&gt; gInteger = new Generic&lt;Integer&gt;(123);        Generic&lt;Number&gt; gNumber = new Generic&lt;Number&gt;(456);        showKeyValue(gNumber);        //泛型中的子类也无法作为父类引用传入//        showKeyValue(gInteger);    }    //直接使用？通配符可以接受任何类型作为泛型传入    public void showKeyValueYeah(Generic&lt;?&gt; obj) {        System.out.println(obj);    }    //只能传入number的子类或者number    public void showKeyValue1(Generic&lt;? extends Number&gt; obj){        System.out.println(obj);    }    //只能传入Integer的父类或者Integer    public void showKeyValue2(Generic&lt;? super Integer&gt; obj){        System.out.println(obj);    }    @Test    public void testup () {        //这一行代码编译器会提示错误，因为String类型并不是Number类型的子类        //showKeyValue1(generic1);        Generic&lt;String&gt; generic1 = new Generic&lt;String&gt;(&quot;11111&quot;);        Generic&lt;Integer&gt; generic2 = new Generic&lt;Integer&gt;(2222);        Generic&lt;Float&gt; generic3 = new Generic&lt;Float&gt;(2.4f);        Generic&lt;Double&gt; generic4 = new Generic&lt;Double&gt;(2.56);        showKeyValue1(generic2);        showKeyValue1(generic3);        showKeyValue1(generic4);    }    @Test    public void testdown () {        Generic&lt;String&gt; generic1 = new Generic&lt;String&gt;(&quot;11111&quot;);        Generic&lt;Integer&gt; generic2 = new Generic&lt;Integer&gt;(2222);        Generic&lt;Number&gt; generic3 = new Generic&lt;Number&gt;(2);//        showKeyValue2(generic1);本行报错，因为String并不是Integer的父类        showKeyValue2(generic2);        showKeyValue2(generic3);    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
            <tag> 泛型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列11: 反射机制</title>
      <link href="/2019/11/22/java-ji-chu-xi-lie-11-fan-she-ji-zhi/"/>
      <url>/2019/11/22/java-ji-chu-xi-lie-11-fan-she-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列11-反射机制"><a href="#Java基础系列11-反射机制" class="headerlink" title="Java基础系列11: 反射机制"></a>Java基础系列11: 反射机制</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="什么是反射"><a href="#什么是反射" class="headerlink" title="什么是反射"></a>什么是反射</h2><p>通过反射，我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息.<br>反射的核心是JVM在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。</p><p>也就是说有些时候我们需要在程序运行到某一步时才去创建一个类的对象,或者根据这个对象的类型去调用某个函数,而这些在编译器是未知的.<br>也就是动态的创建对象</p><h2 id="什么时候运用反射"><a href="#什么时候运用反射" class="headerlink" title="什么时候运用反射"></a>什么时候运用反射</h2><ul><li>在运行时判断任意一个对象所属的类；</li><li>在运行时构造任意一个类的对象；</li><li>在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）；</li><li>在运行时调用任意一个对象的方法<br>注意,全部都是运行时,而不是编译时</li></ul><h2 id="反射的使用举例"><a href="#反射的使用举例" class="headerlink" title="反射的使用举例"></a>反射的使用举例</h2><p>很多框架（比如Spring）都是配置化的（比如通过XML文件配置JavaBean,Action之类的），为了保证框架的通用性，它们可能需要根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射——运行时动态加载需要加载的对象。</p><p>Java反射是Java被视为动态（或准动态）语言的一个关键性质。这个机制允许程序在运行时透过Reflection APIs取得任何一个已知名称的class的内部信息，包括其modifiers（诸如public、static等）、superclass（例如Object）、实现之interfaces（例如Cloneable），也包括fields和methods的所有信息，并可于运行时改变fields内容或唤起methods。</p><p>实现Java反射机制的类都位于java.lang.reflect包中;</p><h2 id="反射的基本使用"><a href="#反射的基本使用" class="headerlink" title="反射的基本使用"></a>反射的基本使用</h2><h3 id="获取Class对象"><a href="#获取Class对象" class="headerlink" title="获取Class对象"></a>获取Class对象</h3><p>1) 使用forName的静态方法</p><pre><code>public static Class&lt;?&gt; forName(String className)在JDBC开发中常用此方法加载数据库驱动:要使用全类名来加载这个类，一般数据库驱动的配置信息会写在配置文件中。加载这个驱动前要先导入jar包 Class.forName(driver);或者这样,就获取到了UserBean这个类的类对象 Class clazz = Class.forName(&quot;com.javase.反射.UserBean&quot;);</code></pre><p>2) 直接获取某一个对象的class，比如:</p><pre><code>//Class&lt;?&gt;是一个泛型表示，用于获取一个类的类型。Class&lt;?&gt; klass = int.class;Class&lt;?&gt; classInt = Integer.TYPE;</code></pre><p>3) 调用某个对象的getClass()方法,比如:</p><pre><code>StringBuilder str = new StringBuilder(&quot;123&quot;);Class&lt;?&gt; klass = str.getClass();</code></pre><h3 id="判断是否为某个类的实例"><a href="#判断是否为某个类的实例" class="headerlink" title="判断是否为某个类的实例"></a>判断是否为某个类的实例</h3><p>可以使用instanceof关键字来判断是否为某个类的实例.<br>也可以用native方法,public native boolean isInstance(Object obj);</p><h3 id="创建实例"><a href="#创建实例" class="headerlink" title="创建实例"></a>创建实例</h3><p>通过反射来生成对象主要有两种方法:<br>1)使用Class对象的newInstance方法来创建Class对象对应类的实例,当前类必须有无参构造器</p><pre><code>//Class&lt;?&gt;代表任何类的一个类对象。//使用这个类对象可以为其他类进行实例化//因为jvm加载类以后自动在堆区生成一个对应的*.Class对象//该对象用于让JVM对进行所有*对象实例化。Class&lt;?&gt; c = String.class;//Class&lt;?&gt; 中的 ? 是通配符，其实就是表示任意符合泛类定义条件的类，和直接使用 Class//效果基本一致，但是这样写更加规范，在某些类型转换时可以避免不必要的 unchecked 错误。Object str = c.newInstance();</code></pre><p>2)先获取一个类对象(类型是Class&lt;?&gt;),再调用getConstructor方法来获取构造器,最后调用构造器的newInstance方法.</p><pre><code>//获取String所对应的Class对象Class&lt;?&gt; c = String.class;//获取String类带一个String参数的构造器Constructor constructor = c.getConstructor(String.class);//根据构造器创建实例Object obj = constructor.newInstance(&quot;23333&quot;);System.out.println(obj);</code></pre><h3 id="获取方法"><a href="#获取方法" class="headerlink" title="获取方法"></a>获取方法</h3><p>getDeclaredMethods()方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法.<br>(因为反射是创建了本类对象,所以相当于是内部调用,也就有了本不应该给外部的private方法的权限,反射攻击要注意这部分)</p><pre><code>public Method[] getDeclaredMethods() throws SecurityException</code></pre><p>getMethods()方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。</p><pre><code>public Method[] getMethods() throws SecurityException</code></pre><p>getMethod方法返回一个特定的方法，其中第一个参数为方法名称，后面的参数为方法的参数对应Class的对象</p><pre><code>public Method getMethod(String name, Class&lt;?&gt;... parameterTypes)</code></pre><p>几个例子:<br>打印一个类的所有方法及详细信息</p><pre><code>public class 打印所有方法 {    public static void main(String[] args) {        Class userBeanClass = UserBean.class;        Field[] fields = userBeanClass.getDeclaredFields();        //注意，打印方法时无法得到局部变量的名称，因为jvm只知道它的类型        Method[] methods = userBeanClass.getDeclaredMethods();        for (Method method : methods) {            //依次获得方法的修饰符，返回类型和名称，外加方法中的参数            String methodString = Modifier.toString(method.getModifiers()) + &quot; &quot; ; // private static            methodString += method.getReturnType().getSimpleName() + &quot; &quot;; // void            methodString += method.getName() + &quot;(&quot;; // staticMethod            Class[] parameters = method.getParameterTypes();            Parameter[] p = method.getParameters();            for (Class parameter : parameters) {                methodString += parameter.getSimpleName() + &quot; &quot; ; // String            }            methodString += &quot;)&quot;;            System.out.println(methodString);        }        //注意方法只能获取到其类型，拿不到变量名/*        public String getName()        public long getId()        public static void staticMethod(String int )        public void publicMethod()        private void privateMethod()*/    }}</code></pre><p>获取构造器信息</p><pre><code>public class 打印构造方法 {    public static void main(String[] args) {        // constructors        Class&lt;?&gt; clazz = UserBean.class;        Class userBeanClass = UserBean.class;        //获得所有的构造方法        Constructor[] constructors = userBeanClass.getDeclaredConstructors();        for (Constructor constructor : constructors) {            String s = Modifier.toString(constructor.getModifiers()) + &quot; &quot;;            s += constructor.getName() + &quot;(&quot;;            //构造方法的参数类型            Class[] parameters = constructor.getParameterTypes();            for (Class parameter : parameters) {                s += parameter.getSimpleName() + &quot;, &quot;;            }            s += &quot;)&quot;;            System.out.println(s);            //打印结果//public com.javase.反射.UserBean(String, long, )        }    }}</code></pre><p>获取类的成员变量的字段信息:</p><pre><code>getFiled: 访问公有的成员变量getDeclaredField：所有已声明的成员变量。但不能得到其父类的成员变量getFileds和getDeclaredFields用法同上（参照Method）public class 打印成员变量 {    public static void main(String[] args) {        Class userBeanClass = UserBean.class;        //获得该类的所有成员变量，包括static private        Field[] fields = userBeanClass.getDeclaredFields();        for(Field field : fields) {            //private属性即使不用下面这个语句也可以访问//            field.setAccessible(true);            //因为类的私有域在反射中默认可访问，所以flag默认为true。            String fieldString = &quot;&quot;;            fieldString += Modifier.toString(field.getModifiers()) + &quot; &quot;; // `private`            fieldString += field.getType().getSimpleName() + &quot; &quot;; // `String`            fieldString += field.getName(); // `userName`            fieldString += &quot;;&quot;;            System.out.println(fieldString);            //打印结果//            public String userName;//            protected int i;//            static int j;//            private int l;//            private long userId;        }    }}</code></pre><h3 id="使用invoke方法来调用类方法"><a href="#使用invoke方法来调用类方法" class="headerlink" title="使用invoke方法来调用类方法"></a>使用invoke方法来调用类方法</h3><p>这里有一个非常标准的示例,来源于:<a href="https://how2playlife.com/2019/09/12/12%E5%8F%8D%E5%B0%84/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/12/12%E5%8F%8D%E5%B0%84/</a></p><pre><code>public Object invoke(Object obj, Object... args)        throws IllegalAccessException, IllegalArgumentException,           InvocationTargetExceptionpublic class 使用反射调用方法 {    public static void main(String[] args) throws InvocationTargetException, IllegalAccessException, InstantiationException, NoSuchMethodException {        Class userBeanClass = UserBean.class;        //获取该类所有的方法，包括静态方法，实例方法。        //此处也包括了私有方法，只不过私有方法在用invoke访问之前要设置访问权限        //也就是使用setAccessible使方法可访问，否则会抛出异常//       // IllegalAccessException的解释是//        * An IllegalAccessException is thrown when an application tries// * to reflectively create an instance (other than an array),// * set or get a field, or invoke a method, but the currently// * executing method does not have access to the definition of// * the specified class, field, method or constructor.//        getDeclaredMethod*()获取的是类自身声明的所有方法，包含public、protected和private方法。//            getMethod*()获取的是类的所有共有方法，这就包括自身的所有public方法，和从基类继承的、从接口实现的所有public方法。        //就是说，当这个类，域或者方法被设为私有访问，使用反射调用但是却没有权限时会抛出异常。        Method[] methods = userBeanClass.getDeclaredMethods(); // 获取所有成员方法        for (Method method : methods) {            //反射可以获取方法上的注解，通过注解来进行判断            if (method.isAnnotationPresent(Invoke.class)) { // 判断是否被 @Invoke 修饰                //判断方法的修饰符是是static                if (Modifier.isStatic(method.getModifiers())) { // 如果是 static 方法                    //反射调用该方法                    //类方法可以直接调用，不必先实例化                    method.invoke(null, &quot;wingjay&quot;,2); // 直接调用，并传入需要的参数 devName                } else {                    //如果不是类方法，需要先获得一个实例再调用方法                    //传入构造方法需要的变量类型                    Class[] params = {String.class, long.class};                    //获取该类指定类型的构造方法                    //如果没有这种类型的方法会报错                    Constructor constructor = userBeanClass.getDeclaredConstructor(params); // 获取参数格式为 String,long 的构造函数                    //通过构造方法的实例来进行实例化                    Object userBean = constructor.newInstance(&quot;wingjay&quot;, 11); // 利用构造函数进行实例化，得到 Object                    if (Modifier.isPrivate(method.getModifiers())) {                        method.setAccessible(true); // 如果是 private 的方法，需要获取其调用权限//                        Set the {@code accessible} flag for this object to//     * the indicated boolean value.  A value of {@code true} indicates that//     * the reflected object should suppress Java language access//     * checking when it is used.  A value of {@code false} indicates//                                * that the reflected object should enforce Java language access checks.                        //通过该方法可以设置其可见或者不可见，不仅可以用于方法                        //后面例子会介绍将其用于成员变量                                            //打印结果//            I&#39;m a public method// Hi wingjay, I&#39;m a static methodI&#39;m a private method                    }                    method.invoke(userBean); // 调用 method，无须参数                                    }            }        }    }}</code></pre><p>这里还有一个更加通俗的,转载自<a href="https://blog.csdn.net/a695422768/article/details/73330951" target="_blank" rel="noopener">https://blog.csdn.net/a695422768/article/details/73330951</a> ,感觉更加好理解一些:</p><pre><code>public static void main(String[] args) throws Exception {        Class&lt;?&gt; class1 = null;        // 反射获取类实例，用的最多的就是jdbc获取驱动的时候就是用Class.forName(&quot;xxx&quot;);        // 一般采用这种形式        class1 = Class.forName(&quot;com.xxx.TestReflect&quot;);        // class1 = new TestReflect().getClass();        // class1 = TestReflect.class;        // 类实例化，到这里就可以访问TestReflect类的public属性的成员方法和成员变量了        TestReflect tr = (TestReflect) class1.newInstance();        // 通过java.lang.Class类得到一个Method对象        // api中java.lang.Class.getDeclaredMethod方法介绍        // 返回一个 Method 对象，该对象反映此 Class 对象所表示的类或接口的指定已声明方法。        Method method = class1.getDeclaredMethod(&quot;mPrivate&quot;);        Method method1 = class1.getDeclaredMethod(&quot;mProtected&quot;);        //将此对象的 accessible 标志设置为指示的布尔值。        //值为 true 则指示反射的对象在使用时应该取消 Java 语言访问检查。        //值为 false 则指示反射的对象应该实施 Java 语言访问检查。        method.setAccessible(true);         method1.setAccessible(true);        // 调用该方法,注意是方法对象来invoke实例对象        method.invoke(tr);        method1.invoke(tr);    }</code></pre><h3 id="使用反射创建数组"><a href="#使用反射创建数组" class="headerlink" title="使用反射创建数组"></a>使用反射创建数组</h3><p>要使用java.lang.reflect.Array类</p><pre><code>public class 用反射创建数组 {    public static void main(String[] args) {        Class&lt;?&gt; cls = null;        try {            cls = Class.forName(&quot;java.lang.String&quot;);        } catch (ClassNotFoundException e) {            e.printStackTrace();        }        Object array = Array.newInstance(cls,25);        //往数组里添加内容        Array.set(array,0,&quot;hello&quot;);        Array.set(array,1,&quot;Java&quot;);        Array.set(array,2,&quot;fuck&quot;);        Array.set(array,3,&quot;Scala&quot;);        Array.set(array,4,&quot;Clojure&quot;);        //获取某一项的内容        System.out.println(Array.get(array,3));        //Scala    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列10: 回调机制</title>
      <link href="/2019/11/20/java-ji-chu-xi-lie-10-hui-diao-ji-zhi/"/>
      <url>/2019/11/20/java-ji-chu-xi-lie-10-hui-diao-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列10-回调机制"><a href="#Java基础系列10-回调机制" class="headerlink" title="Java基础系列10: 回调机制"></a>Java基础系列10: 回调机制</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="几种调用机制"><a href="#几种调用机制" class="headerlink" title="几种调用机制"></a>几种调用机制</h2><h3 id="同步调用"><a href="#同步调用" class="headerlink" title="同步调用"></a>同步调用</h3><p>同步调用是最基本并且最简单的一种调用方式，类A的方法a()调用类B的方法b()，一直等待b()方法执行完毕，a()方法继续往下走。这种调用方式适用于方法b()执行时间不长的情况，因为b()方法执行时间一长或者直接阻塞的话，a()方法的余下代码是无法执行下去的，这样会造成整个流程的阻塞</p><h3 id="异步调用"><a href="#异步调用" class="headerlink" title="异步调用"></a>异步调用</h3><p>类A的方法a()通过新建立一个线程的方式调用类B的方法b(),代码继续往后执行.</p><p>这种方法不确定什么时候能拿到b返回的结果,所以需要监听b</p><h3 id="回调"><a href="#回调" class="headerlink" title="回调"></a>回调</h3><p>回调的定义:A调用B执行一个任务,B执行完之后又调用A继续执行.</p><p>往往使用在多线程中,可以使用callable和future或者futuretask结合来获取线程执行之后的返回值</p><p>以下例子来源于<a href="https://how2playlife.com/2019/09/11/11%E8%A7%A3%E8%AF%BBJava%E4%B8%AD%E7%9A%84%E5%9B%9E%E8%B0%83/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/11/11%E8%A7%A3%E8%AF%BBJava%E4%B8%AD%E7%9A%84%E5%9B%9E%E8%B0%83/</a><br>一个简单的例子:<br>小明和小李相约一起去吃早饭，但是小李起的有点晚要先洗漱，等小李洗漱完成后，通知小明再一起去吃饭。小明就是类A，小李就是类B。一起去吃饭这个事件就是方法a(),小李去洗漱就是方法b()。</p><p>进阶例子:<br>小明和小李相约一起去吃早饭，但是小李起的有点晚要先洗漱，等小李洗漱完成后，通知小明再一起去吃饭,或者和小王去上网。小明就是类A，小李就是类B。不同的是我们新建一个吃饭的接口EatRice，接口中有个抽象方法eat()。在小明中调用这个接口，并实现eat()；小李声明这个接口对象，并且调用这个接口的抽象方法。<br>和小王去上网的代码</p><pre><code>public class XiaoWang implements EatRice{//小王   //小王和小李一起去上网   public void eatFood() {    XiaoLi xl = new XiaoLi();    //A调用B的方法    xl.washFace(&quot;轻舞飞扬上网&quot;, this);   }   @Override   public void eat(String bar) {    // TODO Auto-generated method stub    System.out.println(&quot;小王和小李一起去&quot; + bar);   }}</code></pre><p>再看一个学生做题的例子:<br>数学老师让Tom做一道题，并且Tom做题期间数学老师不用盯着Tom，而是在玩手机，等Tom把题目做完后再把答案告诉老师。</p><p>这个过程可以分为3步:<br>数学老师使用Tom的引用,把题目发给tom<br>tom做题,然后使用老师的引用,调用老师的一个callback方法,把答案告诉这位老师,或者告诉其他老师.</p><p>所以每位老师都需要实现一个callback接口,以便接收学生的答案</p><pre><code>//回调指的是A调用B来做一件事，B做完以后将结果告诉给A，这期间A可以做别的事情。//这个接口中有一个方法，意为B做完题目后告诉A时使用的方法。//所以我们必须提供这个接口以便让B来回调。//回调接口，public interface CallBack {    void tellAnswer(int res);}</code></pre><p>老师代码:</p><pre><code>   //老师类实例化回调接口，即学生写完题目之后通过老师的提供的方法进行回调。    //那么学生如何调用到老师的方法呢，只要在学生类的方法中传入老师的引用即可。    //而老师需要指定学生答题，所以也要传入学生的实例。public class Teacher implements CallBack{    private Student student;    Teacher(Student student) {        this.student = student;    }    void askProblem (Student student, Teacher teacher) {        //main方法是主线程运行，为了实现异步回调，这里开启一个线程来操作        new Thread(new Runnable() {            @Override            public void run() {                student.resolveProblem(teacher);            }        }).start();        //老师让学生做题以后，等待学生回答的这段时间，可以做别的事，比如玩手机.\        //而不需要同步等待，这就是回调的好处。        //当然你可以说开启一个线程让学生做题就行了，但是这样无法让学生通知老师。        //需要另外的机制去实现通知过程。        // 当然，多线程中的future和callable也可以实现数据获取的功能。        for (int i = 1;i &lt; 4;i ++) {            System.out.println(&quot;等学生回答问题的时候老师玩了 &quot; + i + &quot;秒的手机&quot;);        }    }    @Override    public void tellAnswer(int res) {        System.out.println(&quot;the answer is &quot; + res);    }}</code></pre><p>学生代码:</p><pre><code>   //学生的接口，解决问题的方法中要传入老师的引用，否则无法完成对具体实例的回调。    //写为接口的好处就是，很多个学生都可以实现这个接口，并且老师在提问题时可以通过    //传入List&lt;Student&gt;来聚合学生，十分方便。public interface Student {    void resolveProblem (Teacher teacher);}public class Tom implements Student{    @Override    public void resolveProblem(Teacher teacher) {        try {            //学生思考了3秒后得到了答案，通过老师提供的回调方法告诉老师。            Thread.sleep(3000);            System.out.println(&quot;work out&quot;);            teacher.tellAnswer(111);        } catch (InterruptedException e) {            e.printStackTrace();        }    }</code></pre><p>测试代码:</p><pre><code>public class Test {    public static void main(String[] args) {        //测试        Student tom = new Tom();        Teacher lee = new Teacher(tom);        lee.askProblem(tom, lee);        //结果//        等学生回答问题的时候老师玩了 1秒的手机//        等学生回答问题的时候老师玩了 2秒的手机//        等学生回答问题的时候老师玩了 3秒的手机//        work out//        the answer is 111    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列9: 异常体系</title>
      <link href="/2019/11/18/java-ji-chu-xi-lie-9-yi-chang-ti-xi/"/>
      <url>/2019/11/18/java-ji-chu-xi-lie-9-yi-chang-ti-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列9-异常体系"><a href="#Java基础系列9-异常体系" class="headerlink" title="Java基础系列9: 异常体系"></a>Java基础系列9: 异常体系</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="为什么要使用异常"><a href="#为什么要使用异常" class="headerlink" title="为什么要使用异常"></a>为什么要使用异常</h2><p>核心用法是精准定位出现错误的地方,以及把处理错误的代码和正常逻辑代码进行分割.</p><p>异常出现于程序在正常情况下无法再继续运行了,此时程序就会从所给环境中跳出,抛出异常,new一个异常对象,跳转到异常处理程序</p><h2 id="异常的体系结构"><a href="#异常的体系结构" class="headerlink" title="异常的体系结构"></a>异常的体系结构</h2><p>Throwable这个类是所有异常的父类,有error和exception两个子类.<br>error是不能被程序员处理的,很少出现.如果出现了我们应该修正代码,而不是去捕获错误,比如单词拼写错误.<br>exception是可以被try-catch或者throw方法抛出并处理的.</p><h2 id="异常追踪机制"><a href="#异常追踪机制" class="headerlink" title="异常追踪机制"></a>异常追踪机制</h2><p>从发生点开始抛出,一直到调用程序有异常捕获机制的时候进行处理,否则就一直到main抛出给JRE,最后导致程序终止.</p><h2 id="异常的处理方式"><a href="#异常的处理方式" class="headerlink" title="异常的处理方式"></a>异常的处理方式</h2><p>看两个例子,来自于:<a href="https://how2playlife.com/2019/09/10/10Java%E5%BC%82%E5%B8%B8/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/10/10Java%E5%BC%82%E5%B8%B8/</a><br>首先是一个可能会抛出的程序,文件招不到,read方法抛出.</p><pre><code>@Testpublic void testException() throws IOException{    //FileInputStream的构造函数会抛出FileNotFoundException    FileInputStream fileIn = new FileInputStream(&quot;E:\\a.txt&quot;);    int word;    //read方法会抛出IOException    while((word =  fileIn.read())!=-1)    {        System.out.print((char)word);    }    //close方法会抛出IOException    fileIn.close();}</code></pre><p>使用try…catch…finally来解决</p><pre><code>public class 异常处理方式 {@Testpublic void main() {    try{        //try块中放可能发生异常的代码。        InputStream inputStream = new FileInputStream(&quot;a.txt&quot;);        //如果执行完try且不发生异常，则接着去执行finally块和finally后面的代码（如果有的话）。        int i = 1/0;        //如果发生异常，则尝试去匹配catch块。        throw new SQLException();        //使用1.8jdk同时捕获多个异常，runtimeexception也可以捕获。只是捕获后虚拟机也无法处理，所以不建议捕获。    }catch(SQLException | IOException | ArrayIndexOutOfBoundsException exception){        System.out.println(exception.getMessage());        //每一个catch块用于捕获并处理一个特定的异常，或者这异常类型的子类。Java7中可以将多个异常声明在一个catch中。        //catch后面的括号定义了异常类型和异常参数。如果异常与之匹配且是最先匹配到的，则虚拟机将使用这个catch块来处理异常。        //在catch块中可以使用这个块的异常参数来获取异常的相关信息。异常参数是这个catch块中的局部变量，其它块不能访问。        //如果当前try块中发生的异常在后续的所有catch中都没捕获到，则先去执行finally，然后到这个函数的外部caller中去匹配异常处理器。        //如果try中没有发生异常，则所有的catch块将被忽略。    }catch(Exception exception){        System.out.println(exception.getMessage());        //...    }finally{        //finally块通常是可选的。        //无论异常是否发生，异常是否匹配被处理，finally都会执行。        //finally主要做一些清理工作，如流的关闭，数据库连接的关闭等。    }</code></pre><h2 id="finally部分的执行次序"><a href="#finally部分的执行次序" class="headerlink" title="finally部分的执行次序"></a>finally部分的执行次序</h2><p>在同一try…catch…finally块中 ，如果try中抛出异常，且有匹配的catch块，则先执行catch块，再执行finally块。如果没有catch块匹配，则先执行finally，然后去外面的调用者中寻找合适的catch块。</p><p>在同一try…catch…finally块中 ，try发生异常，且匹配的catch块中处理异常时也抛出异常，那么后面的finally也会执行：首先执行finally块，然后去外围调用者中寻找合适的catch块。</p><p>只有在try里面是有System.exit(0)来退出JVM的情况下finally块中的代码才不会执行。</p><h2 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a>自定义异常</h2><p>如果要自定义异常类，则扩展Exception类即可，因此这样的自定义异常都属于检查异常（checked exception）。<br>如果要自定义非检查异常，则扩展自RuntimeException。</p><p>自定义异常必须包含如下的构造函数:<br>一个无参构造函数<br>一个带有String参数的构造函数，并传递给父类的构造函数。<br>一个带有String参数和Throwable参数，并都传递给父类构造函数<br>一个带有Throwable 参数的构造函数，并传递给父类的构造函数。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>1,当子类重写父类的带有 throws声明的函数时，其throws声明的异常必须在父类异常的可控范围内——用于处理父类的throws方法的异常处理器，必须也适用于子类的这个带throws方法 。这是为了支持多态。</p><p>2,Java程序可以是多线程的。每一个线程都是一个独立的执行流，独立的函数调用栈。如果程序只有一个线程，那么没有被任何代码处理的异常 会导致程序终止。如果是多线程的，那么没有被任何代码处理的异常仅仅会导致异常所在的线程结束。也就是说，Java中的异常是线程独立的，线程的问题应该由线程自己来解决，而不要委托到外部，也不会直接影响到其它线程的执行。</p><p>3,在 try块中即便有return，break，continue等改变执行流的语句，finally也会执行。<br>为了避免这个问题,有以下建议:<br>不要在fianlly中使用return。</p><p>不要在finally中抛出异常。</p><p>减轻finally的任务，不要在finally中做一些其它的事情，finally块仅仅用来释放资源是最合适的。</p><p>将尽量将所有的return写在函数的最后面，而不是try … catch … finally中。</p><h2 id="经典面试题回答"><a href="#经典面试题回答" class="headerlink" title="经典面试题回答"></a>经典面试题回答</h2><p>(引用自<a href="https://how2playlife.com/2019/09/10/10Java%E5%BC%82%E5%B8%B8/" target="_blank" rel="noopener">https://how2playlife.com/2019/09/10/10Java%E5%BC%82%E5%B8%B8/</a>)<br>1) Java中的NullPointerException和ArrayIndexOutOfBoundException之间有什么相同之处？<br>这两个异常都是非检查型异常，<strong>都继承自RuntimeException</strong>。该问题可能会引出另一个问题，即Java和C的数组有什么不同之处，因为C里面的数组是没有大小限制的，绝对不会抛出ArrayIndexOutOfBoundException。</p><p>2)在Java异常处理的过程中，你遵循的那些最好的实践是什么？</p><ul><li><p>调用方法的时候返回布尔值来代替返回null，这样可以 NullPointerException。由于空指针是java异常里最恶心的异常</p></li><li><p>catch块里别不写代码。空catch块是异常处理里的错误事件，因为它只是捕获了异常，却没有任何处理或者提示。通常你起码要打印出异常信息，当然你最好根据需求对异常信息进行处理。</p></li><li><p>能抛受控异常（checked Exception）就尽量不抛受非控异常(checked Exception)。通过去掉重复的异常处理代码，可以提高代码的可读性。</p></li><li><p>绝对不要让你的数据库相关异常显示到客户端。由于绝大多数数据库和SQLException异常都是受控异常，在Java中，你应该在DAO层把异常信息处理，然后返回处理过的能让用户看懂并根据异常提示信息改正操作的异常信息。</p></li><li><p>在Java中，一定要在数据库连接，数据库查询，流处理后，在finally块中调用close()方法。</p></li></ul><p>3) 既然我们可以用RuntimeException来处理错误，那么你认为为什么Java中还存在检查型异常?<br>这是一个有争议的问题，在回答该问题时你应当小心。虽然他们肯定愿意听到你的观点，但其实他们最感兴趣的还是有说服力的理由。其中一个理由是，存在检查型异常是一个设计上的决定，受到了诸如C++等比Java更早编程语言设计经验的影响。绝大多数检查型异常位于java.io包内，这是合乎情理的，因为在你请求了不存在的系统资源的时候，一段强壮的程序必须能够优雅的处理这种情况。通过把IOException声明为检查型异常，Java 确保了你能够优雅的对异常进行处理。另一个可能的理由是，可以使用catch或finally来确保数量受限的系统资源（比如文件描述符）在你使用后尽早得到释放</p><p>4) Java中final,finalize,finally关键字的区别<br>final和finally是Java的关键字，而finalize则是方法。final关键字在创建不可变的类的时候非常有用，只是声明这个类是final的。而finalize()方法则是垃圾回收器在回收一个对象前调用，但也Java规范里面没有保证这个方法一定会被调用。finally关键字是唯一一个和这篇文章讨论到的异常处理相关的关键字。在你的产品代码中，在关闭连接和资源文件的是时候都必须要用到finally块。</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列8: Object类</title>
      <link href="/2019/11/16/java-ji-chu-xi-lie-8-object-lei/"/>
      <url>/2019/11/16/java-ji-chu-xi-lie-8-object-lei/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列8-Object类"><a href="#Java基础系列8-Object类" class="headerlink" title="Java基础系列8: Object类"></a>Java基础系列8: Object类</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="Object类"><a href="#Object类" class="headerlink" title="Object类"></a>Object类</h2><p>Object是所有类的共有祖先,属于java.lang包里,没有属性但是有13个方法,有9个是所有类都继承了;</p><pre><code>1．clone方法保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。2．getClass方法final方法，获得运行时类型。3．toString方法该方法用得比较多，一般子类都有覆盖。4．finalize方法该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。5．equals方法该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。6．hashCode方法该方法用于哈希查找，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。一般必须满足obj1.equals(obj2)==true。可以推出obj1.hash- Code()==obj2.hashCode()，但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。7．wait方法wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。调用该方法后当前线程进入睡眠状态，直到以下事件发生。（1）其他线程调用了该对象的notify方法。（2）其他线程调用了该对象的notifyAll方法。（3）其他线程调用了interrupt中断该线程。（4）时间间隔到了。此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。8．notify方法该方法唤醒在该对象上等待的某个线程。9．notifyAll方法该方法唤醒在该对象上等待的所有线程。</code></pre><h2 id="native关键字"><a href="#native关键字" class="headerlink" title="native关键字"></a>native关键字</h2><p>用native关键字修饰的函数表明该方法的实现并不是在Java中去完成，而是由C/C++去完成，并被编译成了.dll，由Java去调用.<br>操作系统提供本方法.</p><h2 id="clone方法"><a href="#clone方法" class="headerlink" title="clone方法"></a>clone方法</h2><p>提供一个浅拷贝,也就是一个一模一样但是地址不同的对象.子类必须实现Cloneable接口.</p><h2 id="浅拷贝和深拷贝的区别"><a href="#浅拷贝和深拷贝的区别" class="headerlink" title="浅拷贝和深拷贝的区别"></a>浅拷贝和深拷贝的区别</h2><p>浅拷贝<br>浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象。</p><p>深拷贝<br>深拷贝会拷贝所有的属性,并拷贝属性指向的动态分配的内存。当对象和它所引用的对象一起拷贝时即发生深拷贝。深拷贝相比于浅拷贝速度较慢并且花销较大。<br>现在为了要在clone对象时进行深拷贝， 那么就要Clonable接口，覆盖并实现clone方法，除了调用父类中的clone方法得到新的对象， 还要将该类中的引用变量也clone出来。如果只是用Object中默认的clone方法，是浅拷贝的。</p><p>通俗的说,浅拷贝是复制钥匙,深拷贝是直接把储藏柜也复制一份.</p><h2 id="getClass"><a href="#getClass" class="headerlink" title="getClass()"></a>getClass()</h2><p>使用反射获取当前类对象,后面到反射那一块再讲</p><h2 id="equals"><a href="#equals" class="headerlink" title="equals()"></a>equals()</h2><p>判断两个对象是否相同,根据不同的子类会重写.</p><h2 id="hashCode"><a href="#hashCode" class="headerlink" title="hashCode()"></a>hashCode()</h2><p>如果两个对象相同,则哈希值必须相同.反之未必.</p><h2 id="toString-NaN"><a href="#toString-NaN" class="headerlink" title="toString()"></a>toString()</h2><p>同上,根据不同的子类具体实现</p><h2 id="wait-notify-notifAll"><a href="#wait-notify-notifAll" class="headerlink" title="wait() notify() notifAll()"></a>wait() notify() notifAll()</h2><p>主要是多线程的部分,有更好的方法可以实现,先不研究.</p><h2 id="finalize"><a href="#finalize" class="headerlink" title="finalize()"></a>finalize()</h2><p>用于垃圾回收部分,详细见JVM学习部分.</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列7: 代码块和执行顺序</title>
      <link href="/2019/11/14/java-ji-chu-xi-lie-7-dai-ma-kuai-he-zhi-xing-shun-xu/"/>
      <url>/2019/11/14/java-ji-chu-xi-lie-7-dai-ma-kuai-he-zhi-xing-shun-xu/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列7-代码块和执行顺序"><a href="#Java基础系列7-代码块和执行顺序" class="headerlink" title="Java基础系列7: 代码块和执行顺序"></a>Java基础系列7: 代码块和执行顺序</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h2><p>构造方法不能被static、final、synchronized、abstract 和 native 修饰,原因是构造方法用于初始化一个新对象，所以用 static 修饰没有意义；构造方法不能被子类继承，所以用 final 和 abstract 修饰没有意义；多个线程不会同时创建内存地址相同的同一个对象，所以用 synchronized 修饰没有必要。</p><p>一个类可以有多个构造方法,维持传入参数不同即可.</p><p>注意构造方法是可以private的,也就是可以在本类的内部实例化,但是不能被外部实例化(也就是不能被其他函数new)</p><h2 id="子类调用父类的构造方法"><a href="#子类调用父类的构造方法" class="headerlink" title="子类调用父类的构造方法"></a>子类调用父类的构造方法</h2><p>核心:子类无论如何都要调用父类的构造方法,而且子类是不能继承父类的构造方法的.</p><h2 id="Java代码块"><a href="#Java代码块" class="headerlink" title="Java代码块"></a>Java代码块</h2><h3 id="普通代码块"><a href="#普通代码块" class="headerlink" title="普通代码块"></a>普通代码块</h3><p>类中方法的方法体</p><h3 id="构造代码块"><a href="#构造代码块" class="headerlink" title="构造代码块"></a>构造代码块</h3><p>在创建对象事被调用,每次创建时也被调用,优先于构造函数执行.</p><pre><code>class A{    int i = 1;    int initValue;//成员变量的初始化交给代码块来完成    {        //代码块的作用体现于此：在调用构造方法之前，用某段代码对成员变量进行初始化。        //而不是在构造方法调用时再进行。一般用于将构造方法的相同部分提取出来。        //        for (int i = 0;i &lt; 100;i ++) {            initValue += i;        }    }    {        System.out.println(initValue);        System.out.println(i);//此时会打印1        int i = 2;//代码块里的变量和成员变量不冲突，但会优先使用代码块的变量        System.out.println(i);//此时打印2        //System.out.println(j);//提示非法向后引用，因为此时j的的初始化还没开始。        //    }    {        System.out.println(&quot;代码块运行&quot;);    }    int j = 2;    {        System.out.println(j);        System.out.println(i);//代码块中的变量运行后自动释放，不会影响代码块之外的代码    }    A(){        System.out.println(&quot;构造方法运行&quot;);    }}public class 构造代码块 {    @Test    public void test() {        A a = new A();    }}</code></pre><h3 id="静态代码块"><a href="#静态代码块" class="headerlink" title="静态代码块"></a>静态代码块</h3><p>只会执行一次,优先于构造代码块执行.只会执行一次.</p><h3 id="同步代码块"><a href="#同步代码块" class="headerlink" title="同步代码块"></a>同步代码块</h3><p>使用synchronized（）{}包起来的代码块.</p><h2 id="有继承关系时的执行顺序"><a href="#有继承关系时的执行顺序" class="headerlink" title="有继承关系时的执行顺序:"></a>有继承关系时的执行顺序:</h2><pre><code>父类的静态成员和代码块子类静态成员和代码块父类成员初始化和代码快父类构造方法子类成员初始化和代码块子类构造方法</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列6: 抽象类和接口</title>
      <link href="/2019/11/12/java-ji-chu-xi-lie-6-chou-xiang-lei-he-jie-kou/"/>
      <url>/2019/11/12/java-ji-chu-xi-lie-6-chou-xiang-lei-he-jie-kou/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列6-抽象类和接口"><a href="#Java基础系列6-抽象类和接口" class="headerlink" title="Java基础系列6: 抽象类和接口"></a>Java基础系列6: 抽象类和接口</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h2><p>只给出方法的定义而不给出方法体,也就是没有’{}’<br>包含一个或多个抽象方法的类必须被声明为抽象类<br>使用abstract修饰符来表示抽象</p><p>抽象类不能被实例化,也就是不能new.必须由子类继承实现之后才能实例化子类.</p><p>这里还有一个多态的典型例子:</p><pre><code>People people=new Teacher(&quot;教师&quot;);people.work();</code></pre><p>一个核心的判断方法:</p><pre><code>抽象类可以不包含抽象方法，包含抽象方法的类就一定是抽象类。</code></pre><h2 id="使用抽象类的好处"><a href="#使用抽象类的好处" class="headerlink" title="使用抽象类的好处"></a>使用抽象类的好处</h2><p>强调这个方法是必须要实现的,有个提示作用.</p><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>接口的意义在于制定标准,往往用于工厂模式.<br>注意一个实现接口的类,必须实现接口内描述的所有抽象方法</p><p>接口内的所有方法都是public abstract的,也可以含有变量,但是也是默认为public static final的,同时接口内的方法是不能再接口内直接实现的.</p><h2 id="工厂模式中的接口"><a href="#工厂模式中的接口" class="headerlink" title="工厂模式中的接口"></a>工厂模式中的接口</h2><pre><code>工厂模式是为了解耦：把对象的创建和使用的过程分开。就是Class A 想调用 Class B ，那么A只是调用B的方法，而至于B的实例化，就交给工厂类。其次，工厂模式可以降低代码重复。如果创建对象B的过程都很复杂，需要一定的代码量，而且很多地方都要用到，那么就会有很多的重复代码。我们可以这些创建对象B的代码放到工厂里统一管理。既减少了重复代码，也方便以后对B的创建过程的修改维护。由于创建过程都由工厂统一管理，所以发生业务逻辑变化，不需要找到所有需要创建B的地方去逐个修正，只需要在工厂里修改即可，降低维护成本。同理，想把所有调用B的地方改成B的子类C，只需要在对应生产B的工厂中或者工厂的方法中修改其生产的对象为C即可，而不需要找到所有的new B（）改为newC()。代码引用自:https://how2playlife.com/2019/09/06/6%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3/package demo;import java.util.Scanner;interface Fruit                        //定义一个水果标准{    public abstract void eat();}class Apple implements Fruit{    public void eat()    {        System.out.println(&quot;吃苹果&quot;);    }}class Orange implements Fruit{    public void eat()    {        System.out.println(&quot;吃橘子&quot;);    }}class factory{    public static Fruit getInstance(String className)  //返回值是Fruit的子类    {        if(&quot;apple&quot;.equals(className))        {            return new Apple();        }        else if(&quot;orange&quot;.equals(className))        {            return new Orange();        }        else        {            return null;        }    }}public class ComplexFactory {    public static void main(String[] args)    {            System.out.println(&quot;请输入水果的英文名:&quot;);        Scanner sc = new Scanner(System.in);        String ans = sc.nextLine();        Fruit f = factory.getInstance(ans);   //初始化参数        f.eat();        sc.close();    }}</code></pre><h2 id="接口和抽象类的区别"><a href="#接口和抽象类的区别" class="headerlink" title="接口和抽象类的区别"></a>接口和抽象类的区别</h2><p>核心区别: </p><pre><code>抽象类表示的是“is a”关系，接口表示的是“like a”关系</code></pre><p>接口(interface)和抽象类(abstract class)是支持抽象类定义的两种机制。</p><p>接口是公开的，不能有私有的方法或变量，接口中的所有方法都没有方法体，通过关键字interface实现。</p><p>抽象类是可以有私有方法或私有变量的，通过把类或者类中的方法声明为abstract来表示一个类是抽象类，被声明为抽象的方法不能包含方法体。子类实现方法必须含有相同的或者更低的访问级别(public-&gt;protected-&gt;private)。抽象类的子类为父类中所有抽象方法的具体实现，否则也是抽象类。</p><p>接口可以被看作是抽象类的变体，接口中所有的方法都是抽象的，可以通过接口来间接的实现多重继承。接口中的成员变量都是static final类型，由于抽象类可以包含部分方法的实现，所以，在一些场合下抽象类比接口更有优势。</p><p>相同点</p><p>（1）都不能被实例化<br>（2）接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。</p><p>不同点</p><p>（1）接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。</p><p>（2）实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。</p><p>（3）接口强调特定功能的实现，而抽象类强调所属关系。</p><p>（4）接口成员变量默认为public static final，必须赋初值，不能被修改；其所有的成员方法都是public、abstract的。抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被private、static、synchronized和native等修饰，必须以分号结尾，不带花括号。</p><p>（5）接口被用于常用的功能，便于日后维护和添加删除，而抽象类更倾向于充当公共类的角色，不适用于日后重新对立面的代码修改。功能需要累积时用抽象类，不需要累积时用接口。</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列5: 文件结构</title>
      <link href="/2019/11/10/java-ji-chu-xi-lie-5-wen-jian-jie-gou/"/>
      <url>/2019/11/10/java-ji-chu-xi-lie-5-wen-jian-jie-gou/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列5-文件结构"><a href="#Java基础系列5-文件结构" class="headerlink" title="Java基础系列5: 文件结构"></a>Java基础系列5: 文件结构</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="包"><a href="#包" class="headerlink" title="包"></a>包</h2><p>包的作用:<br>1、把功能相似或相关的类或接口组织在同一个包中，方便类的查找和使用。</p><p>2、如同文件夹一样，包也采用了树形目录的存储方式。同一个包中的类名字是不同的，不同的包中的类的名字是可以相同的，当同时调用两个不同包中相同类名的类时，应该加上包名加以区别。因此，包可以避免名字冲突。</p><p>3、包也限定了访问权限，拥有包访问权限的类才能访问某个包中的类</p><p>包声明应该在源文件的第一行，每个源文件只能有一个包声明，这个文件中的每个类型都应用于它。</p><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p>通常，一个公司使用它互联网域名的颠倒形式来作为它的包名.例如：互联网域名是 runoob.com，所有的包名都以 com.runoob 开头。包名中的每一个部分对应一个子目录。</p><h2 id="常用的jar包"><a href="#常用的jar包" class="headerlink" title="常用的jar包"></a>常用的jar包</h2><p>1）java.lang：包含语言支持类（例如分类，用于定义基本数据类型，数学运算）。该软件包会自动导入。</p><p>2） java.io：包含分类以支持输入/输出操作。</p><p>3） java.util：包含实现像链接列表，字典和支持等数据结构的实用类; 用于日期/时间操作。</p><p>4） java.applet：包含用于创建Applets的类。</p><p>5） java.awt：包含用于实现图形用户界面组件的类（如按钮，菜单等）。</p><p>6） java.net：包含支持网络操作的类。</p><h2 id="为什么一个java源文件中只能有一个public类？"><a href="#为什么一个java源文件中只能有一个public类？" class="headerlink" title="为什么一个java源文件中只能有一个public类？"></a>为什么一个java源文件中只能有一个public类？</h2><p>1.每个编译单元（文件）都只能有一个public类，这表示，每个编译单元都有单一的公共接口，用public类来表现。该接口可以按要求包含众多的支持包访问权限的类。如果在某个编译单元内有一个以上的public类，编译器就会给出错误信息。</p><p>2.public类的名称必须完全与含有该编译单元的文件名相同，包含大小写。如果不匹配，同样将得到编译错误。</p><p>3.虽然不是很常用，但编译单元内完全不带public类也是可能的。在这种情况下，可以随意对文件命名。</p><p><strong>一个java文件中可以包含很多个类，每个类中有且仅有一个主函数，但是每个java文件中可以包含多个主函数，在运行时，需要指定JVM入口是哪个。例如一个类的主函数可以调用另一个类的主函数。不一定会使用public类的主函数。</strong></p><h2 id="protected关键字"><a href="#protected关键字" class="headerlink" title="protected关键字"></a>protected关键字</h2><p>protected是包内可见并且子类可见，但是当一个外部类想要继承一个protected修饰的非同包类时，压根找不到这个类，更别提几层了;<br>和private的区别,private是子类也不可见的.</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
            <tag> 文件结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列4: final的使用</title>
      <link href="/2019/11/08/java-ji-chu-xi-lie-4-final-de-shi-yong/"/>
      <url>/2019/11/08/java-ji-chu-xi-lie-4-final-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列4-final的使用"><a href="#Java基础系列4-final的使用" class="headerlink" title="Java基础系列4: final的使用"></a>Java基础系列4: final的使用</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="final的常规使用"><a href="#final的常规使用" class="headerlink" title="final的常规使用"></a>final的常规使用</h2><p>final关键字经常和static一同使用,代表类常量;<br>可以选择在声明的时候初始化,或者在构造函数中初始化,无<em>默认值</em></p><p>常量的读取和加载类是分开的,只读取变量而不会调用构造函数,缓存在常量池中</p><pre><code>public class Main {    public static final int i = 2;    Main() {        System.out.println(&quot;调用构造函数&quot;); // 该方法不会调用    }    public static void main(String[] args) {        System.out.println(Main.i);    }}</code></pre><p>final方法不会被子类的方法重写,编译的时候就已经静态绑定了</p><h2 id="final类"><a href="#final类" class="headerlink" title="final类"></a>final类</h2><ul><li>无法被继承</li><li>类中的方法默认也都是final类型</li></ul><h2 id="final方法的好处"><a href="#final方法的好处" class="headerlink" title="final方法的好处"></a>final方法的好处</h2><p>1,提高了性能,静态绑定<br>2,在多线程中安全<br>3,是只可读的,多线程安全共享.<br>会被编译器进行优化,减少函数寻找和调用的次数,因为会将被final修饰过的函数直接插入到调用者代码处.</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列3: String类型的分析</title>
      <link href="/2019/11/06/java-ji-chu-xi-lie-3-string-lei-xing-de-fen-xi/"/>
      <url>/2019/11/06/java-ji-chu-xi-lie-3-string-lei-xing-de-fen-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列3-String类型的分析"><a href="#Java基础系列3-String类型的分析" class="headerlink" title="Java基础系列3: String类型的分析"></a>Java基础系列3: String类型的分析</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>String类有11种构造方法,提供不同的参数来初始化.<br><strong>String类的对象是不可变的,一旦创建就不可改变</strong><br>这里要理解以下,比如:</p><pre><code>str1=&#39;a&#39;str1=&#39;b&#39;</code></pre><p>这是允许的,但是字符串’a’并没有被改变,只不过是str1这个指针现在指向了’b’这个对象.<br>如果需要修改可以使用StringBuffer或者StringBuilder类<br>5大常用方法:length(),substring(),charAt(),indexOf(),lastIndexOf()</p><h2 id="运算符和-equals之间的区别"><a href="#运算符和-equals之间的区别" class="headerlink" title="==运算符和.equals之间的区别"></a>==运算符和.equals之间的区别</h2><p>==运算符判断的是地址,而不同的初始化函数出来的地址是不同的.<br>而equals函数判断的是内容. 如以下代码所示:</p><pre><code>package com.mpp.string; public class StringDemo5 { public static void main(String[] args) {        String str1 = &quot;mpp&quot;;        String str2 = &quot;mpp&quot;;        String str3 = new String(&quot;mpp&quot;);        System.out.println(str1.equals(str2)); //true  内容相同        System.out.println(str1.equals(str3));   //true  内容相同        System.out.println(str1==str2);   //true   地址相同        System.out.println(str1==str3);   //false  地址不同 }}</code></pre><h2 id="字符串拼接"><a href="#字符串拼接" class="headerlink" title="字符串拼接"></a>字符串拼接</h2><p>Java中的拼接是使用转换成StringBuffer对象再转换回来这种方式来实现的.所以最好不要使用拼接,会有大量的中间变量</p><p>StringBuffer这个类是线程安全的,所有的修改数据的方法都有synchronized关键字,但是效率比较低</p><p>StringBuilder是线程不安全的,所以他比较快.</p><p>注意最好在StringBuffer声明的时候就限定好capacity,避免扩容,开销比较大.</p><p>delete的本质是把其余字符重新拷贝到字符数组.</p><h2 id="String和JVM"><a href="#String和JVM" class="headerlink" title="String和JVM"></a>String和JVM</h2><p>这里直接引用别人的定义来解释这4个名次:<br>Java栈（线程私有数据区）：</p><pre><code>每个Java虚拟机线程都有自己的Java虚拟机栈，Java虚拟机栈用来存放栈帧，每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</code></pre><p>Java堆（线程共享数据区）：</p><pre><code>在虚拟机启动时创建，此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配。</code></pre><p>方法区（线程共享数据区）：</p><pre><code>方法区在虚拟机启动的时候被创建，它存储了每一个类的结构信息，例如运行时常量池、字段和方法数据、构造函数和普通方法的字节码内容、还包括在类、实例、接口初始化时用到的特殊方法。在JDK8之前永久代是方法区的一种实现，而JDK8元空间替代了永久代，永久代被移除，也可以理解为元空间是方法区的一种实现。</code></pre><p>常量池（线程共享数据区）：</p><pre><code>常量池常被分为两大类：静态常量池和运行时常量池。静态常量池也就是Class文件中的常量池，存在于Class文件中。运行时常量池（Runtime Constant Pool）是方法区的一部分，存放一些运行时常量数据。</code></pre><p>字符串常量池:</p><pre><code>字符串常量池存在运行时常量池之中（在JDK7之前存在运行时常量池之中，在JDK7已经将其转移到堆中）。字符串常量池的存在使JVM提高了性能和减少了内存开销。使用字符串常量池，每当我们使用字面量（String s=”1”;）创建字符串常量时，JVM会首先检查字符串常量池，如果该字符串已经存在常量池中，那么就将此字符串对象的地址赋值给引用s（引用s在Java栈中）。如果字符串不存在常量池中，就会实例化该字符串并且将其放到常量池中，并将此字符串对象的地址赋值给引用s（引用s在Java栈中）。使用字符串常量池，每当我们使用关键字new（String s=new String(”1”);）创建字符串常量时，JVM会首先检查字符串常量池，如果该字符串已经存在常量池中，那么不再在字符串常量池创建该字符串对象，而直接堆中复制该对象的副本，然后将堆中对象的地址赋值给引用s，如果字符串不存在常量池中，就会实例化该字符串并且将其放到常量池中，然后在堆中复制该对象的副本，然后将堆中对象的地址赋值给引用s。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
            <tag> String </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列2: 自动装箱与拆箱</title>
      <link href="/2019/11/04/java-ji-chu-xi-lie-2-zi-dong-zhuang-xiang-yu-chai-xiang/"/>
      <url>/2019/11/04/java-ji-chu-xi-lie-2-zi-dong-zhuang-xiang-yu-chai-xiang/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列2-自动装箱与拆箱"><a href="#Java基础系列2-自动装箱与拆箱" class="headerlink" title="Java基础系列2: 自动装箱与拆箱"></a>Java基础系列2: 自动装箱与拆箱</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="内置数据类型"><a href="#内置数据类型" class="headerlink" title="内置数据类型"></a>内置数据类型</h2><ul><li>byte:8位的,-128到127,默认值为0</li><li>short:16位,(-32768,32767),默认值为0</li><li>int:32位</li><li>long:64位,默认值0L</li><li>float:32位,默认值0.0f</li><li>double:64位,默认值0.0d</li><li>boolean:1位,默认值false</li><li>char:16位</li></ul><h2 id="引用数据类型"><a href="#引用数据类型" class="headerlink" title="引用数据类型"></a>引用数据类型</h2><p>对象,数组都是引用数据类型,所有的引用数据类型默认值都是null</p><h2 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h2><p>final关键字定义的值就是常量,通常全部使用大写来表示不可更改</p><h2 id="自动拆箱和装箱"><a href="#自动拆箱和装箱" class="headerlink" title="自动拆箱和装箱"></a>自动拆箱和装箱</h2><p>包装器类型,比如Ingeter,是对应于基本的内置数据类型,对应于valueOf和xxxValue两个方法.</p><h2 id="不同数据类型的存储位置"><a href="#不同数据类型的存储位置" class="headerlink" title="不同数据类型的存储位置"></a>不同数据类型的存储位置</h2><p>1,局部变量存在栈中<br>eg:</p><pre><code>public void(int a){int i = 1;int j = 1;}</code></pre><p>2,实例存在堆中,实例的属性也存在堆中<br>eg:</p><pre><code>class A{int i = 1;A a = new A();}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
            <tag> 自动装箱与拆箱 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础系列1:三大特性</title>
      <link href="/2019/11/02/java-ji-chu-xi-lie-1-san-da-te-xing/"/>
      <url>/2019/11/02/java-ji-chu-xi-lie-1-san-da-te-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="Java基础系列1：三大特性"><a href="#Java基础系列1：三大特性" class="headerlink" title="Java基础系列1：三大特性"></a>Java基础系列1：三大特性</h1><p>本文是作者的读书笔记和心得整理，部分内容来源于网络，如有侵权，请联系作者。</p><h2 id="何为对象"><a href="#何为对象" class="headerlink" title="何为对象"></a>何为对象</h2><p>对象就是instance，也可以说是实例，指的是现实世界中的实体，比如一个人，一个小狗，一粒沙子，都是一个对象。<br>对象有以下的特征：</p><ul><li>对象具有属性和行为</li><li>对象具有唯一性</li><li>对象都是某个类别的实例</li><li>一切皆为对象，真实世界中的所有事物都可以视为对象</li></ul><h2 id="面向对象和面向过程的区别"><a href="#面向对象和面向过程的区别" class="headerlink" title="面向对象和面向过程的区别"></a>面向对象和面向过程的区别</h2><p>面向过程的本质是先后顺序，也就是先有一个流程，然后对每个流程都使用函数一步一步实现，从而最后实现整个过程。<br>典型语言是C语言。</p><p>面向对象的本质是函数，每个函数完成一个功能，有输入和输出。最后有一个主函数按照想要的顺序调用这些函数即可。</p><p>面向过程的缺陷是在初始设计阶段，就要完整的设计好每个模块的流程，每个小模块要干什么，要处理哪些数据都要想清楚，不能乱了次序；<br>设计不够直观，非常不人性化，代码的复用性非常差。</p><p>面向对象的优点是可以多次复用，最小的代码单元是类，可以更好的开发不同的模块和复用。</p><h2 id="核心特性1：继承"><a href="#核心特性1：继承" class="headerlink" title="核心特性1：继承"></a>核心特性1：继承</h2><p>继承就是子类继承父类的行为，比如猫是动物，动物可以呼吸，所以猫也可以呼吸；但是猫有的特性父类未必有，比如猫有爪子，而动物未必都有爪子。<br>示例图片：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cucnVub29iLmNvbS93cC1jb250ZW50L3VwbG9hZHMvMjAxMy8xMi8xNEIwOTUxRS1GQzc1LTQ3QTMtQjYxMS00RTE4ODM4ODczMzkuanBn?x-oss-process=image/format,png" alt></p><p>(图片来源于<a href="https://www.runoob.com/wp-content/uploads/2013/12/14B0951E-FC75-47A3-B611-4E1883887339.jpg" target="_blank" rel="noopener">https://www.runoob.com/wp-content/uploads/2013/12/14B0951E-FC75-47A3-B611-4E1883887339.jpg</a>)</p><h3 id="单继承和多继承"><a href="#单继承和多继承" class="headerlink" title="单继承和多继承"></a>单继承和多继承</h3><p>Java中默认使用的是单继承，并不支持多继承，从而避免继承的两个父类中同名方法冲突的困扰。而且继承的内容仅限于public的方法，private的方法并不会被子类继承。<br>但是可以通过内部类继承其他类来强行实现多继承，具体实现方法是创建一个匿名内部类继承另外一个类A，从而调用A中的函数来实现本类函数。<br>示例代码：</p><pre><code>public class Son extends Father{public void go () {System.out.println(&quot;son go&quot;);}public void eat () {System.out.println(&quot;son eat&quot;);}public void sleep() {System.out.println(&quot;zzzzzz&quot;);}public void cook() {//匿名内部类实现的多继承new Mother().cook();//内部类继承第二个父类来实现多继承Mom mom = new Mom();mom.cook();}private class Mom extends Mother {@Overridepublic void cook() {System.out.println(&quot;mom cook&quot;);}}}</code></pre><h3 id="函数的重写"><a href="#函数的重写" class="headerlink" title="函数的重写"></a>函数的重写</h3><p>当子类和父类中的函数名，变量，返回值都完全一致时，优先调用子类函数。<br>注意必须完全一致，否则只会重载。Java是允许多个函数名一样但是参数不同的。</p><h3 id="继承的初始化顺序"><a href="#继承的初始化顺序" class="headerlink" title="继承的初始化顺序"></a>继承的初始化顺序</h3><p>1，先初始化父类，再初始化子类；</p><p>2，先执行初始化对象中属性，再执行构造方法中初始化；</p><p>所以整体的执行顺序是：<br><strong>父类对象属性初始化—-&gt;父类对象构造方法—-&gt;子类对象属性初始化—&gt;子类对象构造方法</strong>　　</p><h3 id="final关键字"><a href="#final关键字" class="headerlink" title="final关键字"></a>final关键字</h3><p>final类：不允许被继承<br>final方法：不允许被重写<br>final属性：初始化必须有值或者在构造方法中赋值，无默认值，之后无法更改<br>final变量：只能初始化的时候赋值，所以是常量</p><h2 id="核心特性2：多态"><a href="#核心特性2：多态" class="headerlink" title="核心特性2：多态"></a>核心特性2：多态</h2><p>多态是指一个行为具有多个不同的表现形式，体现在java中就是实现同一个接口的同名方法，可能有完全不同的效果。<br>比如都实现接口run，一个是程序‘运行‘，一个是人’跑‘。取决于到底是哪个类实现了这个接口。<br>如下图所示:</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2MuYmlhbmNoZW5nLm5ldC91cGxvYWRzL2FsbGltZy8xODEwMTcvMy0xUTAxRzQwOTViVy5qcGc?x-oss-process=image/format,png" alt></p><p>(图片引用自:<a href="https://c.biancheng.net/uploads/allimg/181017/3-1Q01G4095bW.jpg" target="_blank" rel="noopener">https://c.biancheng.net/uploads/allimg/181017/3-1Q01G4095bW.jpg</a>)</p><p>一个很大的好处是需要更新实现方式的时候可以无需修改之前的索引,而是重新定义一个新的继承接口就好啦</p><h3 id="重写和重载"><a href="#重写和重载" class="headerlink" title="重写和重载"></a>重写和重载</h3><p>重写适用于函数的名字和参数完全一致,此时子类函数覆盖父类函数;<br>重载适用于函数名字相投,参数不同,此时根据传入参数调用不同的函数.</p><h2 id="核心特性3：封装"><a href="#核心特性3：封装" class="headerlink" title="核心特性3：封装"></a>核心特性3：封装</h2><p>封装主要体现在私有属性和私有方法上，也就是一个类的私有属性和函数只能被当前对象所调用，外界只能访问到public的属性和方法。<br>封装的好处是保护自己的代码不被外部修改，或者内部的改动不为外部所知，比如U盘的内部逻辑我们并不关心，只要插上符合标准就行。<br>主要使用get/set方法进行实现.</p><h3 id="this关键字"><a href="#this关键字" class="headerlink" title="this关键字"></a>this关键字</h3><p>调用本类的实例,函数和属性</p><h3 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h3><p>几个原则:<br>1,不允许其他类访问内部类<br>2,内部类可以直接访问外部类的所有资源,包括private</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
            <tag> 三大特性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop</title>
      <link href="/2019/11/01/hadoop/"/>
      <url>/2019/11/01/hadoop/</url>
      
        <content type="html"><![CDATA[<h1 id="整理50个hadoop相关的面试题"><a href="#整理50个hadoop相关的面试题" class="headerlink" title="整理50个hadoop相关的面试题"></a>整理50个hadoop相关的面试题</h1><pre><code>https://blog.csdn.net/WYpersist/article/details/80262066</code></pre><h2 id="列出Hadoop集群的Hadoop守护进程和相关的角色。"><a href="#列出Hadoop集群的Hadoop守护进程和相关的角色。" class="headerlink" title="列出Hadoop集群的Hadoop守护进程和相关的角色。"></a>列出Hadoop集群的Hadoop守护进程和相关的角色。</h2><p>Namenode：它运行上Master节点上，负责存储的文件和目录所有元数据。它管理文件的块信息，以及块在集群中分布的信息。<br>Datanode：它是一个存储实际数据的Slave节点。它定时向Namenode发送本节点上块的信息。<br>Secondary Namenode：它会定期通过Editlog合并NameNode的变化，从而它r的日志不会过大。它可以在NameNode的故障的情况下做为副本使用。<br>JobTracker：这是运行在Namenode上，负责提交和跟踪MapReduce Job的守护程序。它会向Tasktracker分配的任务。<br>TaskTracker：这是Datanode上运行的守护进程。它在Slave节点上负责具体任务的运行。<br>ResourceManager的（Hadoop的2.X）：它负责YARN上运行的资源和调度。</p><p>NodeManager（Hadoop的2.X）：它可以运行在Slave节点，并负责启动应用程序的容器，监测他们的资源使用情况（CPU，内存，磁盘，网络），并报告这些到ResourceManager。</p><p>JobHistoryServer（Hadoop的2.X）：它维护有关的MapReduce工作中的应用终止后的信息。</p><h2 id="什么是主动和被动的namenodes"><a href="#什么是主动和被动的namenodes" class="headerlink" title="什么是主动和被动的namenodes"></a>什么是主动和被动的namenodes</h2><p>在Hadoop的2.x中，我们有两个Namenodes-主动“Namenode” 被动“Namenode”。主动“Namenode”是在集群中运行的Namenode。被动“的Namenode”是一个备用“的Namenode”，里面有主动“的Namenode”的数据。当主动“Namenode”失败，则被动“Namenode”集群中替换主动“Namenode”。因此，集群是从来不会没有“Namenode”，所以它永远不会失败。</p><h2 id="怎样才能删除或Hadoop集群添加节点？"><a href="#怎样才能删除或Hadoop集群添加节点？" class="headerlink" title="怎样才能删除或Hadoop集群添加节点？"></a>怎样才能删除或Hadoop集群添加节点？</h2><p>修改所有机器的hosts文件和/home/hadoop/hadoop/conf下slaves文件，切换到hosts文件在文件的后面添加新节点的ip和机器名：192.168.56.204 slaves，再切换到hadoop用户，在slaves文件后面添加slave4</p><h2 id="当两个客户端尝试访问对HDFS相同的文件，会发生什么？"><a href="#当两个客户端尝试访问对HDFS相同的文件，会发生什么？" class="headerlink" title="当两个客户端尝试访问对HDFS相同的文件，会发生什么？"></a>当两个客户端尝试访问对HDFS相同的文件，会发生什么？</h2><p>HDFS只支持独占写入。</p><p>当第一个客户端连接“Namenode”打开文件进行写入时，“Namenode”授予租约的客户端创建这个文件。当第二个客户端试图打开同一个文件写入时，“Namenode”会注意到该文件的租约已经授予给另一个客户端，并拒绝第二个客户端打开请求.</p><h2 id="为什么我们有时会得到一个“文件只能被复制到0节点，而不是1”的错误？"><a href="#为什么我们有时会得到一个“文件只能被复制到0节点，而不是1”的错误？" class="headerlink" title="为什么我们有时会得到一个“文件只能被复制到0节点，而不是1”的错误？"></a>为什么我们有时会得到一个“文件只能被复制到0节点，而不是1”的错误？</h2><p>这是因为“的Namenode”没有任何可用的DataNodes。</p><h2 id="如何在HDFS定义“block”？Hadoop1和2中Hadoop块大小是多少？是否可以改变？"><a href="#如何在HDFS定义“block”？Hadoop1和2中Hadoop块大小是多少？是否可以改变？" class="headerlink" title="如何在HDFS定义“block”？Hadoop1和2中Hadoop块大小是多少？是否可以改变？"></a>如何在HDFS定义“block”？Hadoop1和2中Hadoop块大小是多少？是否可以改变？</h2><p>“块”是可被读取或写入的数据的最小量。 HDFS中的文件被分解成块大小的块，它们被存储作为独立的单元。<br>Hadoop的1默认块大小：64 MB<br>Hadoop的2默认块大小：128 MB<br>是，块可以被配置。该dfs.block.size参数可在HDFS-site.xml文件被用来设置一个块的大小。</p><h2 id="你如何在Hadoop中定义“rack-awareness”？"><a href="#你如何在Hadoop中定义“rack-awareness”？" class="headerlink" title="你如何在Hadoop中定义“rack awareness”？"></a>你如何在Hadoop中定义“rack awareness”？</h2><p>它是在“Namenode”上确定块放置方式，以尽量减少在同一机架内“DataNodes”之间的网络流量的方式。比方说，我们考虑复制因子3（默认），该策略是“数据的每个块，两个副本将在一个机架中，第三个副本存在于不同的机架”。这条规则被称为“副本放置策略”。</p><h2 id="为什么Hadoop适用于大型数据集的应用程序，而不是具有大量的小文件的应用程序？"><a href="#为什么Hadoop适用于大型数据集的应用程序，而不是具有大量的小文件的应用程序？" class="headerlink" title="为什么Hadoop适用于大型数据集的应用程序，而不是具有大量的小文件的应用程序？"></a>为什么Hadoop适用于大型数据集的应用程序，而不是具有大量的小文件的应用程序？</h2><p>相较于在多个分布数据量小的文件 ，HDFS更适合在一个文件中具有大量的数据集。这是因为“Namenode”是非常昂贵的，高性能的系统中，它是不慎重的占据“Namenode”通过了为多个小文件生成的元数据的不必要量的空间。因此，当在一个单独文件中的大量的数据，“Namenode”将占据更少的空间。因此，为获得最佳的性能，HDFS支持大数据集，而不是多个小文件。</p><h2 id="什么是传统的关系型数据库和Hadoop之间的基本区别？"><a href="#什么是传统的关系型数据库和Hadoop之间的基本区别？" class="headerlink" title="什么是传统的关系型数据库和Hadoop之间的基本区别？"></a>什么是传统的关系型数据库和Hadoop之间的基本区别？</h2><p>传统的RDBMS是用于交易系统报告和存档数据，而Hadoop是存储和处理的分布式文件系统的海量数据的方法。当你想寻求大数据的一个记录RDBMS将是有益的。因此，当你在一次存储很大的文件并随后进行分析，Hadoop将是有益的。</p><h2 id="解释HDFS索引过程"><a href="#解释HDFS索引过程" class="headerlink" title="解释HDFS索引过程"></a>解释HDFS索引过程</h2><p>Hadoop的有它自己的索引数据的方式。取决于块大小，HDFS将继续存储数据的最后部分。它还会告诉你数据的下一部分的位置。</p><h2 id="什么是“speculative-running”在Hadoop中"><a href="#什么是“speculative-running”在Hadoop中" class="headerlink" title="什么是“speculative running”在Hadoop中"></a>什么是“speculative running”在Hadoop中</h2><p>如果一个节点出现运行一个任务较慢，主节点可以冗余另一个节点上执行同一任务的另一实例。这里，它第一个完成任务的将被接受，而另一个被杀死。这个过程被称为“speculative running”。</p><h2 id="为什么在HDFS，“读”是并行的，但“写”不是？"><a href="#为什么在HDFS，“读”是并行的，但“写”不是？" class="headerlink" title="为什么在HDFS，“读”是并行的，但“写”不是？"></a>为什么在HDFS，“读”是并行的，但“写”不是？</h2><p>使用的MapReduce程序，该文件可以通过分割成块被读取。不过，写入时MapReduce并行 不能适用。</p><h2 id="如果您在尝试访问HDFS或者其相应的文件得到一个“连接被拒绝Java异常’的错误会发生什么？"><a href="#如果您在尝试访问HDFS或者其相应的文件得到一个“连接被拒绝Java异常’的错误会发生什么？" class="headerlink" title="如果您在尝试访问HDFS或者其相应的文件得到一个“连接被拒绝Java异常’的错误会发生什么？"></a>如果您在尝试访问HDFS或者其相应的文件得到一个“连接被拒绝Java异常’的错误会发生什么？</h2><p>这可能意味着“Namenode”不工作了。“Namenode”可能是在“安全模式”或“Namenode”的IP地址可能改变了。</p><h2 id="“zookeeper”在Hadoop集群中的作用？"><a href="#“zookeeper”在Hadoop集群中的作用？" class="headerlink" title="“zookeeper”在Hadoop集群中的作用？"></a>“zookeeper”在Hadoop集群中的作用？</h2><p>“zookeeper”的目的是集群管理。 “zookeeper”将帮助你实现的Hadoop节点之间的协调。 也有助于：<br>管理跨节点配置<br>实现可靠的消息传递<br>实现冗余服务<br>同步流程执行</p><h1 id="MapReduce相关"><a href="#MapReduce相关" class="headerlink" title="MapReduce相关"></a>MapReduce相关</h1><h2 id="什么是“MapReduce的”？"><a href="#什么是“MapReduce的”？" class="headerlink" title="什么是“MapReduce的”？"></a>什么是“MapReduce的”？</h2><p>它是一个框架或用于通过使用分布式编程的计算机的集群处理大型数据集的编程模型。</p><h2 id="什么是运行“MapReduce的”程序的语法？"><a href="#什么是运行“MapReduce的”程序的语法？" class="headerlink" title="什么是运行“MapReduce的”程序的语法？"></a>什么是运行“MapReduce的”程序的语法？</h2><p>Hadoop jar file.jar / input_path / output_path</p><h2 id="为什么我们不能在一个映射器进行“聚合”（加法）的原因是什么？我们为什么需要这个了“reduce”？"><a href="#为什么我们不能在一个映射器进行“聚合”（加法）的原因是什么？我们为什么需要这个了“reduce”？" class="headerlink" title="为什么我们不能在一个映射器进行“聚合”（加法）的原因是什么？我们为什么需要这个了“reduce”？"></a>为什么我们不能在一个映射器进行“聚合”（加法）的原因是什么？我们为什么需要这个了“reduce”？</h2><p>因为排序不在“mapper”中发生。排序仅在reducer侧发生。在“mapper”的方法初始化取决于每个输入。在“聚合”时，我们将失去以前的实例的值。对于每一行，一个新的“mapper”将得到初始化。对于每一行，input split再次被分为“mapper”。因此，我们不能跟踪前一行的值。</p><h2 id="Hadoop中“RecordReader”的目的是什么？"><a href="#Hadoop中“RecordReader”的目的是什么？" class="headerlink" title="Hadoop中“RecordReader”的目的是什么？"></a>Hadoop中“RecordReader”的目的是什么？</h2><p>在“InputSplit”定义工作片，但并没有描述如何访问它。的“RecordReader”级从其源加载数据，并将其转换成适合于“mapper”读的（键，值）对。“RecordReader”实例是由“输入格式”中定义。</p><h2 id="什么是一个“MapReduce的分区”？分组？"><a href="#什么是一个“MapReduce的分区”？分组？" class="headerlink" title="什么是一个“MapReduce的分区”？分组？"></a>什么是一个“MapReduce的分区”？分组？</h2><p>分区的目的是根据Key值决定Mapper的输出记录被送到哪一个Reducer上去处理，从而允许“reducer”对应的map输出的平均分布。它通过确定哪个“reducer”是负责该特定键从而把map输出重定向给reducer。</p><p>分组：分组就是与记录的Key相关。在同一个分区里面，具有相同Key值的记录是属于同一个分组的</p><h1 id="Hive相关"><a href="#Hive相关" class="headerlink" title="Hive相关"></a>Hive相关</h1><h2 id="“hive”存储表中的数据的默认位置是？"><a href="#“hive”存储表中的数据的默认位置是？" class="headerlink" title="“hive”存储表中的数据的默认位置是？"></a>“hive”存储表中的数据的默认位置是？</h2><p>HDFS：//NameNode/用户/hive/warehouse</p><h2 id="解释在Hadoop中“Sqoop”。"><a href="#解释在Hadoop中“Sqoop”。" class="headerlink" title="解释在Hadoop中“Sqoop”。"></a>解释在Hadoop中“Sqoop”。</h2><p>“Sqoop”是用于一个RDBMS并在Hadoop HDFS之间传送数据的一种工具。使用“Sqoop”，数据可以从一个RDBMS（如MySQL或Oracle）插入HDFS以及从HDFS文件RDBMS出口数据传输。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NoSQL</title>
      <link href="/2019/09/16/nosql/"/>
      <url>/2019/09/16/nosql/</url>
      
        <content type="html"><![CDATA[<h1 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h1><p>MongoDB架构：<a href="https://zhuanlan.zhihu.com/p/98210524" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/98210524</a></p><h2 id="1-为什么要用mongodb-相对于关系型数据库有什么好处"><a href="#1-为什么要用mongodb-相对于关系型数据库有什么好处" class="headerlink" title="1.为什么要用mongodb?相对于关系型数据库有什么好处?"></a>1.为什么要用mongodb?相对于关系型数据库有什么好处?</h2><p>弱一致性（最终一致），更能保证用户的访问速度<br>文档结构的存储方式，能够更便捷的获取数据<br>GridFS是一个出色的分布式文件系统，可以支持海量的数据存储。内置了GridFS了MongoDB，能够满足对大数据集的快速范围查询<br>内置Sharding<br>性能优越</p><p>自动备份：<br>MongoDB可以提供副本集的高可用性。副本集由两个或多个mongo数据库实例组成。每个副本集成员可以随时充当主副本或辅助副本的角色。主副本是与客户端交互并执行所有读/写操作的主服务器。辅助副本使用内置复制维护主数据的副本。当主副本发生故障时，副本集将自动切换到辅助副本，然后它将成为主服务器。注意是异步同步的，所以是弱一致性。<br>Mysql是强一致性，优先保证从库的 relay log 中继日志更新落盘比主库返回给应用程序事务已提交早。</p><p>从NoSQL数据库的简介中可以看出，行（或在MongoDB中调用的文档）不需要预先定义架构。相反，可以动态创建字段。</p><h2 id="2-缺点"><a href="#2-缺点" class="headerlink" title="2.缺点"></a>2.缺点</h2><p>mongodb不支持事务操作<br>mongodb占用空间过大</p><h2 id="3-MongoDB的整体架构"><a href="#3-MongoDB的整体架构" class="headerlink" title="3.MongoDB的整体架构"></a>3.MongoDB的整体架构</h2><p><img src="https://s1.ax1x.com/2020/08/19/dlc9rF.png" alt="dlc9rF.png"></p><h2 id="4-MongoDB为什么快"><a href="#4-MongoDB为什么快" class="headerlink" title="4.MongoDB为什么快"></a>4.MongoDB为什么快</h2><p>写操作的快速，根本原因是MongoDB使用内存映射技术，写数据只要在内存完成就返回了，而flush的操作在后台异步完成。<br>安全性：默认开始日志，保证数据安全；对于复制来说，不用等到oplog刷新磁盘，在内存中就可以直接复制到Sencondary节点。</p><p>读操作快：<br>常用的数据在内存里装得下；<br>所需要的数据都相对集中在一起，减少磁头重定位<br>便于水平扩展，自动sharding。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NoSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础</title>
      <link href="/2019/08/06/java-ji-chu/"/>
      <url>/2019/08/06/java-ji-chu/</url>
      
        <content type="html"><![CDATA[<h1 id="JAVA基础"><a href="#JAVA基础" class="headerlink" title="JAVA基础"></a>JAVA基础</h1><h2 id="1-Java中的泛型有哪些应用-为什么要使用泛型"><a href="#1-Java中的泛型有哪些应用-为什么要使用泛型" class="headerlink" title="1.Java中的泛型有哪些应用?为什么要使用泛型."></a>1.Java中的泛型有哪些应用?为什么要使用泛型.</h2><p>在没有使用泛型的情况下，如果要实现参数“任意化”，通常会定义成Object类型来接受，然后强制类型转换使用；而强制类型转换有明显的缺点，就是必须要知道实际参数的具体类型的情况才可以进行转换，同时在强制转换的过程中，编译器不会报错提示的，只有在运行阶段才会出现异常，一定程度上存在安全隐患。<br>主要是用于定义公共类,比如hashmap的源码中,集合类的源码中.泛型可以用到容器，方法，接口，内部类，抽象类</p><h2 id="2-Java中的反射有哪些应用"><a href="#2-Java中的反射有哪些应用" class="headerlink" title="2.Java中的反射有哪些应用?"></a>2.Java中的反射有哪些应用?</h2><p>生成各种代理类,动态代理,调用不同的连接器等等.<br>JDBC数据库的连接:加载数据库驱动程序,根据地址用户和密码连接,使用connection接口接收连接.<br>xml的配置加载bean就是根据字符串获取class实例,动态配置实例属性.</p><h2 id="3-内存泄漏是怎么回事"><a href="#3-内存泄漏是怎么回事" class="headerlink" title="3.内存泄漏是怎么回事?"></a>3.内存泄漏是怎么回事?</h2><p>生命周期长引用了生命周期短的实例.</p><h2 id="4-final关键字"><a href="#4-final关键字" class="headerlink" title="4.final关键字"></a>4.final关键字</h2><p>当用final修饰一个类时，表明这个类不能被继承<br>修饰一个函数,不能被重写.<br>对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；<br>如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。</p><h2 id="5-设计模式了解哪些"><a href="#5-设计模式了解哪些" class="headerlink" title="5.设计模式了解哪些"></a>5.设计模式了解哪些</h2><p><a href="https://www.jianshu.com/p/bdf65e4afbb0" target="_blank" rel="noopener">https://www.jianshu.com/p/bdf65e4afbb0</a><br>简单工厂模式:根据不同的条件,返回不同的对象.<br>工厂模式:不同的工厂类实现同一个工厂接口,返回不同的产品.<br>抽象工厂模式:应对产品族,当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。<br>装饰者模式:动态的给某对象添加一些额外的功能<br>代理模式:封装被代理对象,并且限制外界对被代理对象的访问<br>模板方法模式:定义一个操作的算法骨架,并且将一些步骤延迟到子类中<br>外观模式:为系统向外界提供一个统一的接口<br>适配器模式:类似于三足插头,提供统一的接口标准,比如一个类可能有10个私有方法,但是对外只有3个接口方法.<br>桥接模式:把原本要耦合的上下层抽象出来,上层和下层使用组合的方式连接,这样一来就只需要set方法即可切换不同的子类,类似于切换桥的方向.<br>建造者模式:把builder单独抽象出来,可以使用lombok的builder方法.<br>观察者模式:定义了一种1对多的依赖关系,当Observable状态改变时通知所有Observer<br>单例模式:保证本类只有一个实例,并且提供一个访问他的全局控制点<br>命令模式:封装一系列命令,通过重写命令可以实现指定命令集的运行.</p><h3 id="6-如何实现多线程安全的单例模式"><a href="#6-如何实现多线程安全的单例模式" class="headerlink" title="6.如何实现多线程安全的单例模式:"></a>6.如何实现多线程安全的单例模式:</h3><p>直接放一个代码</p><pre><code>private static volatile SettingsDbHelper sInst = null;public static SettingsDbHelper getInstance(Context context) {      SettingsDbHelper inst = sInst;  // &lt;&lt;&lt; 在这里创建临时变量    if (inst == null) {        synchronized (SettingsDbHelper.class) {            inst = sInst;            if (inst == null) {                inst = new SettingsDbHelper(context);                sInst = inst;            }        }    }    return inst;  // &lt;&lt;&lt; 注意这里返回的是临时变量}</code></pre><p>这样一来,除了第一次访问,其他的访问单例都只会访问一次sInst变量</p><p>再加一个延迟初始化的方式:</p><pre><code>class Foo {      private static class HelperHolder {       public static final Helper helper = new Helper();    }    public static Helper getHelper() {        return HelperHolder.helper;    }}</code></pre><p>这个方法也可以保证延迟初始化,并且多线程安全.</p><p>或者更加粗暴一些:</p><pre><code>public enum Foo {      INSTANCE;}</code></pre><h2 id="7-设计原则了解哪些"><a href="#7-设计原则了解哪些" class="headerlink" title="7.设计原则了解哪些"></a>7.设计原则了解哪些</h2><p>1,单一职责原则:每个类只执行一个功能<br>2,里氏替换原则:父类出现的地方替换为子类必须可以出现<br>3,依赖倒置原则:类不应该从具体类派生出来,实现类之间没有依赖关系<br>4,接口隔离原则:类尽量实现接口<br>5,迪米特法则:一个对象应该对其他对象有最少的了解<br>6,开闭原则:软件实体应该对扩展开放,对修改关闭.</p><h2 id="8-谈谈垃圾回收"><a href="#8-谈谈垃圾回收" class="headerlink" title="8.谈谈垃圾回收"></a>8.谈谈垃圾回收</h2><p>见另外一个博客:深入理解JAVA虚拟机</p><h2 id="9-创建对象的方式"><a href="#9-创建对象的方式" class="headerlink" title="9.创建对象的方式"></a>9.创建对象的方式</h2><p>1,使用new关键字,调用任意的构造函数<br>2,使用反射</p><pre><code>//创建方法1User user = (User)Class.forName(&quot;根路径.User&quot;).newInstance();　//创建方法2（用这个最好）User user = User.class.newInstance();Constructor&lt;User&gt; constructor = User.class.getConstructor();User user = constructor.newInstance();</code></pre><p>3,实现Cloneable接口并且实现定义的clone方法</p><p>4,使用反序列化读出一个对象</p><h2 id="10-类初始化和加载的顺序"><a href="#10-类初始化和加载的顺序" class="headerlink" title="10.类初始化和加载的顺序"></a>10.类初始化和加载的顺序</h2><p>父类的静态变量&gt;子类静态变量&gt;父类的变量&gt;子类变量</p><h2 id="11-垃圾回收只回收堆中对象吗"><a href="#11-垃圾回收只回收堆中对象吗" class="headerlink" title="11.垃圾回收只回收堆中对象吗?"></a>11.垃圾回收只回收堆中对象吗?</h2><p>基本上是的,大部分对象都存在堆内存中</p><h2 id="12-如何保证不同线程之间隔离-同一线程共享"><a href="#12-如何保证不同线程之间隔离-同一线程共享" class="headerlink" title="12.如何保证不同线程之间隔离,同一线程共享"></a>12.如何保证不同线程之间隔离,同一线程共享</h2><p> ThreadLocal不是用于解决多线程共享资源的问题，因为每个线程都会备份ThreadLocal变量的副本，相当于对线程自身局部变量的操作，所以不存在资源同步的问题。ThreadLocal主要解决变量需要在线程内方法之间传递但在不同线程间隔离的问题。<br>每个访问 ThreadLocal 变量的线程都有自己的一个“本地”实例副本</p><h2 id="13-引用顺序"><a href="#13-引用顺序" class="headerlink" title="13.引用顺序"></a>13.引用顺序</h2><p>强引用:绝不会被回收<br>软引用:内存空间不足就会被回收<br>弱引用:一旦被发现就被回收<br>虚引用:被回收的时候会发一个消息</p><h2 id="14-说一下内存泄漏的场景"><a href="#14-说一下内存泄漏的场景" class="headerlink" title="14.说一下内存泄漏的场景"></a>14.说一下内存泄漏的场景</h2><p>应用程序不再使用对象，但是垃圾回收器无法删除它们，因为它们已被引用。</p><pre><code>class stack{        Object data[1000];        int top = -1;        public void push(Object o){                top++;                data[top] = o;            }        public Object pop(Object o){                top--;                return data[top+1];            }    }</code></pre><h2 id="15-如何防止基础类被破坏"><a href="#15-如何防止基础类被破坏" class="headerlink" title="15.如何防止基础类被破坏"></a>15.如何防止基础类被破坏</h2><p>双亲委派模型。<br>具体实现：<br><img src="https://s1.ax1x.com/2020/08/19/dlgQyT.png" alt="dlgQyT.png"></p><p>一个类在加载时会优先让父类加载器去加载，如果不行再使用自定义加载器加载。</p><h2 id="16-动态加载"><a href="#16-动态加载" class="headerlink" title="16.动态加载"></a>16.动态加载</h2><p>动态加载是使用反射实现的，而静态加载是使用new关键字，在编译期实现的。</p><h2 id="17-手写一下快排的代码"><a href="#17-手写一下快排的代码" class="headerlink" title="17.手写一下快排的代码"></a>17.手写一下快排的代码</h2><p>快速排序是挖坑填数+分治来实现的<br>快速排序的基本思想:<br>1．先从数列中取出一个数作为基准数。</p><p>2．分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。</p><p>3．再对左右区间重复第二步，直到各区间只有一个数。</p><p>挖坑法实现:</p><pre><code>public static void pothlingSort(int[] arrays , int low , int high){    if(low &lt; high){        //求每次分治的分割线        int divideIndex = getDivideIndex(arrays,low,high);        //再递归分别对分割的俩个子数组进行递归排序        pothlingSort(arrays,low,divideIndex -1);        pothlingSort(arrays,divideIndex + 1, high);    }}private static int getDivideIndex(int[] arrays, int low, int high) {    // 将数组最左端arrays[0]作为默认的基准值,将最左端的值放至基准值的坑内。    // 此时arrays[0]没有值了，需要从最右端找到一个比基准值小的数填至[0]这个坑。    // 再从左到右找到一个比基准值大的数填到刚才的坑。循环进行直到low=high    // 将基准值填至刚才的low位置。再进行分治    int baseValue = arrays[low];    arrays[low] =0 ; //挖个坑    while(low &lt;high){        //从右往左,找第一个比坑数小的数字        while(low &lt; high &amp;&amp; arrays[high] &gt;= baseValue){                high--;            }        arrays[low] = arrays[high] ;        arrays[high] = 0 ;        //从左往右,找第一个比坑大的数字        while(low &lt; high &amp;&amp; arrays[low] &lt;= baseValue){                low++;            }            arrays[high] = arrays[low] ;            arrays[low] = 0 ;    }    if(low == high){            arrays[low] = baseValue;        }        return low;    //最后坑填完了,返回坑,或者不返回}</code></pre><h2 id="18-java的跨平台性如何理解"><a href="#18-java的跨平台性如何理解" class="headerlink" title="18.java的跨平台性如何理解"></a>18.java的跨平台性如何理解</h2><p>JVM会把.java文件翻译成.class字节码文件,然后虚拟机识别平台,对应不同的平台转换为机器码.<br>注意不同平台下需要安装不同版本的JVM.</p><h2 id="19-String，StringBuilder，StringBuffer的区别，哪个是线程安全的"><a href="#19-String，StringBuilder，StringBuffer的区别，哪个是线程安全的" class="headerlink" title="19.String，StringBuilder，StringBuffer的区别，哪个是线程安全的"></a>19.String，StringBuilder，StringBuffer的区别，哪个是线程安全的</h2><p>String是不可变的常量.<br>StringBuffer是字符串变量（线程安全）,使用synchronized关键字来进行操作.<br>StringBuilder是字符串变量(线程不安全)但是快</p><h2 id="20-ArrayList，LinkedList的区别，适用场景，线程安全，如果要实现线程安全怎么办"><a href="#20-ArrayList，LinkedList的区别，适用场景，线程安全，如果要实现线程安全怎么办" class="headerlink" title="20.ArrayList，LinkedList的区别，适用场景，线程安全，如果要实现线程安全怎么办"></a>20.ArrayList，LinkedList的区别，适用场景，线程安全，如果要实现线程安全怎么办</h2><ol><li>ArrayList是实现了基于动态数组的数据结构，而LinkedList是基于链表的数据结构；</li><li>对于随机访问get和set，ArrayList要优于LinkedList，因为LinkedList要移动指针；</li></ol><p>都是线程不安全的,如果要安全可以用两种方法:</p><ol><li>List<string> list = Collections.synchronizedList(new LinkedList<string>());<br>也就是使用Collections.synchronizedList这个方法包装一下</string></string></li><li>或者用ConcurrentLinkedQueue代替linkedList<br>如果是要用Array的话,要使用CopyOnWriteArrayList,每次做更新操作都会做一次数组拷贝</li></ol><h2 id="21-TreeMap的线程安全问题"><a href="#21-TreeMap的线程安全问题" class="headerlink" title="21.TreeMap的线程安全问题"></a>21.TreeMap的线程安全问题</h2><p>线程不安全,也是同上两种方式:<br>Collections.synchronizedSortedSet/Collections.synchronizedSortedMap方法包装一下<br>ConcurrentSkipListMap/ConcurrentSkipListSet</p><h2 id="22-讲讲动态代理"><a href="#22-讲讲动态代理" class="headerlink" title="22.讲讲动态代理"></a>22.讲讲动态代理</h2><p>静态代理:就是单纯的封装一层,类似装饰者模式,拓展一些功能.<br>缺点:写死的类,会有很多的代理类和重复代码.</p><p>动态代理:使用反射来动态的获取不同的目标类,并且生成代理类<br>代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能用动态代理<br>static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h )使用这一行来实现代理<br>示例代码:</p><pre><code>/** * 创建动态代理对象 * 动态代理不需要实现接口,但是需要指定接口类型 */public class ProxyFactory{    //维护一个目标对象    private Object target;    public ProxyFactory(Object target){        this.target=target;    }   //给目标对象生成代理对象    public Object getProxyInstance(){        return Proxy.newProxyInstance(                target.getClass().getClassLoader(),                target.getClass().getInterfaces(),                new InvocationHandler() {                    @Override                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {                        System.out.println(&quot;开始事务2&quot;);                        //运用反射执行目标对象方法                        Object returnValue = method.invoke(target, args);                        System.out.println(&quot;提交事务2&quot;);                        return returnValue;                    }                }        );    }}</code></pre><p>如果目标对象只是一个单独的对象,并未实现接口,这时候就要用到子类代理.<br>Cglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展.<br>Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop,为他们提供方法的interception(拦截)</p><p>如果方法为private,static则无法进行代理.</p><p>在spring AOP中往往使用代理模式来进行切面编程</p><h2 id="23-介绍NIO"><a href="#23-介绍NIO" class="headerlink" title="23.介绍NIO"></a>23.介绍NIO</h2><p>NIO=Non-blocking I/O.是同步非阻塞的I/O模型<br>不同的IO模型:<br><img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/77752ed5.jpg" alt><br>NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）</p><h2 id="24-红黑树"><a href="#24-红黑树" class="headerlink" title="24.红黑树"></a>24.红黑树</h2><p>红黑树:二叉平衡搜索树<br>二叉排序树的性能取决于二叉树的层数,最好的情况是logn,完全二叉排序树,最差的情况是On,全部有序.</p><p>红黑树是在二叉查找树的基础上额外添加了一个标记,和一些规则.<br>红黑树保证了一种平衡，插入、删除、查找的最坏时间复杂度都为 O(logn)。</p><h3 id="黑色高度"><a href="#黑色高度" class="headerlink" title="黑色高度"></a>黑色高度</h3><p>从根节点到叶节点的路径上黑色节点的个数，叫做树的黑色高度。</p><p>一些规则:<br>每个节点要么是红色，要么是黑色；<br>根节点永远是黑色的；<br>所有的叶节点都是是黑色的（注意这里说叶子节点其实是上图中的 NIL 节点）；<br>每个红色节点的两个子节点一定都是黑色；<br>从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点；</p><p>性质 4 的意思是：从每个根到节点的路径上不会有两个连续的红色节点，但黑色节点是可以连续的。</p><h3 id="左旋和右旋"><a href="#左旋和右旋" class="headerlink" title="左旋和右旋"></a>左旋和右旋</h3><p><img src="https://s1.ax1x.com/2020/08/19/dl2YDS.png" alt="dl2YDS.png"></p><h3 id="红黑树的平衡插入"><a href="#红黑树的平衡插入" class="headerlink" title="红黑树的平衡插入"></a>红黑树的平衡插入</h3><p>红黑树的插入主要分两步：</p><p>首先和二叉查找树的插入一样，查找、插入<br>然后调整结构，保证满足红黑树状态<br>对结点进行重新着色<br>以及对树进行相关的旋转操作</p><p>前面说了，插入一个节点后要担心违反特征 4 和 5，数学里最常用的一个解题技巧就是把多个未知数化解成一个未知数。我们这里采用同样的技巧，把插入的节点直接染成红色，这样就不会影响特征 5，只要专心调整满足特征 4 就好了。这样比同时满足 4、5 要简单一些。</p><p>染成红色后，我们只要关心父节点是否为红，如果是红的，就要把父节点进行变化，让父节点变成黑色，或者换一个黑色节点当父亲，这些操作的同时不能影响 不同路径上的黑色节点数一致的规则。</p><h2 id="25-ConcurrentHashMap底层源码分析"><a href="#25-ConcurrentHashMap底层源码分析" class="headerlink" title="25.ConcurrentHashMap底层源码分析"></a>25.ConcurrentHashMap底层源码分析</h2><p>参考这篇文章:<br><a href="https://www.jasongj.com/java/concurrenthashmap/" target="_blank" rel="noopener">https://www.jasongj.com/java/concurrenthashmap/</a></p><h2 id="26-单例模式"><a href="#26-单例模式" class="headerlink" title="26.单例模式"></a>26.单例模式</h2><p>饿汉模式:</p><pre><code>public class Singleton{    private static Singleton instance = new Singleton();    private Singleton(){}    public static Singleton newInstance(){        return instance;    }}</code></pre><p>缺点:<br>从代码中我们看到，类的构造函数定义为private的，保证其他类不能实例化此类，然后提供了一个静态实例并返回给调用者。饿汉模式是最简单的一种实现方式，饿汉模式在类加载的时候就对实例进行创建，实例在整个程序周期都存在。<br>它的好处是只在类加载的时候创建一次实例，不会存在多个线程创建多个实例的情况，避免了多线程同步的问题。<br>它的缺点也很明显，即使这个单例没有用到也会被创建，而且在类加载之后就被创建，内存就被浪费了。<br>这种实现方式适合单例占用内存比较小，在初始化时就会被用到的情况。但是，如果单例占用的内存比较大，或单例只是在某个特定场景下才会用到，使用饿汉模式就不合适了，这时候就需要用到懒汉模式进行延迟加载。</p><p>懒汉:</p><pre><code>public class Singleton{    private static Singleton instance = null;    private Singleton(){}    public static Singleton newInstance(){        if(null == instance){            instance = new Singleton();        }        return instance;    }}</code></pre><p>好处：懒汉模式中单例是在需要的时候才去创建的，如果单例已经创建，再次调用获取接口将不会重新创建新的对象，而是直接返回之前创建的对象。<br>适用于：如果某个单例使用的次数少，并且创建单例消耗的资源较多，那么就需要实现单例的按需创建，这个时候使用懒汉模式就是一个不错的选择。<br>缺点：但是这里的懒汉模式并没有考虑线程安全问题，在多个线程可能会并发调用它的getInstance()方法，导致创建多个实例，因此需要加锁解决线程同步问题</p><p>线程安全版本懒汉:</p><pre><code>public class Singleton{    private static Singleton instance = null;    private Singleton(){}    public static synchronized Singleton newInstance(){        if(null == instance){  // Single Checked            instance = new Singleton();        }        return instance;    }}</code></pre><p>线程安全版本双重校验锁懒汉:</p><pre><code>public class Singleton {    private static Singleton instance = null;    private Singleton(){}    public static Singleton getInstance() {        if (instance == null) {   // Single Checked            synchronized (Singleton.class) {                if (instance == null) { // Double checked                    instance = new Singleton();                }            }        }        return instance;    }}</code></pre><p>但是还是有隐患,因为指令重排序:导致初始化Singleton和将对象地址赋给instance字段.<br>所以1.5之后加了这个东西:volatile<br>volatile是一个特殊的修饰符，只有成员变量才能使用它。<br>在Java并发程序缺少同步类的情况下，多线程对成员变量的操作对其它线程是透明的。<br>volatile变量可以保证下一个读取操作会在前一个写操作之后发生<br>双重校验+volatile实现饿汉模式</p><pre><code>public class Singleton {    private static volatile Singleton instance = null;    private Singleton(){}    public static Singleton getInstance() {        if (instance == null) { // Single Checked            synchronized (Singleton.class) {                if (instance == null) { // Double checked                    instance = new Singleton();                }            }        }        return instance;    }}</code></pre><p>静态内部类实现:</p><pre><code>public class Singleton{    private static class SingletonHolder{        public static Singleton instance = new Singleton();    }    private Singleton(){}    public static Singleton newInstance(){        return SingletonHolder.instance;    }}</code></pre><p>相对于饿汉模式,静态内部类只有在第一次被用到的时候才会加载.所以同时实现了延迟加载和线程安全</p><p>使用枚举类:</p><pre><code>class Resource{}public enum SomeThing {    INSTANCE;    private Resource instance;    private SomeThing() {        instance = new Resource();    }    public Resource getInstance() {        return instance;    }}</code></pre><p>上面的类Resource是我们要应用单例模式的资源，具体可以表现为网络连接，数据库连接，线程池等等。<br>获取资源的方式很简单，只要 SomeThing.INSTANCE.getInstance() 即可获得所要实例。<br>下面我们来看看单例是如何被保证的：<br>首先，在枚举中我们明确了构造方法限制为私有，在我们访问枚举实例时会执行构造方法。<br>同时每个枚举实例都是static final类型的，也就表明只能被实例化一次。在调用构造方法时，我们的单例被实例化。<br>也就是说，因为enum中的实例被保证只会被实例化一次，所以我们的INSTANCE也被保证实例化一次。 </p><p>缺点:<br>上面提到的四种实现单例的方式都有共同的缺点：<br>1）需要额外的工作来实现序列化，否则每次反序列化一个序列化的对象时都会创建一个新的实例。<br>2）可以使用反射强行调用私有构造器（如果要避免这种情况，可以修改构造器，让它在创建第二个实例的时候抛异常）</p><p>而枚举类很好的解决了这两个问题，使用枚举除了线程安全和防止反射调用构造器之外，还提供了自动序列化机制，防止反序列化的时候创建新的对象。</p><h2 id="27-讲讲happen-before"><a href="#27-讲讲happen-before" class="headerlink" title="27.讲讲happen-before"></a>27.讲讲happen-before</h2><p>如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</p><p>两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。</p><h2 id="28-触发新生代GC，如果存活对象总量大于survivor区容量，咋办？"><a href="#28-触发新生代GC，如果存活对象总量大于survivor区容量，咋办？" class="headerlink" title="28.触发新生代GC，如果存活对象总量大于survivor区容量，咋办？"></a>28.触发新生代GC，如果存活对象总量大于survivor区容量，咋办？</h2><p>先放到老年代,类似于大对象，如果老年代可用空间小于新生代存活对象所占空间，如果没有开启空间担保参数会直接触发Full GC，新生代老年代都进行回收</p><h2 id="29-如果任务很多，线程池的阻塞队列会撑爆内存的哪个区域？"><a href="#29-如果任务很多，线程池的阻塞队列会撑爆内存的哪个区域？" class="headerlink" title="29.如果任务很多，线程池的阻塞队列会撑爆内存的哪个区域？"></a>29.如果任务很多，线程池的阻塞队列会撑爆内存的哪个区域？</h2><p>堆，因为是存储的对象在堆上</p><h2 id="30-JMM是什么？"><a href="#30-JMM是什么？" class="headerlink" title="30.JMM是什么？"></a>30.JMM是什么？</h2><p>java内存模型</p><h2 id="31-GC-root有哪些？"><a href="#31-GC-root有哪些？" class="headerlink" title="31.GC root有哪些？"></a>31.GC root有哪些？</h2><p>1.虚拟机栈（栈帧中的本地变量表）中引用的对象；</p><p>2.方法区中的类静态属性引用的对象；</p><p>3.方法区中常量引用的对象；</p><p>4.本地方法栈中JNI（即一般说的Native方法）中引用的对象</p><h2 id="32-GC算法有哪些"><a href="#32-GC算法有哪些" class="headerlink" title="32.GC算法有哪些"></a>32.GC算法有哪些</h2><p>标记-清除，复制算法（新生代），标记-压缩（老年代），分代收集</p><h2 id="33-Synchronized底层"><a href="#33-Synchronized底层" class="headerlink" title="33.Synchronized底层"></a>33.Synchronized底层</h2><p>可以看到锁信息也是存在于对象的mark word中的。当对象状态为偏向锁（biasable）时，mark word存储的是偏向的线程ID；当状态为轻量级锁（lightweight locked）时，mark word存储的是指向线程栈中Lock Record的指针；当状态为重量级锁（inflated）时，为指向堆中的monitor对象的指针。</p><p>Java中的synchronized有偏向锁、轻量级锁、重量级锁三种形式，分别对应了锁只被一个线程持有、不同线程交替持有锁、多线程竞争锁三种情况。当条件不满足时，锁会按偏向锁-&gt;轻量级锁-&gt;重量级锁 的顺序升级。</p><h2 id="34-JAVA中有哪些基本数据类型"><a href="#34-JAVA中有哪些基本数据类型" class="headerlink" title="34.JAVA中有哪些基本数据类型"></a>34.JAVA中有哪些基本数据类型</h2><p>字符类型char，布尔类型boolean以及数值类型byte、short、int、long、float、double</p><h2 id="35-Integer包装类底层是怎么实现的"><a href="#35-Integer包装类底层是怎么实现的" class="headerlink" title="35.Integer包装类底层是怎么实现的?"></a>35.Integer包装类底层是怎么实现的?</h2><p>int 是基本数据类型，Integer是int的包装类，属于对象类型。<br>int类型的值直接储存在栈里，调用起来更效率。</p><p>Integer类型的值储存在堆里，它有自己的方法可以调用，有些特定的地方只能接收Integer类型而不能接收int类型。</p><p>例如集合的泛型，List<integer>,如果写List<int>会报错。往List<integer>里添加int类型数据也能成功是因为java从1.6开始提供了自动拆装箱的功能，所以不用我们手动去转换。</integer></int></integer></p><h2 id="36-原子类了解吗"><a href="#36-原子类了解吗" class="headerlink" title="36.原子类了解吗?"></a>36.原子类了解吗?</h2><p>参考文章:<a href="https://juejin.im/post/6844903683268804622" target="_blank" rel="noopener">https://juejin.im/post/6844903683268804622</a><br>原子类的优点是更加方便的更新一个原子对象.<br>基本使用:</p><pre><code>class AtomicDemo {    private AtomicInteger mAtomicInteger = new AtomicInteger();//如果没有指定值，默认是1    private void doAdd() {        for (int i = 0; i &lt; 5; i++) {            int value = mAtomicInteger.addAndGet(1);            System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + value);        }    }    public static void main(String[] args) {        AtomicDemo demo = new AtomicDemo();        new Thread(demo::doAdd, &quot;线程1&quot;).start();        new Thread(demo::doAdd, &quot;线程2&quot;).start();    }}//输出结果线程1---&gt;1线程1---&gt;2线程1---&gt;3线程2---&gt;4线程1---&gt;5线程2---&gt;6线程1---&gt;7线程2---&gt;8线程2---&gt;9线程2---&gt;10</code></pre><p>如何实现:<br>以AtomicInteger为原型来进行讲解:<br>比如getAndAdd这个方法,首先是获取内存中的值,最后会调用compareAndSetInt这个方法来完成最后的原子操作,使用CAS实现,如果不成功就一直循环.</p><h2 id="37-哈希冲突算法"><a href="#37-哈希冲突算法" class="headerlink" title="37.哈希冲突算法"></a>37.哈希冲突算法</h2><p>TODO</p>]]></content>
      
      
      <categories>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux</title>
      <link href="/2019/07/04/linux/"/>
      <url>/2019/07/04/linux/</url>
      
        <content type="html"><![CDATA[<h1 id="linux服务器部分-操作系统"><a href="#linux服务器部分-操作系统" class="headerlink" title="linux服务器部分/操作系统"></a>linux服务器部分/操作系统</h1><h2 id="1-怎么查看日志-如果只想看日志的最底端-用什么命令-如果想在日志里检索关键词-用什么命令"><a href="#1-怎么查看日志-如果只想看日志的最底端-用什么命令-如果想在日志里检索关键词-用什么命令" class="headerlink" title="1.怎么查看日志?如果只想看日志的最底端,用什么命令?如果想在日志里检索关键词,用什么命令?"></a>1.怎么查看日志?如果只想看日志的最底端,用什么命令?如果想在日志里检索关键词,用什么命令?</h2><p>使用tail -f test.log,查看最底端正在改变的文件.</p><p>head是查看前多少行日志.</p><p>cat是查看关键字的日志.</p><p>cat -n test.log |grep “debug”得到关键字行号<br>grep是查看关键字</p><p>tac和cat是相反的,cat可以显示整个文件.<br>cat可以合并文件.cat file1 file2 &gt; file</p><p>cat -n test.log |grep “debug” |more     分页打印,空格翻页<br>cat -n test.log |grep “debug”  &gt;debug.txt 拉下来查询</p><h2 id="2-如何查看cpu使用情况-如果查看硬盘使用情况"><a href="#2-如何查看cpu使用情况-如果查看硬盘使用情况" class="headerlink" title="2.如何查看cpu使用情况?如果查看硬盘使用情况?"></a>2.如何查看cpu使用情况?如果查看硬盘使用情况?</h2><p>top命令查看cpu使用情况<br>df -h查看硬盘使用情况</p><h2 id="3-僵尸进程是什么"><a href="#3-僵尸进程是什么" class="headerlink" title="3.僵尸进程是什么?"></a>3.僵尸进程是什么?</h2><p>孤儿进程: 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。<br>僵尸进程: 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程.<br>简单来说就是父进程没调用wait导致子进程的进程号没有被回收.</p><h2 id="4-内核态和用户态"><a href="#4-内核态和用户态" class="headerlink" title="4.内核态和用户态"></a>4.内核态和用户态</h2><p>权限不同。用户态的进程能够访问的资源受到了极大的控制，而运行在内核态的进程可以“为所欲为”.<br><strong>系统调用:</strong>这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。<br><strong>异常：</strong>当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。<br><strong>外设中断：</strong>当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</p><h2 id="5-什么是INode"><a href="#5-什么是INode" class="headerlink" title="5.什么是INode"></a>5.什么是INode</h2><p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p><p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。</p><p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。</p><p>每一个文件都有对应的inode，里面包含了与该文件有关的一些元信息。<br>可以用stat命令，查看某个文件的inode信息。<br>每个inode都有一个号码，操作系统用inode号码来识别不同的文件。</p><p>目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。</p><h3 id="硬链接"><a href="#硬链接" class="headerlink" title="硬链接"></a>硬链接</h3><p>可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问<br>创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。</p><h3 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h3><p>文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）。也就是指向文件名，但不是iNode</p><h3 id="iNode的特殊用法"><a href="#iNode的特殊用法" class="headerlink" title="iNode的特殊用法"></a>iNode的特殊用法</h3><p>由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。</p><p>　　1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。</p><p>　　2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。</p><p>　　3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。</p><p>第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。</p><h2 id="6-如果在日志中查找指定顺序怎么办"><a href="#6-如果在日志中查找指定顺序怎么办" class="headerlink" title="6.如果在日志中查找指定顺序怎么办"></a>6.如果在日志中查找指定顺序怎么办</h2><p>使用sort命令进行排序，使用awk命令进行统计</p><p>#排序功能 -t表示用@作为分割符，-k表示用分割出来的第几个域排序(不要漏掉后面的,2/,3/,1，详细意思看下面的参考链接，这里不做详述)<br>sed -f test.sed demolog.log | sort -t@ -k2,2n -k3,3r -k1,1                  #n为按数字排序，r为倒序</p><h2 id="7-用户线程和内核线程"><a href="#7-用户线程和内核线程" class="headerlink" title="7.用户线程和内核线程"></a>7.用户线程和内核线程</h2><p>（1）内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。</p><p>（2）用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。</p><p>（3）用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。</p><p>（4）在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。</p><p>（5）用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。</p><h2 id="8-什么是多线程-为什么要使用多线程"><a href="#8-什么是多线程-为什么要使用多线程" class="headerlink" title="8.什么是多线程,为什么要使用多线程"></a>8.什么是多线程,为什么要使用多线程</h2><p>进程:CPU所能处理的单个任务<br>线程:资源调度的最小单位,进程中的一个单一顺序的控制流</p><p>多线程:一个进程开启多个线程,并发执行.</p><p>使用多线程可以加速IO密集型任务的运作效率,减少阻塞和等待.</p><p>未必,如果是CPU密集型任务,多线程反而慢</p><h2 id="9-怎么开启多线程"><a href="#9-怎么开启多线程" class="headerlink" title="9.怎么开启多线程"></a>9.怎么开启多线程</h2><p>创建一个线程,然后start;<br>或者用线程池;</p><h2 id="10-什么是虚拟内存"><a href="#10-什么是虚拟内存" class="headerlink" title="10.什么是虚拟内存"></a>10.什么是虚拟内存</h2><p>虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）;<br>实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。<br>Linux通过将一个虚拟内存区域与一个硬盘上的文件关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射（memory mapping）。这种将虚拟内存系统集成到文件系统的方法可以简单而高效地把程序和数据加载到内存中。</p><p>一个区域可以映射到一个普通硬盘文件的连续部分，例如一个可执行目标文件。文件区（section）被分成页大小的片，每一片包含一个虚拟页的初始内容。由于按需页面调度的策略，这些虚拟页面没有实际交换进入物理内存，直到CPU引用的虚拟地址在该区域的范围内。如果区域比文件区要大，那么就用零来填充这个区域的余下部分。</p><h2 id="11-线程都有哪些状态"><a href="#11-线程都有哪些状态" class="headerlink" title="11.线程都有哪些状态"></a>11.线程都有哪些状态</h2><p>初始状态-就绪状态-运行中-阻塞-等待-超时等待-终止.</p><h2 id="12-Cookie和SessionId说一下"><a href="#12-Cookie和SessionId说一下" class="headerlink" title="12.Cookie和SessionId说一下"></a>12.Cookie和SessionId说一下</h2><p>Cookie: 相当于是服务器生成的一个包裹,发给浏览器,每次浏览器发信息都带上它,服务器可以从中读出信息.<br>Session: 主要信息不存在与包裹内,而是存在服务器,包裹里只是存了一个银行卡,用于从服务器中检索信息.</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Srping</title>
      <link href="/2019/06/25/spring/"/>
      <url>/2019/06/25/spring/</url>
      
        <content type="html"><![CDATA[<h2 id="1-如何配置一个bean？"><a href="#1-如何配置一个bean？" class="headerlink" title="1.如何配置一个bean？"></a>1.如何配置一个bean？</h2><p>使用XML配置<br>使用注解配置:在bean实现类上使用@Component定义<br>使用Java类配置: 在标注了@Configuration的java类中,在类方法上标注@Bean来定义bean<br><img src="https://s1.ax1x.com/2020/07/27/aPEKMQ.png" alt="aPEKMQ.png"></p><h2 id="2-如何解决依赖循环问题"><a href="#2-如何解决依赖循环问题" class="headerlink" title="2.如何解决依赖循环问题"></a>2.如何解决依赖循环问题</h2><p>主要参考文章:<a href="https://zhuanlan.zhihu.com/p/84267654" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/84267654</a><br>Spring是通过递归的方式获取目标bean及其所依赖的bean的；<br>Spring实例化一个bean的时候，是分两步进行的，首先实例化目标bean，然后为其注入属性。</p><p>Spring 如何解决的<br>Spring 为了解决单例的循环依赖问题，使用了 三级缓存 ，递归调用时发现 Bean 还在创建中即为循环依赖<br>单例模式的 Bean 保存在如下的数据结构中：</p><pre><code>/** 一级缓存：用于存放完全初始化好的 bean **/private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);/** 二级缓存：存放原始的 bean 对象（尚未填充属性），用于解决循环依赖 */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);/** 三级级缓存：存放 bean 工厂对象，用于解决循环依赖 */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);/**bean 的获取过程：先从一级获取，失败再从二级、三级里面获取创建中状态：是指对象已经 new 出来了但是所有的属性均为 null 等待被 init*/</code></pre><p>检测循环依赖的过程如下：</p><p>A 创建过程中需要 B，于是 A 将自己放到三级缓里面 ，去实例化 B<br>B 实例化的时候发现需要 A，于是 B 先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了！<br>然后把三级缓存里面的这个 A 放到二级缓存里面，并删除三级缓存里面的 A<br>B 顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态）<br>然后回来接着创建 A，此时 B 已经创建结束，直接从一级缓存里面拿到 B ，然后完成创建，并将自己放到一级缓存里面<br>如此一来便解决了循环依赖的问题</p><p>一句话：先让最底层对象完成初始化，通过三级缓存与二级缓存提前曝光创建中的 Bean，让其他 Bean 率先完成初始化。</p><p>仍然存在的问题:<br>Spring 还是有一些无法解决的循环依赖，需要我们写代码的时候注意，例如：使用构造器注入其他 Bean 的实例，这个就没办法了。要手动改代码</p><h2 id="3-什么是IOC和依赖倒置"><a href="#3-什么是IOC和依赖倒置" class="headerlink" title="3.什么是IOC和依赖倒置?"></a>3.什么是IOC和依赖倒置?</h2><p>把原本的高层建筑依赖底层建筑“倒置”过来，变成底层建筑依赖高层建筑。高层建筑决定需要什么，底层去实现这样的需求，但是高层并不用管底层是怎么实现的。这样就不会出现前面的“牵一发动全身”的情况。</p><p>依赖注入:高层按照需要定义接口，底层按照高层定义的接口实现接口。<br>所谓依赖注入，就是把底层类作为参数传入上层类，实现上层类对下层类的“控制”<br>好处是在初始化的过程中就避免的会写大量的new。容器可以自动对你的代码进行初始化，你只需要维护一个Configuration（可以是xml可以是一段代码），而不用每次初始化都要亲手去写那一大段初始化的代码.<br>我们在创建实例的时候不需要了解其中的细节.比如这个例子:<br><img src="https://pic2.zhimg.com/80/v2-24a96669241e81439c636e83976ba152_1440w.jpg?source=1940ef5c" alt></p><h2 id="4-Spring从接受一个请求到控制器处理的全过程"><a href="#4-Spring从接受一个请求到控制器处理的全过程" class="headerlink" title="4.Spring从接受一个请求到控制器处理的全过程"></a>4.Spring从接受一个请求到控制器处理的全过程</h2><p><img src="https://sishuok.com/forum/upload/2012/7/14/57ea9e7edeebd5ee2ec0cf27313c5fb6__2.JPG" alt><br>1、  首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；</p><p>2、  DispatcherServlet——&gt;HandlerMapping， HandlerMapping将会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象，通过这种策略模式，很容易添加新的映射策略；</p><p>3、  DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；</p><p>4、  HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）；</p><p>5、  ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；</p><p>6、  View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；</p><p>7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。</p><h2 id="5-Hytrix的具体应用-是否是单点的"><a href="#5-Hytrix的具体应用-是否是单点的" class="headerlink" title="5.Hytrix的具体应用,是否是单点的"></a>5.Hytrix的具体应用,是否是单点的</h2><p>主要参考这篇文章:<br><a href="https://www.jianshu.com/p/16440d0ce457" target="_blank" rel="noopener">https://www.jianshu.com/p/16440d0ce457</a><br>Hystrix 是一个在调用端上，实现断路器模式，以及隔舱模式，通过避免级联故障，提高系统容错能力，从而实现高可用设计的一个 Java 类库。<br>Hystrix 的主要目的是保护跨进程调用，避免因为超时等问题，导致的级联故障。Hystrix 的实现方法是封装跨进程调用。具体的使用方式有多种：从编程方式看可分为编程方式和注解方式两种；从调用方式看可分为同步调用方式、异步调用方式和反应式调用方式三种。</p><p>基本方式是使用内部类,或者全局配置.</p><p>首先要定义GroupKey<br>HystrixCommandGroupKey 的作用主要有两个：</p><p>一是起到分组监控、报警的作用。后面的文章会对监控等方面进行介绍；<br>二是在不配置 HystrixThreadPoolKey 的情况下，起到分组线程池的作用。即默认使用 HystrixCommandGroupKey 去命名线程池。使用同一个 HystrixCommandGroupKey 且没有自定义 HystrixThreadPoolKey 的 HystrixCommand 将使用同一个线程池。</p><p>然后要定义Command Thread-Pool<br>主要是来具体定义线程池的实现<br>这是一些相关的参数:<br>andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(“MyThreadPool”)) 这是配置 ThreadPoolKey。如果需要在同一个 GroupKey 下面配置不同的 ThreadPool 就需要这个配置。<br>withCoreSize(10) 用来配置线程池大小。Hystrix 对线程池的配置有一些限制，这里只能配置线程数的 Core Size，不能配置 Max Size。不配置的话使用的默认值是 10。<br>withKeepAliveTimeMinutes(1) 用来配置核心线程数空闲时 keep alive 的时长，默认为 1 mins。这项配置一般不需要修改。<br>withMaxQueueSize(-1) 用来配置线程池任务队列的大小，默认值为 -1。当使用 -1 时，SynchronousQueue 将被使用，即意味着其实这个队列只是一个交换器，任务将被直接交给工作线程处理。如果工作线程不足，那任务将被拒绝；如果使用任何正整数，LinkedBlockingQueue 将被使用。</p><p>最后还需要配置Command Properties<br>这部分是和命令执行直接相关的配置，包括隔离策略、超时时间、Fallback(服务降级)相关配置</p><p>客户端弹性机制:<br>客户端弹性机制的作用主要是，当远程资源（远程调用或者数据库访问）宕掉或处理能力弱时，能降低消费方受到的影响，避免也因此宕掉。这些机制的目标是让消费方能“快速结束调用(fail fast)”，不会大量占用可用资源，如数据库连接、线程池等，并避免受到上游服务的影响。客户端弹性机制包括：</p><p>Client-side load balancing：客户端负载均衡<br>关于客户端负载均衡，前两章介绍服务发现(Netflix Eureka)时已经介绍过。<br>客户端负载均衡的机制是：客户端从服务发现代理（如Netflix Eureka）获取其他服务实例的IP等位置信息，然后缓存起来并定时刷新。当服务消费端需要调用其他服务，客户端负载均衡器会从维护的可用服务实例池返回目标服务的一个可用实例的具体位置，从而消费端能够准确定位并访问。</p><p>因为客户端负载均衡器处在服务客户端和服务消费端之间（客户端可以理解为服务；消费端则为服务的某个方法，该方法中调用了远程接口，即该方法消费了远程资源），所以负载均衡器能检测到哪个远程服务实例抛异常或者处理能力弱，若检测到，则会将该可能已经出问题的服务实例从可用服务实例池中移除，避免再次访问。</p><p>Netflix的Ribbon库就实现了这样的机制，能开箱即用而不用额外的配置。因为在服务发现已经介绍过Netflix Ribbon的基本使用方法，这里就不过多赘述。</p><p>Circuit breaker：熔断器<br>当一个连接很长时间没有返回结果,强行打断.<br>监控失败调用的次数,以后的调用会自动迅速返回失败,从而有利于远程服务的性能恢复.</p><p>FallBack：回退机制<br>回退机制的作用是，当一个远程访问失败后，服务消费端会执行另一段代码，这段代码可以返回一个已定义好的结果，当然也可以做其它逻辑，而不是硬生生地抛异常。比如现在调用远程接口获取用户数据，而且失败了，那么此时可以选择返回一个用户对象，其中的数据为空，而不是抛出异常，毕竟抛异常的用户体验很不好</p><p>Bulkhead：舱壁机制<br>同样，可以将同一远程调用分到同一线程池中，这样能降低因为一个响应缓慢的调用不断地消耗可用资源而拖垮整个应用的风险。这些线程成就好比船只的一个个舱室，当一个响应缓慢的调用所属的线程池满了，那么接下来的调用只能进入一个队列排队等待，而不会去占用其它可用资源，也就不会影响到其它模块的正常运行。</p><p>具体实现:<br>当Hystrix命令遇到一个远程资源调用失败，它会开启一个10s的计时器，计时器被用来检测该服务调用失败的频率。该时间窗（计时器）是可以配置的，默认是10s。在时间窗开启后结束前，会统计接下来的每一个失败调用。如果失败调用的频数小于一个预设的值，Hystrix不会采取进一步措施，认为之前的失败调用属于正常可控的。比如，设置这个预设值为20，在10s内，Hystrix统计到的失败调用数为15，那么Hystrix会放行接下来的远程调用请求。</p><p>在时间窗结束前，失败调用频数达到预设的值，Hystrix会开始统计远程调用整体失败率。如果失败率超过阈值，该阈值默认为50%，Hystrix会触发熔断器，让接下来的请求都迅速失败返回，防止继续访问可能已出现故障的远程资源。如果，10s时间窗结束，总体失败率未达到或超过阈值，那么Hystrix会重置只统计的数据。直到监听到又一个失败请求，Hystrix会再次开启一个时间窗。稍后还会讲解Hystrix通过放行部分远程调用请求尝试，确认远程资源故障是否已修复，实现“无缝恢复”。</p><p>熔断器有打开，肯定就会有关闭，不然只要熔断器一打开，那么对应的那个远程资源岂不是直接被判死刑，永远拉入黑名单，就算远程资源已恢复也不会放行，人家跟你什么仇什么怨。很明显，这肯定是不合理的。在说明Hystrix何时关闭熔断器时，会涉及到一个叫熔断器“半开”状态的概念。</p><p>何为“半开”状态？熔断器被触发后，Hystrix会开启另一个默认为5s长度也可设置的休眠时间窗，当时间窗结束后，熔断器会从开启状态转换为半开状态。熔断器半开状态下，Hystrix会允许请求尝试访问，若此时访问继续失败，熔断器有进入开启状态，并继续等待下一个休眠时间窗结束后，会再进入半开状态，一直循环重复，知道请求成功；若请求成功，熔断器会被重置为关闭状态。</p><p>Hystrix就是这样来控制熔断器的开启与关闭的。</p><h2 id="6-Ribbon是怎么用的"><a href="#6-Ribbon是怎么用的" class="headerlink" title="6.Ribbon是怎么用的"></a>6.Ribbon是怎么用的</h2><p>Ribbon是一个负载均衡组件,和Nginx不同的是,他是一个进程内负载均衡.<br>负载均衡常见的有软件负载和硬件负载，代表的产品蛋Nginx与F5;<br>Ribbon和他们的区别就是集中式负载均衡与进程内负载均衡的区别。<br>集中式负载均衡是指位于因特网与服务提供者之间，并负责吧网络请求转发到各个提供单位，这个时候Nginx与F5就可以划分为一类了，也可以成为服务端负载均衡策略。进程内负载均衡就是从一个实例库选取一个实例进行流量导入，在微服务的范畴内，实例库一般是存储在Eureka,Consul,Zookeeper,etcd这样的注册中心。</p><h3 id="7-常见的负载均衡策略"><a href="#7-常见的负载均衡策略" class="headerlink" title="7.常见的负载均衡策略"></a>7.常见的负载均衡策略</h3><p><img src="https://s1.ax1x.com/2020/07/27/aPEQqs.png" alt="aPEQqs.png"></p><h2 id="8-为什么采用RxJava并不采用其他的"><a href="#8-为什么采用RxJava并不采用其他的" class="headerlink" title="8.为什么采用RxJava并不采用其他的"></a>8.为什么采用RxJava并不采用其他的</h2><p>本回答主要参考<a href="https://juejin.im/post/5a224cc76fb9a04527256683" target="_blank" rel="noopener">https://juejin.im/post/5a224cc76fb9a04527256683</a><br>简洁.所有的操作都是一条线的,没有嵌套.<br>同样:由被观察者调用了观察者的回调方法，就实现了由被观察者向观察者的事件传递，即观察者模式</p><h2 id="9-为什么用Feign-好处是什么"><a href="#9-为什么用Feign-好处是什么" class="headerlink" title="9.为什么用Feign,好处是什么"></a>9.为什么用Feign,好处是什么</h2><p>Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。<br>同时还集成了Ribbon和hystrix,作为fallback</p><h2 id="10-Dubbo有了解过吗-Docker呢"><a href="#10-Dubbo有了解过吗-Docker呢" class="headerlink" title="10.Dubbo有了解过吗?Docker呢?"></a>10.Dubbo有了解过吗?Docker呢?</h2><p><img src="https://img-blog.csdnimg.cn/20181127112054804.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmcyMHk4,size_16,color_FFFFFF,t_70" alt></p><h2 id="11-Feign是如何设计的"><a href="#11-Feign是如何设计的" class="headerlink" title="11.Feign是如何设计的?"></a>11.Feign是如何设计的?</h2><p>参考文章:<a href="https://www.jianshu.com/p/8c7b92b4396c" target="_blank" rel="noopener">https://www.jianshu.com/p/8c7b92b4396c</a><br><a href="https://imgchr.com/i/dZFBOH" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/08/17/dZFBOH.png" alt="dZFBOH.png"></a></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>容器类</title>
      <link href="/2019/05/05/rong-qi-lei/"/>
      <url>/2019/05/05/rong-qi-lei/</url>
      
        <content type="html"><![CDATA[<h1 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h1><h2 id="1-Hashmap是怎么实现的-hashmap里面有一个resize方法-怎么实现的-hashmap如何扩容的"><a href="#1-Hashmap是怎么实现的-hashmap里面有一个resize方法-怎么实现的-hashmap如何扩容的" class="headerlink" title="1.Hashmap是怎么实现的?hashmap里面有一个resize方法,怎么实现的?hashmap如何扩容的?"></a>1.Hashmap是怎么实现的?hashmap里面有一个resize方法,怎么实现的?hashmap如何扩容的?</h2><p>HashMap实际上是一个一定长度的数组,数组中存放的是链表.<br>当向hashmap中添加元素时,也就是put方法,先算出哈希值,然后取模,然后将新加入的元素放在链表头上.<br><img src="https://s1.ax1x.com/2020/08/19/dlfKN4.png" alt="dlfKN4.png"></p><p>当从hashmap中获取元素的时候,也就是get方法,也是先计算hashcode,找到对应的数组位置,再对比key遍历链表.根据这个原理我们知道,如果每个index上的链表只有一个元素,效率是最高的.所以我们需要扩容机制.</p><p>扩容机制:<br>首先是初始容量大小:16,最大值是2^30.负载因子是0.75;HashMap的容量size乘以负载因子[默认0.75] = threshold, threshold即为开始扩容的临界值.<br>当hashmap中的元素个数超过数组大小的的0.75时,且新建的这个entry落在一个非空的桶上,就要把数组大小扩充为两倍,重新计算每个元素在数组中的位置.这个0.75的计算是大量实验统计出来的.如果取0.5就会造成资源浪费,如果取1,那么get/put碰撞几率增加.JavaDoc写0.75时链表长度服从参数为0.5的泊松分布<br>为什么容量必须是2的幂:可以看到这里是将哈希值h与桶数组的length-1（实际上也是map的容量-1）进行了一个与操作得出了对应的桶的位置，h &amp; (length-1)。因为&amp;比%这个操作符快了10倍左右.</p><p>1.8更新:<br>引入了红黑树,具体使用如下:<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBd1RrUkZNMDFFV21wT1YwVTFUMWRWZDAxdFJYcE1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png" alt><br>主要就是在对应的节点处判断是否已经有数据,解决长链表查询缓慢的问题.<br>要注意1.8之后改成了尾插法,1.7是头插法.<br>因此数组元素和链表节点采用Node类实现.</p><p>因此加入了一些红黑树的相关参数:</p><pre><code>// 1. 桶的树化阈值：即 链表转成红黑树的阈值，在存储数据时，当链表长度 &gt; 该值时，则将链表转换成红黑树   static final int TREEIFY_THRESHOLD = 8;    // 2. 桶的链表还原阈值：即 红黑树转为链表的阈值，当在扩容（resize（））时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 &lt; 6时，则将 红黑树转换成链表   static final int UNTREEIFY_THRESHOLD = 6;   // 3. 最小树形化容量阈值：即 当哈希表中的容量 &gt; 该值时，才允许树形化链表 （即 将链表 转换成红黑树）   // 否则，若桶内元素太多时，则直接扩容，而不是树形化   // 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD   static final int MIN_TREEIFY_CAPACITY = 64;</code></pre><p>hashcode的部分计算图:核心是高位参与低位运算,加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 &amp; 均匀性，最终减少Hash冲突<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBd1dsZFdhazE2U1RSYVZHaHJXa1JPYTA0eVZUTk1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png" alt></p><p>插入操作也进行了优化,如下图:<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBeFRUSkpkMDU2VlhsTmJVbDZUa1JPYkZsdFZUVk1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png" alt><br>核心是先判断是否要树化,再判断是否扩容;</p><p>扩容部分也进行了优化:<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpGb1RYcEdiRTVVUm1sTmFsSnRUVlJOTVZwRVpHcE1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png" alt><br>主要区别是:<br>1,1.8的扩容包含了待插入的数据<br>2,1.8的新位置直接是原位置,或者原位置+旧容量,避免了再次计算.<br>3,使用尾插法</p><p>HashMap 线程不安全的其中一个重要原因：多线程下容易出现resize（）死循环</p><h2 id="2-为什么使用红黑树而不是AVL树"><a href="#2-为什么使用红黑树而不是AVL树" class="headerlink" title="2.为什么使用红黑树而不是AVL树"></a>2.为什么使用红黑树而不是AVL树</h2><p>因为红黑树不需要存储平衡因子,节约内存,而且删除和插入更加的快.AVL查找更快.<br>而且AVL树的旋转更加难以控制和调试</p><h2 id="3-优先队列"><a href="#3-优先队列" class="headerlink" title="3.优先队列"></a>3.优先队列</h2><p>添加复杂度为logN,取出复杂度为logN,peek为O1,默认是升序.</p><h2 id="4-讲一下concurrenthashmap的实现原理"><a href="#4-讲一下concurrenthashmap的实现原理" class="headerlink" title="4.讲一下concurrenthashmap的实现原理"></a>4.讲一下concurrenthashmap的实现原理</h2><p>这里直接总结一下常用的java并发数据结构<br><em>CountDownLatch</em> - 同步工具类</p><p>这个类可以让一个线程等待其他线程完成各自的工作之后再执行,很少使用.</p><p><em>BlockingQueue</em> - 阻塞队列<br>常用实现:<br>ArrayBlockingQueue</p><p>LinkedBlockingQueue</p><p>于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列</p><p>PriorityBlockingQueue</p><p>基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。</p><p><em>ConcurrentLinkedQueue</em>-非阻塞队列<br>这是非阻塞的,队列中元素按照FIFO原则排序,采用CAS操作保证元素一致性.<br>他的自带操作是原子的,但是如果是自己写的非原子操作,还是需要自己加锁</p><p><strong>ConcurrentHashMap</strong> 非常非常重要的数据结构<br>因为HashMap线程不安全,Hashtable所有的重要方法都加了synchronized 关键字修饰,所以线程安全;</p><p>ConcurrentHashMap引入了一个分段锁的概念,把一个大的Map拆分成了N个小的HashTable,默认是16个;所以相当于是16个锁,提高了效率;</p><p><em>ThreadLocal<t></t></em> 创建线程副本<br>通过为每个线程实现ThreadLocalMap来实现每个线程有独立变量</p><h2 id="5-Hash一致性"><a href="#5-Hash一致性" class="headerlink" title="5.Hash一致性"></a>5.Hash一致性</h2><p>一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），得到一个hash环.<br>每台服务器在这个环上有位置.<br>数据将会hit顺时针的第一个机器,这样就保证了一致性.</p><p>因为不管是宕机或者增加一个节点,都只会影响一台机器,所以数据的容错性和扩展性很好.</p><p>虚拟节点机制:<br>对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。<br>同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。<br><img src="https://pic2.zhimg.com/80/v2-0368841e5020dd07f1e67f449b49a1ba_1440w.jpg" alt></p>]]></content>
      
      
      <categories>
          
          <category> 集合类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 容器类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程</title>
      <link href="/2018/12/02/duo-xian-cheng/"/>
      <url>/2018/12/02/duo-xian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h1><h2 id="1-什么是线程池"><a href="#1-什么是线程池" class="headerlink" title="1.什么是线程池"></a>1.什么是线程池</h2><p>一种多线程处理形式,处理时把任务提交到线程池,任务的执行由线程池管理.</p><h2 id="2-为什么要使用"><a href="#2-为什么要使用" class="headerlink" title="2.为什么要使用"></a>2.为什么要使用</h2><p>1,不同请求之间重复利用线程，无需频繁的创建和销毁线程，降低系统开销和控制线程数量上限，避免创建过多的线程耗尽进程内存空间.<br>2,同时减少线程上下文切换次数。</p><p>核心思想:线程池里的每一个线程代码结束后，并不会死亡，而是再次回到线程池中成为空闲状态，等待下一个对象来使用。<br>也就是这其中的每个线程,都会执行提交上来的不同的任务的run,而不会消亡.</p><h2 id="3-线程池的创建和使用"><a href="#3-线程池的创建和使用" class="headerlink" title="3.线程池的创建和使用"></a>3.线程池的创建和使用</h2><p>newSingleThreadExecutor: 单线程的线程池.<br>newFixedThreadPool: 固定大小线程池<br>newCachedThreadPool: 可缓存的线程池<br>newScheduledThreadPool: 支持定时和周期性执行任务的需求<br>newWorkStealingPool: 1.8新增,动态创建和关闭线程</p><p>主要使用spring配置线程池的方式,如下</p><pre><code>&lt;bean id=&quot;userThreadPool&quot;    class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt;    &lt;property name=&quot;corePoolSize&quot; value=&quot;10&quot; /&gt;    &lt;property name=&quot;maxPoolSize&quot; value=&quot;100&quot; /&gt;    &lt;property name=&quot;queueCapacity&quot; value=&quot;2000&quot; /&gt;&lt;property name=&quot;threadFactory&quot; value= threadFactory /&gt;    &lt;property name=&quot;rejectedExecutionHandler&quot;&gt;        &lt;ref local=&quot;rejectedExecutionHandler&quot; /&gt;    &lt;/property&gt;&lt;/bean&gt;// in codeuserThreadPool.execute(thread);</code></pre><p>本质上都是使用ThreadPoolExecutor的线程构造方法</p><h2 id="4-线程池的拒绝策略"><a href="#4-线程池的拒绝策略" class="headerlink" title="4.线程池的拒绝策略"></a>4.线程池的拒绝策略</h2><p>主要有四种策略:<br>AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作。<br>CallerRunsPolicy策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前的被丢弃的任务。<br>DiscardOleddestPolicy策略：该策略将丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。<br>DiscardPolicy策略：该策略默默的丢弃无法处理的任务，不予任何处理。<br>也可以自定义,实现RejectedExecutionHandler接口，在创建ThreadPoolExecutor对象时作为参数传入即可。</p><h2 id="5-线程池的执行"><a href="#5-线程池的执行" class="headerlink" title="5.线程池的执行"></a>5.线程池的执行</h2><p>创建完成ThreadPoolExecutor后,当向线程池提交任务时,通常使用execute方法,该方法执行流程如下:<br><img src="https://img-blog.csdnimg.cn/20191216212221777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9oZWxsby5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70" alt></p><p>如果确定没有问题,则开一个worker线程去执行任务,woker线程的执行流程就是首先执行初始化时分配给的任务，执行完成以后会尝试从阻塞队列中获取可执行的任务，如果指定时间内仍然没有任务可以执行，则进入销毁逻辑。这里只会回收corePoolSize与maximumPoolSize之间的那部分woker。</p><p>执行任务除了可以使用execute方法还可以使用submit方法。它们的主要区别是：execute适用于不需要关注返回值的场景，submit方法适用于需要关注返回值的场景。submit执行的任务，可以通过返回的Future对象的get方法接收抛出的异常，再进行处理。这也算是execute方法与submit方法的差别之一。</p><h2 id="6-重量级锁和轻量级锁的区别是什么"><a href="#6-重量级锁和轻量级锁的区别是什么" class="headerlink" title="6.重量级锁和轻量级锁的区别是什么?\"></a>6.重量级锁和轻量级锁的区别是什么?\</h2><p>字宽:内存大小的单位概念， 对于 32 位处理器 1 Word = 4 Bytes， 64 位处理器 1 Word = 8 Bytes<br>每一个 Java 对象都至少占用 2 个字宽的内存(数组类型占用3个字宽)。<br>第一个字宽也被称为对象头Mark Word。 对象头包含了多种不同的信息， 其中就包含对象锁相关的信息。<br>第二个字宽是指向定义该对象类信息（class metadata）的指针<br><img src="https://img-blog.csdnimg.cn/20190415101813830.png" alt><br>轻量级锁是乐观锁,synchronized锁是重量级的锁.<br>轻量级锁的操作是默认没有加锁,拷贝对象头中的Mark Word复制到锁记录中,拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功就获取锁,如果没有成功就升级为重量级锁.<br>偏向锁已经基本被弃用了.总结就是拿到就不放,别人竞争再放.</p><h2 id="7-介绍一下synchronized关键字"><a href="#7-介绍一下synchronized关键字" class="headerlink" title="7.介绍一下synchronized关键字"></a>7.介绍一下synchronized关键字</h2><p>synchronized 代码块是由一对 monitorenter/moniterexit 字节码指令实现.上述这三种机制的切换是根据竞争激烈程度进行的， 在几乎无竞争的条件下，会使用偏向锁，在轻度竞争的条件下，会由偏向锁升级为轻量级锁(CAS)，在重度竞争的情况下，会升级到重量级锁(操作系统mutex信号量控制)。也就是一开始是偏向锁,逐渐升级到重量级.<br>注意偏向锁是将其他线程的偏向锁撤销之后升级为轻量级锁.</p><h2 id="8-介绍一下Reentrantlock锁-和synchronized关键字的区别在哪"><a href="#8-介绍一下Reentrantlock锁-和synchronized关键字的区别在哪" class="headerlink" title="8.介绍一下Reentrantlock锁?和synchronized关键字的区别在哪?"></a>8.介绍一下Reentrantlock锁?和synchronized关键字的区别在哪?</h2><p>Reentrantlock是等待可中断的,但是synchronized不能;<br>Re可以设置为公平锁(按照申请时间顺序获取锁),但是syn是非公平的(在被释放时,任何一个都有机会获得)<br>锁绑定多个条件</p><p>ReentrantLock可以同时绑定多个Condition对象，只需多次调用newCondition方法即可。<br>synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件。但如果要和多于一个的条件关联的时候，就不得不额外添加一个锁。</p><h2 id="9-LocalThread变量底层实现原理"><a href="#9-LocalThread变量底层实现原理" class="headerlink" title="9.LocalThread变量底层实现原理"></a>9.LocalThread变量底层实现原理</h2><p>参考文章<a href="https://www.cnblogs.com/sxdcgaq8080/p/10436495.html" target="_blank" rel="noopener">https://www.cnblogs.com/sxdcgaq8080/p/10436495.html</a></p><p>简单来说就是在每个线程都会创造一个对应的T副本,线程之间互不影响.</p><p>底层结构是通过操作它的内部类ThreadLocalMap，进行&lt;k,v&gt;键值对的存取和移除。<br>比较常用的:<br>1.拦截器存储 调用接口的用户信息，在本次Request到达，处理，直到返回的本线程中，都可以使用线程变量中的用户信息。(时刻主要线程结束之前一定要remove,防止内存泄漏)</p><h2 id="10-double变量线程安全"><a href="#10-double变量线程安全" class="headerlink" title="10.double变量线程安全"></a>10.double变量线程安全</h2><p>java规范规定了对基本数据类型的操作必须是原子性的，但是long和double除外。<br>但是对于volatile 修饰的long和double，读写必须为原子的。<br>因为读取一个long和double对象不是原子的,需要分为两步,如果一个线程正在修改该 long 变量的值，另一个线程可能只能看到该值的一半（前 32 位）。但是对一个 volatile 型的 long 或 double 变量的读写是原子。<br>但是在最新的jdk中对64位的操作也是原子的了.</p><h2 id="11-volatile关键字的使用和原理"><a href="#11-volatile关键字的使用和原理" class="headerlink" title="11.volatile关键字的使用和原理"></a>11.volatile关键字的使用和原理</h2><p>volatile 变量提供顺序和可见性保证，例如，JVM 或者 JIT为了获得更好的性能会对语句重排序，但是 volatile 类型变量即使在没有同步块的情况下赋值也不会与其他语句重排序。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。某些情况下，volatile 还能提供原子性，如读 64 位数据类型，像 long 和 double 都不是原子的，但 volatile 类型的 double 和 long 就是原子的。</p><p>当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。</p><p>而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。<br>通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。</p><p>深入分析:<br>一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：<br>1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。<br>第一：使用volatile关键字会强制将修改的值立即写入主存；<br>第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；<br>第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。</p><p>2）禁止进行指令重排序。<br>    1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；</p><p>　　 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。</p><p>注意,volatile变量无法保证对变量操作的原子性,自增操作是不具备原子性的,因为即使读取到了原始值,在赋值的时候还是会出现问题.</p><p>最本质实现:<br>“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”<br>lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：</p><p>1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；<br>2）它会强制将对缓存的修改操作立即写入主存；<br>3）如果是写操作，它会导致其他CPU中对应的缓存行无效。</p><p>使用场景:<br>synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：<br>1）对变量的写操作不依赖于当前值<br>2）该变量没有包含在具有其他变量的不变式中<br>实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。<br>事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。</p><h2 id="12-epoll-select-poll-之间的区别"><a href="#12-epoll-select-poll-之间的区别" class="headerlink" title="12.epoll,select,poll 之间的区别"></a>12.epoll,select,poll 之间的区别</h2><p>参考文章:<a href="https://www.cnblogs.com/aspirant/p/9166944.html" target="_blank" rel="noopener">https://www.cnblogs.com/aspirant/p/9166944.html</a><br>(1)select==&gt;时间复杂度O(n)</p><p>它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。</p><p>(2)poll==&gt;时间复杂度O(n)</p><p>poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的.</p><p>(3)epoll==&gt;时间复杂度O(1)</p><p>epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）</p><p>select</p><p>内核需要将消息传递到用户空间，都需要内核拷贝动作</p><p>poll</p><p>同上</p><p>epoll</p><p>epoll通过内核和用户空间共享一块内存来实现的。</p>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
